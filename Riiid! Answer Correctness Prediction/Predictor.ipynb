{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T13:57:59.789613Z",
     "iopub.status.busy": "2021-01-07T13:57:59.788783Z",
     "iopub.status.idle": "2021-01-07T13:58:00.593158Z",
     "shell.execute_reply": "2021-01-07T13:58:00.592356Z"
    },
    "papermill": {
     "duration": 0.836633,
     "end_time": "2021-01-07T13:58:00.593325",
     "exception": false,
     "start_time": "2021-01-07T13:57:59.756692",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T13:58:00.647402Z",
     "iopub.status.busy": "2021-01-07T13:58:00.646632Z",
     "iopub.status.idle": "2021-01-07T13:58:01.717926Z",
     "shell.execute_reply": "2021-01-07T13:58:01.717091Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 1.10159,
     "end_time": "2021-01-07T13:58:01.718074",
     "exception": false,
     "start_time": "2021-01-07T13:58:00.616484",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import defaultdict\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "import datetime\n",
    "import collections\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T13:58:01.773217Z",
     "iopub.status.busy": "2021-01-07T13:58:01.772135Z",
     "iopub.status.idle": "2021-01-07T13:58:01.775440Z",
     "shell.execute_reply": "2021-01-07T13:58:01.774865Z"
    },
    "papermill": {
     "duration": 0.034005,
     "end_time": "2021-01-07T13:58:01.775592",
     "exception": false,
     "start_time": "2021-01-07T13:58:01.741587",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(707)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T13:58:01.838832Z",
     "iopub.status.busy": "2021-01-07T13:58:01.837636Z",
     "iopub.status.idle": "2021-01-07T13:58:01.842019Z",
     "shell.execute_reply": "2021-01-07T13:58:01.841055Z"
    },
    "papermill": {
     "duration": 0.042074,
     "end_time": "2021-01-07T13:58:01.842166",
     "exception": false,
     "start_time": "2021-01-07T13:58:01.800092",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pickle = '../input/riiid-cross-validation-files/cv1_train.pickle'\n",
    "valid_pickle = '../input/riiid-cross-validation-files/cv1_valid.pickle'\n",
    "question_file = '../input/riiid-test-answer-prediction/questions.csv'\n",
    "debug = False\n",
    "build = False\n",
    "\n",
    "# read data\n",
    "feld_needed = ['row_id','timestamp', 'user_id', 'content_id', 'content_type_id', 'answered_correctly', 'prior_question_elapsed_time', 'prior_question_had_explanation','user_answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024505,
     "end_time": "2021-01-07T13:58:01.891026",
     "exception": false,
     "start_time": "2021-01-07T13:58:01.866521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T13:58:01.944689Z",
     "iopub.status.busy": "2021-01-07T13:58:01.943565Z",
     "iopub.status.idle": "2021-01-07T13:58:06.012471Z",
     "shell.execute_reply": "2021-01-07T13:58:06.013157Z"
    },
    "papermill": {
     "duration": 4.097825,
     "end_time": "2021-01-07T13:58:06.013350",
     "exception": false,
     "start_time": "2021-01-07T13:58:01.915525",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92,)\n",
      "['tags_92']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>part</th>\n",
       "      <th>tags_92</th>\n",
       "      <th>enc_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id  correct_answer  part  tags_92  enc_tags\n",
       "0            0               0     0        0       981\n",
       "1            1               1     0        0       306\n",
       "2            2               0     0        1       250"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform tags into lists of ints:\n",
    "questions_df = pd.read_csv(question_file)\n",
    "questions_df['part'] = (questions_df['part'] - 1).astype('uint8')\n",
    "questions_df['correct_answer'] = questions_df['correct_answer'].astype('uint8')\n",
    "questions_df['tags'] = questions_df['tags'].apply(lambda ts: [int(x) for x in str(ts).split() if x != 'nan'])\n",
    "\n",
    "tag_rank = []\n",
    "tag_columns = []\n",
    "tag_to_questions = {}\n",
    "for i, row in questions_df.iterrows():\n",
    "    for t in row['tags']:\n",
    "        tag_rank.append(t)\n",
    "        if t not in tag_to_questions:\n",
    "            tag_to_questions[t] = set()\n",
    "        tag_to_questions[t].add(row['question_id'])\n",
    "tags_df = pd.DataFrame([{'tag':t,'questions':qs}for t,qs in tag_to_questions.items()])\n",
    "tag_rank, counts = zip(*collections.Counter(tag_rank).most_common(1))\n",
    "print(tag_rank)\n",
    "for t in tag_rank:\n",
    "    tag_columns.append('tags_' + str(t))\n",
    "    for i in range(len(questions_df)):\n",
    "        if t in questions_df.iloc[i]['tags']:\n",
    "            questions_df.at[i,'tags_' + str(t)] = 1\n",
    "        else:\n",
    "            questions_df.at[i,'tags_' + str(t)] = 0\n",
    "    questions_df['tags_' + str(t)] = questions_df['tags_' + str(t)].astype('uint8')\n",
    "\n",
    "del questions_df['bundle_id']\n",
    "print(tag_columns)\n",
    "\n",
    "le = LabelEncoder()\n",
    "encoded = le.fit_transform(questions_df['tags'].astype(str))\n",
    "decoded = le.inverse_transform(encoded)\n",
    "questions_df['enc_tags'] = encoded.astype('uint16')\n",
    "del questions_df['tags'], le\n",
    "\n",
    "questions_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T13:58:06.077107Z",
     "iopub.status.busy": "2021-01-07T13:58:06.069002Z",
     "iopub.status.idle": "2021-01-07T13:58:16.144183Z",
     "shell.execute_reply": "2021-01-07T13:58:16.143374Z"
    },
    "papermill": {
     "duration": 10.105841,
     "end_time": "2021-01-07T13:58:16.144347",
     "exception": false,
     "start_time": "2021-01-07T13:58:06.038506",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cython\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "DTYPE = np.int32\n",
    "ctypedef np.int32_t np_int_t\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.nonecheck(False)\n",
    "def add_user_feats_without_update(df,\n",
    "                                  answer_per_dict,\n",
    "                                  answered_correctly_sum_u_dict,\n",
    "                                  answered_correctly_cumsum_u_dict,\n",
    "                                  answered_incorrectly_cumsum_u_dict,\n",
    "                                  count_u_dict,\n",
    "                                  parts_u_dict,\n",
    "                                  parts_count_u_dict,\n",
    "                                  answered_diff_sum_u_dict,\n",
    "                                  avg_c_sum_u_dict,\n",
    "                                  parts_avg_c_dict,\n",
    "                                  user_answer_per_sum_dict,\n",
    "                                  parts_user_answer_per_sum_dict,\n",
    "                                  content_correct_user_mean_dict,\n",
    "                                  content_correct_count_dict,\n",
    "                                  parts_content_correct_user_mean_dict,\n",
    "                                  last_correct_timestamp_dict,\n",
    "                                  last_incorrect_timestamp_dict,\n",
    "                                  like_answer_dict,\n",
    "                                  like_answer_three_dict,\n",
    "                                  dislike_answer_dict,\n",
    "                                  dislike_answer_three_dict,\n",
    "                                  parts_answered_correctly_cumsum_u_dict,\n",
    "                                  parts_answered_incorrectly_cumsum_u_dict):\n",
    "    cdef int arr_size = len(df)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] acsu = np.zeros(arr_size, dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] accu = np.zeros(arr_size, dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] aicu = np.zeros(arr_size, dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] paccu = np.zeros(arr_size, dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] paicu = np.zeros(arr_size, dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] cu = np.zeros(arr_size, dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=2] ptu = np.zeros([arr_size,7], dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=2] ptcu = np.zeros([arr_size,7], dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] adsu = np.zeros(arr_size, dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] avcu = np.zeros(arr_size, dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] pavc = np.zeros(arr_size, dtype=DTYPE)\n",
    "    cdef np.ndarray[float, ndim=1] uaps = np.zeros(arr_size,dtype=np.float32)\n",
    "    cdef np.ndarray[float, ndim=1] puaps = np.zeros(arr_size,dtype=np.float32)\n",
    "    cdef np.ndarray[float, ndim=1] cucm = np.zeros(arr_size,dtype=np.float32)\n",
    "    cdef np.ndarray[float, ndim=1] pcucm = np.zeros(arr_size,dtype=np.float32)\n",
    "    cdef np.ndarray[long, ndim=1] lct = np.zeros(arr_size, dtype=long)\n",
    "    cdef np.ndarray[long, ndim=1] lit = np.zeros(arr_size, dtype=long)\n",
    "    cdef np.ndarray[float, ndim=1] like = np.zeros(arr_size, dtype=np.float32)\n",
    "    cdef np.ndarray[float, ndim=1] dislike = np.zeros(arr_size, dtype=np.float32)\n",
    "    cdef int cnt, i\n",
    "    cdef np.ndarray[long, ndim=1] row\n",
    "    \n",
    "    for cnt,row in enumerate(df[['user_id','part','content_id','timestamp','correct_answer']].values):\n",
    "        acsu[cnt] = answered_correctly_sum_u_dict[row[0]]\n",
    "        accu[cnt] = answered_correctly_cumsum_u_dict[row[0]]\n",
    "        aicu[cnt] = answered_incorrectly_cumsum_u_dict[row[0]]\n",
    "        paccu[cnt] = parts_answered_correctly_cumsum_u_dict[row[1]][row[0]]\n",
    "        paicu[cnt] = parts_answered_incorrectly_cumsum_u_dict[row[1]][row[0]]\n",
    "        cu[cnt] = count_u_dict[row[0]]\n",
    "        adsu[cnt] = answered_diff_sum_u_dict[row[0]]\n",
    "        avcu[cnt] = avg_c_sum_u_dict[row[0]] \n",
    "        uaps[cnt] = user_answer_per_sum_dict[row[0]]\n",
    "        lct[cnt] = row[3] - last_correct_timestamp_dict[row[0]]\n",
    "        lit[cnt] = row[3] - last_incorrect_timestamp_dict[row[0]]\n",
    "        if row[1] == 1:\n",
    "            if (row[3] == 0) or (dict_sub(answered_correctly_sum_u_dict[row[0]] ,count_u_dict[row[0]])==0):\n",
    "                like[cnt] = np.nan\n",
    "                dislike[cnt] = np.nan\n",
    "            else:\n",
    "                like[cnt] = like_answer_three_dict[row[4]][row[0]] / (dict_sub(cu[cnt] ,acsu[cnt]))\n",
    "                dislike[cnt] = dislike_answer_three_dict[row[4]][row[0]] / dict_sub(cu[cnt] ,acsu[cnt])\n",
    "        else:\n",
    "            if (row[3] == 0) or (dict_sub(answered_correctly_sum_u_dict[row[0]] , count_u_dict[row[0]])==0):\n",
    "                like[cnt] = np.nan\n",
    "                dislike[cnt] = np.nan\n",
    "            else:\n",
    "                like[cnt] = like_answer_dict[row[4]][row[0]] / (dict_sub(cu[cnt] , acsu[cnt]))\n",
    "                dislike[cnt] = dislike_answer_dict[row[4]][row[0]] / dict_sub(cu[cnt] , acsu[cnt])\n",
    "                \n",
    "        if content_correct_count_dict[row[2]] > 0:\n",
    "            cucm[cnt] = content_correct_user_mean_dict[row[2]] / content_correct_count_dict[row[2]]\n",
    "            pcucm[cnt] = parts_content_correct_user_mean_dict[row[2]] / content_correct_count_dict[row[2]]\n",
    "\n",
    "        for i in range(7):\n",
    "            ptu[cnt,i] = parts_u_dict[i][row[0]]\n",
    "            ptcu[cnt,i] = parts_count_u_dict[i][row[0]]\n",
    "            if i == row[1]:\n",
    "                pavc[cnt] = parts_avg_c_dict[i][row[0]] / dict_sum(parts_count_u_dict[i][row[0]] , 1)\n",
    "\n",
    "                \n",
    "        if ptcu[cnt,row[1]] != 0:\n",
    "            puaps[cnt] = parts_user_answer_per_sum_dict[row[1]][row[0]] / ptcu[cnt,row[1]]\n",
    "            \n",
    "    df['answered_correctly_sum_u'] = acsu\n",
    "    df['answered_correctly_sum_u'] = df['answered_correctly_sum_u'].astype('uint16')\n",
    "    df['answered_cumsum_u'] = accu - aicu\n",
    "    df['answered_cumsum_u'] = df['answered_cumsum_u'].astype('int8')\n",
    "    df['part_answered_cumsum_u'] = paccu - paicu\n",
    "    df['part_answered_cumsum_u'] = df['part_answered_cumsum_u'].astype('int8') \n",
    "    df['count_u'] = cu\n",
    "    df['count_u'] = df['count_u'].astype('uint16')\n",
    "    df['answered_correctly_avg_u'] = df['answered_correctly_sum_u'] / df['count_u']\n",
    "    df['answered_correctly_avg_u'] = df['answered_correctly_avg_u'].astype('float16')\n",
    "    df['answered_diff_mean'] = adsu  / cu\n",
    "    df['answered_diff_mean'] = df['answered_diff_mean'].astype('float16')\n",
    "    df['avg_c_mean'] = avcu / cu\n",
    "    df['avg_c_mean'] = df['avg_c_mean'].astype('float16')\n",
    "    df['part_avg_c_mean'] = pavc\n",
    "    df['part_avg_c_mean'] = df['part_avg_c_mean'].astype('uint8')\n",
    "    df['avg_c_per_u'] = df['avg_c_mean'] / (df['answered_correctly_avg_u'] * 100)\n",
    "    df['avg_c_per_u'] = df['avg_c_per_u'].astype('float16')\n",
    "    \n",
    "    df['user_answer_per_mean'] = uaps\n",
    "    df['user_answer_per_mean'] = df['user_answer_per_mean']  / df['count_u']\n",
    "    df['user_answer_per_mean'] = df['user_answer_per_mean'].astype('float16')\n",
    "    \n",
    "    df['part_user_answer_per_mean']= puaps\n",
    "    df['part_user_answer_per_mean'] = df['part_user_answer_per_mean'].astype('float16')\n",
    "    \n",
    "    df['content_lv'] = cucm\n",
    "    df['content_lv'] = df['content_lv'].astype('float16')\n",
    "    df['part_content_lv'] = pcucm\n",
    "    df['part_content_lv'] = df['part_content_lv'].astype('float16')\n",
    "    df.loc[df['content_lv']==0,'content_lv']=0.5\n",
    "    df.loc[df['part_content_lv']==0,'part_content_lv']=0.5\n",
    "    \n",
    "    df['last_correct_timelag'] = lct\n",
    "    df['last_correct_timelag'] = df['last_correct_timelag'].astype('uint32')\n",
    "    df['last_incorrect_timelag'] = lit\n",
    "    df['last_incorrect_timelag'] = df['last_incorrect_timelag'].astype('uint32')\n",
    "\n",
    "    df['is_like_answer'] = like\n",
    "    df['is_like_answer'] = df['is_like_answer'].astype('float16')\n",
    "    df['is_dislike_answer'] = dislike\n",
    "    df['is_dislike_answer'] = df['is_dislike_answer'].astype('float16')\n",
    "    \n",
    "    df['part_count_per'] = 0\n",
    "    df['lr_count_per'] = 0\n",
    "    \n",
    "    cdef str pnum\n",
    "    for i in range(7):\n",
    "        pnum = str(i)\n",
    "        df['p' + pnum + '_count_u'] = ptcu[:,i]\n",
    "        df['p' + pnum + '_count_u'] = df['p' + pnum + '_count_u']\n",
    "        df['p' + pnum + '_count_u'] = df['p' + pnum + '_count_u'].astype('uint32')\n",
    "        df['p' + pnum + '_mean_u'] = ptu[:,i] / ptcu[:,i]\n",
    "        df['p' + pnum + '_mean_u']  = df['p' + pnum + '_mean_u'] * (df['p' + pnum + '_count_u'] / df['count_u'])\n",
    "        df['p' + pnum + '_mean_u'] = df['p' + pnum + '_mean_u'].astype('float16')\n",
    "        df.loc[df['part']==i,'part_count_per'] = df['p' + pnum + '_count_u'] / df['count_u']\n",
    "    df.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "    df['part_count_per'] = df['part_count_per'].astype('float16')\n",
    "        \n",
    "    df.loc[df['part']<4,'lr_count_per'] = ((df['p0_count_u'] + df['p1_count_u'] + df['p2_count_u'] + df['p3_count_u']) / df['count_u'])\n",
    "    df.loc[df['part']>3,'lr_count_per'] = ((df['p4_count_u'] + df['p5_count_u'] + df['p6_count_u']) / df['count_u']).astype('float16')\n",
    "    df['lr_count_per'] = df['lr_count_per'].astype('float16')\n",
    "    \n",
    "    df['part_count_per'].replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "    return df\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.nonecheck(False)\n",
    "def update_user_feats(df, \n",
    "                      dict answer_per_dict,\n",
    "                      answered_correctly_sum_u_dict,\n",
    "                      answered_correctly_cumsum_u_dict,\n",
    "                      answered_incorrectly_cumsum_u_dict,\n",
    "                      count_u_dict,\n",
    "                      parts_u_dict,\n",
    "                      parts_count_u_dict,\n",
    "                      answered_diff_sum_u_dict,\n",
    "                      avg_c_sum_u_dict,\n",
    "                      parts_avg_c_dict,\n",
    "                      user_answer_per_sum_dict,\n",
    "                      parts_user_answer_per_sum_dict,\n",
    "                      content_correct_user_mean_dict,\n",
    "                      content_correct_count_dict,\n",
    "                      parts_content_correct_user_mean_dict,\n",
    "                      last_correct_timestamp_dict,\n",
    "                      last_incorrect_timestamp_dict,\n",
    "                      like_answer_dict,\n",
    "                      like_answer_three_dict,\n",
    "                      dislike_answer_dict,\n",
    "                      dislike_answer_three_dict,\n",
    "                      parts_answered_correctly_cumsum_u_dict,\n",
    "                      parts_answered_incorrectly_cumsum_u_dict):\n",
    "    #講義列あり\n",
    "    cdef np.ndarray[long, ndim=1] row\n",
    "    #                   0             1                    2           3               4                     5            6           7              8            \n",
    "    for row in df[['user_id','answered_correctly','content_type_id','part','answered_correctly_avg_c','content_id','user_answer','timestamp','correct_answer']].values:\n",
    "        if row[2] == 0:\n",
    "            if row[1] == 1:\n",
    "                answered_correctly_sum_u_dict[row[0]] = dict_sum(answered_correctly_sum_u_dict[row[0]],1)\n",
    "                answered_correctly_cumsum_u_dict[row[0]] = dict_sum(answered_correctly_cumsum_u_dict[row[0]],1)\n",
    "                answered_incorrectly_cumsum_u_dict[row[0]] = 0\n",
    "                parts_answered_correctly_cumsum_u_dict[row[3]][row[0]] = dict_sum(parts_answered_correctly_cumsum_u_dict[row[3]][row[0]],1)\n",
    "                parts_answered_incorrectly_cumsum_u_dict[row[3]][row[0]] = 0\n",
    "                last_correct_timestamp_dict[row[0]] = row[7]\n",
    "            else:\n",
    "                answered_correctly_cumsum_u_dict[row[0]] = 0\n",
    "                answered_incorrectly_cumsum_u_dict[row[0]] = dict_sum(answered_incorrectly_cumsum_u_dict[row[0]],1)\n",
    "                parts_answered_correctly_cumsum_u_dict[row[3]][row[0]] = 0\n",
    "                parts_answered_incorrectly_cumsum_u_dict[row[3]][row[0]] = dict_sum(parts_answered_incorrectly_cumsum_u_dict[row[3]][row[0]],1)\n",
    "                last_incorrect_timestamp_dict[row[0]] = row[7]\n",
    "                if row[3] == 1:\n",
    "                    like_answer_three_dict[row[6]][row[0]] = dict_sum(like_answer_three_dict[row[6]][row[0]],1)\n",
    "                    for j in [0,1,3]:\n",
    "                        if row[6] != j:\n",
    "                            dislike_answer_three_dict[j][row[0]] = dict_sum(dislike_answer_three_dict[j][row[0]],1)\n",
    "                else:\n",
    "                    like_answer_dict[row[6]][row[0]] = dict_sum(like_answer_dict[row[6]][row[0]],1)\n",
    "                    for j in [0,1,2,3]:\n",
    "                        if row[6] != j:\n",
    "                            dislike_answer_dict[j][row[0]] = dict_sum(dislike_answer_dict[j][row[0]],1)\n",
    "                    \n",
    "            answered_diff_sum_u_dict[row[0]] = dict_sum(answered_diff_sum_u_dict[row[0]],abs(row[4] - (row[1] * 100)))\n",
    "            \n",
    "            if row[5] in answer_per_dict[row[6]]:\n",
    "                user_answer_per_sum_dict[row[0]] = user_answer_per_sum_dict[row[0]] + answer_per_dict[row[6]][row[5]]\n",
    "                parts_user_answer_per_sum_dict[row[3]][row[0]] = parts_user_answer_per_sum_dict[row[3]][row[0]] + answer_per_dict[row[6]][row[5]]\n",
    "            else:\n",
    "                user_answer_per_sum_dict[row[0]] = user_answer_per_sum_dict[row[0]] + 0.33\n",
    "                parts_user_answer_per_sum_dict[row[3]][row[0]] = parts_user_answer_per_sum_dict[row[3]][row[0]] + 0.33\n",
    "            \n",
    "            avg_c_sum_u_dict[row[0]] = dict_sum(avg_c_sum_u_dict[row[0]],row[4])\n",
    "            count_u_dict[row[0]] = dict_sum(count_u_dict[row[0]],1)\n",
    "\n",
    "            parts_u_dict[row[3]][row[0]] = dict_sum(parts_u_dict[row[3]][row[0]],row[1])\n",
    "            parts_count_u_dict[row[3]][row[0]] = dict_sum(parts_count_u_dict[row[3]][row[0]],1)\n",
    "            parts_avg_c_dict[row[3]][row[0]] = dict_sum(parts_avg_c_dict[row[3]][row[0]],row[4])\n",
    "            \n",
    "            if row[1] == 1:\n",
    "                content_correct_count_dict[row[5]] =  dict_sum(content_correct_count_dict[row[5]],1)\n",
    "                content_correct_user_mean_dict[row[5]] = content_correct_user_mean_dict[row[5]] + (answered_correctly_sum_u_dict[row[0]] / count_u_dict[row[0]])\n",
    "                parts_content_correct_user_mean_dict[row[5]] = parts_content_correct_user_mean_dict[row[5]] + (parts_u_dict[row[3]][row[0]] / parts_count_u_dict[row[3]][row[0]])\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.nonecheck(False)\n",
    "cdef int dict_sum(int a, int b):\n",
    "    return a + b\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.nonecheck(False)\n",
    "cdef int dict_sub(int a, int b):\n",
    "    return a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T13:58:16.202775Z",
     "iopub.status.busy": "2021-01-07T13:58:16.201948Z",
     "iopub.status.idle": "2021-01-07T13:58:18.451251Z",
     "shell.execute_reply": "2021-01-07T13:58:18.450647Z"
    },
    "papermill": {
     "duration": 2.28149,
     "end_time": "2021-01-07T13:58:18.451443",
     "exception": false,
     "start_time": "2021-01-07T13:58:16.169953",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cython\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.nonecheck(False)\n",
    "def add_time_feats(df,time_u_dict,lect_u_dict):\n",
    "    cdef int arr_size = len(df)\n",
    "    cdef int cnt\n",
    "    cdef np.ndarray[long, ndim=1] row\n",
    "    cdef np.ndarray[long, ndim=1] tu = np.zeros(arr_size,dtype=long)\n",
    "    cdef np.ndarray[long, ndim=1] lc = np.zeros(arr_size,dtype=long)\n",
    "    for cnt,row in enumerate(df[['user_id','timestamp','content_type_id']].values):\n",
    "        if (row[1] - time_u_dict[row[0]]>0):\n",
    "            tu[cnt] = dict_sub(row[1],time_u_dict[row[0]])\n",
    "        elif (row[1] == 0):\n",
    "            tu[cnt] = 0\n",
    "        else:\n",
    "            tu[cnt] = tu[cnt - 1]\n",
    "        lc[cnt] = lect_u_dict[row[0]]\n",
    "        \n",
    "        time_u_dict[row[0]] = row[1]\n",
    "        if (row[2] == 1):\n",
    "            lect_u_dict[row[0]] = lect_u_dict[row[0]] + 1\n",
    "    \n",
    "    cdef int split = 60*60*24\n",
    "    cdef np.ndarray[long, ndim=1] tu_day = tu // split\n",
    "    cdef np.ndarray[long, ndim=1] tu_time = tu % split \n",
    "\n",
    "    df['lag_time'] = tu_time\n",
    "    df['lag_time'] = df['lag_time'].astype('uint16')\n",
    "    df['lag_day'] = tu_day\n",
    "    df['lag_day'] = df['lag_day'].astype('uint16')\n",
    "    df.loc[df['lag_day']>0,'lag_time'] = np.iinfo(np.uint16).max\n",
    "    df['lecture_count'] = lc\n",
    "    df.loc[df['lecture_count']>np.iinfo(np.uint8).max,'lecture_count'] = np.iinfo(np.uint8).max\n",
    "    df['lecture_count'] = df['lecture_count'].astype('uint8')\n",
    "    return df\n",
    "            \n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.nonecheck(False)\n",
    "cdef int dict_sub(long a, int b):\n",
    "    return a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T13:58:18.509542Z",
     "iopub.status.busy": "2021-01-07T13:58:18.508793Z",
     "iopub.status.idle": "2021-01-07T13:58:18.513154Z",
     "shell.execute_reply": "2021-01-07T13:58:18.513760Z"
    },
    "papermill": {
     "duration": 0.037382,
     "end_time": "2021-01-07T13:58:18.513939",
     "exception": false,
     "start_time": "2021-01-07T13:58:18.476557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions_df = questions_df.set_index('question_id')\n",
    "questions_df.index.name = 'content_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T13:58:18.568266Z",
     "iopub.status.busy": "2021-01-07T13:58:18.567489Z",
     "iopub.status.idle": "2021-01-07T14:00:22.575169Z",
     "shell.execute_reply": "2021-01-07T14:00:22.574351Z"
    },
    "papermill": {
     "duration": 124.03589,
     "end_time": "2021-01-07T14:00:22.575337",
     "exception": false,
     "start_time": "2021-01-07T13:58:18.539447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#content_answer_per生成\n",
    "train = pd.read_pickle(train_pickle)[feld_needed]\n",
    "train = train.loc[train['content_type_id']==0][['content_id','user_answer']]\n",
    "tmp = train.groupby('content_id').count()\n",
    "tmp.rename(columns={'user_answer':'count'},inplace=True)\n",
    "train = pd.read_pickle(train_pickle)[feld_needed]\n",
    "train = train.loc[train['content_type_id']==0][['content_id','user_answer','content_type_id']]\n",
    "tmp2 = train.groupby(['content_id','user_answer']).count().reset_index()\n",
    "tmp2 = tmp2.merge(tmp,left_on='content_id',right_index=True,how='left')\n",
    "tmp2['answer_per'] = tmp2['content_type_id'] / tmp2['count']\n",
    "tmp2 = tmp2[['content_id','user_answer','answer_per']]\n",
    "tmp2['answer_per'].fillna(0.3,inplace=True)\n",
    "answer_per_dict = {}\n",
    "for i in range(4):\n",
    "    answer_per_dict[i] = tmp2.loc[tmp2['user_answer']==i].set_index('content_id')[['answer_per']].to_dict()['answer_per']\n",
    "del train, tmp2, tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T14:00:22.645149Z",
     "iopub.status.busy": "2021-01-07T14:00:22.644276Z",
     "iopub.status.idle": "2021-01-07T14:02:51.688156Z",
     "shell.execute_reply": "2021-01-07T14:02:51.688876Z"
    },
    "papermill": {
     "duration": 149.088034,
     "end_time": "2021-01-07T14:02:51.689092",
     "exception": false,
     "start_time": "2021-01-07T14:00:22.601058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all = 0 101230331\n",
      "current = 50611238 101230331\n",
      "(27270555, 9)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_pickle(train_pickle)[feld_needed]\n",
    "valid = pd.read_pickle(valid_pickle)[feld_needed]\n",
    "# answered correctly average for each content\n",
    "# content_type_idが異なっていて同じコンテンツIDが存在する\n",
    "content_df = train.loc[train['content_type_id']==0][['content_id','answered_correctly']].groupby(['content_id']).agg(['mean']).reset_index()\n",
    "content_df.columns = ['content_id', 'answered_correctly_avg_c']\n",
    "content_df['answered_correctly_avg_c'] = (content_df['answered_correctly_avg_c'] * 100).astype(np.uint8)\n",
    "content_df = content_df.set_index('content_id')\n",
    "content_df.index.name = 'content_id'\n",
    "\n",
    "if debug:\n",
    "    train = pd.read_pickle(train_pickle)\n",
    "    train[:1000000].to_csv('debug.csv')\n",
    "    train = train[feld_needed]\n",
    "    train = train[:1000000]\n",
    "    valid = valid[:10000]\n",
    "else:\n",
    "    #user_id split because user trace\n",
    "    #current active user trace \n",
    "    print('all =',train['row_id'].min(),train['row_id'].max())\n",
    "    train = train.sort_values('row_id')\n",
    "    train = train[int(len(train)/2):]\n",
    "    print('current =',train['row_id'].min(),train['row_id'].max())\n",
    "    users = np.random.choice(train['user_id'].unique(), int(len(train['user_id'].unique()) * 8 / 10), replace=True)\n",
    "\n",
    "    train = pd.read_pickle(train_pickle)[feld_needed]\n",
    "    train = train.loc[train['user_id'].isin(users)]\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T14:02:51.757170Z",
     "iopub.status.busy": "2021-01-07T14:02:51.755317Z",
     "iopub.status.idle": "2021-01-07T14:02:55.008105Z",
     "shell.execute_reply": "2021-01-07T14:02:55.007234Z"
    },
    "papermill": {
     "duration": 3.290538,
     "end_time": "2021-01-07T14:02:55.008254",
     "exception": false,
     "start_time": "2021-01-07T14:02:51.717716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cython\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.nonecheck(False)\n",
    "def data_format(df,questions_df,content_df,float prior_question_elapsed_time_mean):\n",
    "    df['row_id'] = df['row_id'].astype('uint32')\n",
    "    df['user_id'] = df['user_id'].astype('int32')\n",
    "    df['content_type_id'] = df['content_type_id'].astype('uint8')\n",
    "    df.loc[df['content_type_id'] != 0,'content_id'] = 532 #暫定\n",
    "    df['content_id'] = df['content_id'].astype('uint16')\n",
    "    # changing dtype to avoid lightgbm error\n",
    "    df['prior_question_had_explanation'] = df.prior_question_had_explanation.fillna(False).astype('uint8')\n",
    "    df['prior_question_elapsed_time'] = df.prior_question_elapsed_time.fillna(prior_question_elapsed_time_mean)\n",
    "    df['prior_question_elapsed_time'] = (df['prior_question_elapsed_time'] / 1000).astype('uint16')\n",
    "    df['timestamp'] = (df['timestamp'] / 1000).astype(np.uint32)\n",
    "    # merge\n",
    "    df = pd.concat([df.reset_index(drop=True), questions_df.reindex(df['content_id'].values).reset_index(drop=True)], axis=1)\n",
    "    df = pd.concat([df.reset_index(drop=True), content_df.reindex(df['content_id'].values).reset_index(drop=True)], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T14:02:55.073783Z",
     "iopub.status.busy": "2021-01-07T14:02:55.072961Z",
     "iopub.status.idle": "2021-01-07T14:03:12.681562Z",
     "shell.execute_reply": "2021-01-07T14:03:12.680776Z"
    },
    "papermill": {
     "duration": 17.644974,
     "end_time": "2021-01-07T14:03:12.681715",
     "exception": false,
     "start_time": "2021-01-07T14:02:55.036741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fill with mean value for prior_question_elapsed_time\n",
    "# note that `train.prior_question_elapsed_time.mean()` dose not work!\n",
    "# please refer https://www.kaggle.com/its7171/can-we-trust-pandas-mean for detail.\n",
    "prior_question_elapsed_time_mean = train.prior_question_elapsed_time.dropna().values.mean()\n",
    "\n",
    "train = data_format(train,questions_df,content_df,prior_question_elapsed_time_mean)\n",
    "valid = data_format(valid,questions_df,content_df,prior_question_elapsed_time_mean)\n",
    "\n",
    "# memory compaction\n",
    "train.loc[train['answered_correctly'] < 0,'answered_correctly'] = 0\n",
    "train['answered_correctly'] = train['answered_correctly'].astype('uint8')\n",
    "train['user_answer'] = train['user_answer'].astype('uint8')\n",
    "valid.loc[valid['answered_correctly'] < 0,'answered_correctly'] = 0\n",
    "valid['answered_correctly'] = valid['answered_correctly'].astype('uint8')\n",
    "valid['user_answer'] = valid['user_answer'].astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T14:03:12.744559Z",
     "iopub.status.busy": "2021-01-07T14:03:12.743670Z",
     "iopub.status.idle": "2021-01-07T14:03:15.877417Z",
     "shell.execute_reply": "2021-01-07T14:03:15.876556Z"
    },
    "papermill": {
     "duration": 3.168532,
     "end_time": "2021-01-07T14:03:15.877554",
     "exception": false,
     "start_time": "2021-01-07T14:03:12.709022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.loc[train.content_type_id == False].reset_index(drop=True)\n",
    "valid = valid.loc[valid.content_type_id == False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T14:03:15.941073Z",
     "iopub.status.busy": "2021-01-07T14:03:15.939814Z",
     "iopub.status.idle": "2021-01-07T14:03:20.488918Z",
     "shell.execute_reply": "2021-01-07T14:03:20.489527Z"
    },
    "papermill": {
     "duration": 4.585551,
     "end_time": "2021-01-07T14:03:20.489733",
     "exception": false,
     "start_time": "2021-01-07T14:03:15.904182",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cython\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DTYPE = np.int32\n",
    "ctypedef np.int32_t np_int_t\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.nonecheck(False)\n",
    "def add_prior_feats(df, q_stats_dict,q_enc_tag_dict,q_prior_root_dict,\n",
    "                    prior_content_dict, prior_prior_content_dict, prior_time_dict, \n",
    "                    prior_time_per_sum_dict,\n",
    "                    prior_lag_dict, prior_prior_lag_dict,\n",
    "                    lag_sum_dict, prior_avg_c_dict, prior_prior_avg_c_dict,\n",
    "                    part_lag_sum_dict, prior_part_dict):\n",
    "    cdef int arr_size = len(df)\n",
    "    cdef int cnt\n",
    "    cdef np.ndarray[int, ndim=1] row\n",
    "    cdef np.ndarray[np_int_t, ndim=1] pc = np.zeros(arr_size,dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] ppc = np.zeros(arr_size,dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] eqtag = np.zeros(arr_size,dtype=DTYPE)\n",
    "    cdef np.ndarray[float, ndim=1] tp = np.zeros(arr_size,dtype=np.float32)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] pt = np.zeros(arr_size,dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] ul = np.zeros(arr_size,dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] ull = np.zeros(arr_size,dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] pe = np.zeros(arr_size,dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] ls = np.zeros(arr_size,dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] pac = np.zeros(arr_size,dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] ppac = np.zeros(arr_size,dtype=DTYPE)\n",
    "    cdef np.ndarray[float, ndim=1] ptps = np.zeros(arr_size,dtype=np.float32)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] pls = np.zeros(arr_size,dtype=DTYPE)\n",
    "    cdef np.ndarray[float, ndim=1] pr = np.zeros(arr_size,dtype=np.float32)\n",
    "    \n",
    "    for cnt,row in enumerate(df[['user_id','content_id','prior_question_elapsed_time','lag_time' ,'prior_question_had_explanation','answered_correctly_avg_c','part']].values):\n",
    "        ppc[cnt] = prior_prior_content_dict[row[0]]\n",
    "        pc[cnt] = prior_content_dict[row[0]]\n",
    "        if prior_prior_content_dict[row[0]] in q_stats_dict:\n",
    "            pt[cnt] = prior_time_dict[row[0]] / q_stats_dict[prior_prior_content_dict[row[0]]]\n",
    "        else:\n",
    "            pt[cnt] = 1\n",
    "        ls[cnt] = lag_sum_dict[row[0]]\n",
    "        pac[cnt] = prior_avg_c_dict[row[0]]\n",
    "        ppac[cnt] = prior_prior_avg_c_dict[row[0]]\n",
    "        pls[cnt] = part_lag_sum_dict[row[6]][row[0]]\n",
    "        if (q_enc_tag_dict[pc[cnt]] == q_enc_tag_dict[row[1]]):\n",
    "            eqtag[cnt] = 1\n",
    "        else:\n",
    "            eqtag[cnt] = 0\n",
    "        if prior_content_dict[row[0]] > 0:\n",
    "            if (row[1],prior_content_dict[row[0]]) in q_prior_root_dict:\n",
    "                pr[cnt] = q_prior_root_dict[(row[1],prior_content_dict[row[0]])]\n",
    "        else:\n",
    "            if (row[1],-999) in q_prior_root_dict:\n",
    "                pr[cnt] = q_prior_root_dict[(row[1],-999)]\n",
    "        if (prior_content_dict[row[0]] > 0) & (prior_content_dict[row[0]] in q_stats_dict):\n",
    "            tp[cnt] = row[2] / q_stats_dict[prior_content_dict[row[0]]]\n",
    "            prior_time_per_sum_dict[row[0]] = prior_time_per_sum_dict[row[0]] + tp[cnt]\n",
    "        else:\n",
    "            tp[cnt] = 1\n",
    "        ptps[cnt] = prior_time_per_sum_dict[row[0]]\n",
    "        \n",
    "        if prior_content_dict[row[0]] > 0:\n",
    "            prior_part_dict[row[0]] = row[6]\n",
    "            part_lag_sum_dict[prior_part_dict[row[0]]][row[0]] = part_lag_sum_dict[prior_part_dict[row[0]]][row[0]] + tp[cnt]\n",
    "        prior_prior_content_dict[row[0]] = prior_content_dict[row[0]]\n",
    "        prior_content_dict[row[0]] = row[1]\n",
    "        prior_time_dict[row[0]] = row[2] #1つ前のコンテンツの回答時間\n",
    "        ul[cnt] = prior_lag_dict[row[0]]\n",
    "        ull[cnt] = prior_prior_lag_dict[row[0]]\n",
    "        prior_prior_lag_dict[row[0]] = prior_lag_dict[row[0]]\n",
    "        prior_lag_dict[row[0]] = row[3]\n",
    "        lag_sum_dict[row[0]] = lag_sum_dict[row[0]] + row[3]\n",
    "        prior_prior_avg_c_dict[row[0]] = prior_avg_c_dict[row[0]]\n",
    "        prior_avg_c_dict[row[0]] = row[5]\n",
    "            \n",
    "    df['prior_content_id'] = pc\n",
    "    df['prior_content_id'] = df['prior_content_id'].astype('uint16')\n",
    "    df['prior_content_diff'] = df['content_id'] - df['prior_content_id']\n",
    "    df.loc[df['timestamp']==0, 'prior_content_diff'] = -999\n",
    "    #\n",
    "    df['prior_root'] = pr\n",
    "    df['prior_root'] = df['prior_root'].astype('float16')\n",
    "    \n",
    "    df['is_same_prior'] = eqtag\n",
    "    df.loc[df['prior_content_id'] == df['content_id'],'is_same_prior'] = df['is_same_prior'] + 2\n",
    "    df['is_same_prior'] = df['is_same_prior'].astype('uint8')\n",
    "    df['lag_time_per'] = df['lag_time'] / df['prior_question_elapsed_time'].astype('float32')\n",
    "    df['elapsed_lag_per'] = tp\n",
    "    df['elapsed_lag_per'] = df['elapsed_lag_per'].astype('float16')\n",
    "    df['elapsed_time_per_mean'] = ptps\n",
    "    df['elapsed_time_per_mean'] = df['elapsed_time_per_mean'].astype('float16')\n",
    "    \n",
    "    df['part_elapsed_time_per_mean'] = pls\n",
    "    df['part_elapsed_time_per_mean'] = df['part_elapsed_time_per_mean'].astype('float16')\n",
    "\n",
    "    df['prior_prior_lag_time'] = ull\n",
    "    df['prior_prior_lag_time'] = df['prior_prior_lag_time'].astype('uint16')\n",
    "    df['prior_lag_time'] = ul\n",
    "    df['prior_lag_time'] = df['prior_lag_time'].astype('uint16')\n",
    "    df['lag_lag_time'] = df['lag_time'] / df['prior_lag_time']\n",
    "    df['lag_lag_time'] = df['lag_lag_time'].astype('float16')\n",
    "    df['lag_sum'] = ls\n",
    "    df['prior_avg_c'] = pac\n",
    "    df['prior_avg_c'] = df['prior_avg_c'].astype('uint8')\n",
    "    df['prior_prior_avg_c'] = ppac\n",
    "    df['prior_prior_avg_c'] = df['prior_prior_avg_c'].astype('uint8')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T14:03:20.564904Z",
     "iopub.status.busy": "2021-01-07T14:03:20.564091Z",
     "iopub.status.idle": "2021-01-07T14:03:31.029338Z",
     "shell.execute_reply": "2021-01-07T14:03:31.028668Z"
    },
    "papermill": {
     "duration": 10.512369,
     "end_time": "2021-01-07T14:03:31.029475",
     "exception": false,
     "start_time": "2021-01-07T14:03:20.517106",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#q_stats_dict = pd.read_csv('../input/riiiddataset/question_stats.csv').set_index('content_id')[['q_elapsed_time_mean']].to_dict()['q_elapsed_time_mean']\n",
    "#correct answer only\n",
    "q_stats_dict = pd.read_csv('../input/riiiddataset/correct_q_elapsed_time_mean.csv').set_index('content_id')[['correct_q_elapsed_time_mean']].to_dict()['correct_q_elapsed_time_mean']\n",
    "q_enc_tag_dict = questions_df[['enc_tags']].to_dict()['enc_tags']\n",
    "q_ans_dict = questions_df[['correct_answer']].to_dict()['correct_answer']\n",
    "q_prior_root_dict = pd.read_csv('../input/riiiddataset/prior_position_per.csv').fillna(-999).set_index(['content_id','prior_content_id']).to_dict()['prior_position_per']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T14:03:31.092323Z",
     "iopub.status.busy": "2021-01-07T14:03:31.091518Z",
     "iopub.status.idle": "2021-01-07T14:03:34.630786Z",
     "shell.execute_reply": "2021-01-07T14:03:34.629433Z"
    },
    "papermill": {
     "duration": 3.574015,
     "end_time": "2021-01-07T14:03:34.630960",
     "exception": false,
     "start_time": "2021-01-07T14:03:31.056945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cython\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DTYPE = np.int32\n",
    "ctypedef np.int32_t np_int_t\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.nonecheck(False)\n",
    "def add_user_content_feats(df, user_content_dict, user_tags_dict, user_repeat_count_dict):\n",
    "    cdef int arr_size = len(df)\n",
    "    cdef int cnt,i\n",
    "    cdef np.ndarray[np_int_t, ndim=1] row\n",
    "    cdef np.ndarray[np_int_t, ndim=1] uc = np.zeros(arr_size,dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] rc = np.zeros(arr_size,dtype=DTYPE)\n",
    "    for cnt,row in enumerate(df[['user_id','content_id','answered_correctly','enc_tags','part']].values):\n",
    "        if (row[1] in user_content_dict[row[0]]):\n",
    "            uc[cnt] = user_content_dict[row[0]][row[1]]\n",
    "        else:\n",
    "            uc[cnt] = 0\n",
    "        if (row[3] in user_tags_dict[row[0]]):\n",
    "            uc[cnt] = uc[cnt] + (user_tags_dict[row[0]][row[3]] * 2)\n",
    "\n",
    "        rc[cnt] = user_repeat_count_dict[row[4]][row[0]]\n",
    "        \n",
    "        if row[2] == 0:\n",
    "            user_content_dict[row[0]][row[1]] = 1\n",
    "            user_tags_dict[row[0]][row[3]] = 1\n",
    "        else:\n",
    "            user_content_dict[row[0]][row[1]] = 2\n",
    "            user_tags_dict[row[0]][row[3]] = 2\n",
    "            \n",
    "        if row[1] in user_content_dict[row[0]]:\n",
    "            if not row[0] in user_repeat_count_dict[row[4]]:\n",
    "                user_repeat_count_dict[row[4]][row[0]] = 0\n",
    "            user_repeat_count_dict[row[4]][row[0]] = user_repeat_count_dict[row[4]][row[0]] + 1\n",
    "    df['done_content_tag'] = uc\n",
    "    df['done_content_tag'] = df['done_content_tag'].astype('uint8')\n",
    "    df['repeat_part_per'] = rc\n",
    "    return df\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.nonecheck(False)\n",
    "def update_user_content_feats(df,user_content_dict, user_tags_dict, user_repeat_count_dict):\n",
    "    #講義列あり\n",
    "    cdef int arr_size = len(df)\n",
    "    cdef int cnt\n",
    "    cdef np.ndarray[np_int_t, ndim=1] row\n",
    "    for cnt,row in enumerate(df[['user_id','content_id','answered_correctly','enc_tags','content_type_id','part']].values):\n",
    "        if row[4] == 0:\n",
    "            if row[2] == 0:\n",
    "                user_content_dict[row[0]][row[1]] = 1\n",
    "                user_tags_dict[row[0]][row[3]] = 1\n",
    "            else:\n",
    "                user_content_dict[row[0]][row[1]] = 2\n",
    "                user_tags_dict[row[0]][row[3]] = 2\n",
    "            if row[1] in user_content_dict[row[0]]:\n",
    "                if not row[0] in user_repeat_count_dict[row[5]]:\n",
    "                    user_repeat_count_dict[row[5]][row[0]] = 0\n",
    "            user_repeat_count_dict[row[5]][row[0]] = user_repeat_count_dict[row[5]][row[0]] + 1\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.nonecheck(False)\n",
    "def add_user_content_feats_without_update(df,user_content_dict, user_tags_dict, user_repeat_count_dict):\n",
    "    cdef int arr_size = len(df)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] uc = np.zeros(arr_size,dtype=DTYPE)\n",
    "    cdef np.ndarray[np_int_t, ndim=1] rc = np.zeros(arr_size,dtype=DTYPE)\n",
    "    cdef int cnt, i\n",
    "    cdef np.ndarray[np_int_t, ndim=1] row\n",
    "    #content_type_idの考慮不要\n",
    "    for cnt,row in enumerate(df[['user_id','content_id','enc_tags','part']].values):\n",
    "        if (row[1] in user_content_dict[row[0]]):\n",
    "            uc[cnt] = user_content_dict[row[0]][row[1]]\n",
    "        else:\n",
    "            uc[cnt] = 0\n",
    "        \n",
    "        if (row[2] in user_tags_dict[row[0]]):\n",
    "            uc[cnt] = uc[cnt] + (user_tags_dict[row[0]][row[2]] * 2)\n",
    "        rc[cnt] = user_repeat_count_dict[row[3]][row[0]]\n",
    "        \n",
    "    df['done_content_tag'] = uc\n",
    "    df['done_content_tag'] = df['done_content_tag'].astype('uint8')\n",
    "    df['repeat_part_per'] = rc\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T14:03:34.693694Z",
     "iopub.status.busy": "2021-01-07T14:03:34.692837Z",
     "iopub.status.idle": "2021-01-07T14:03:36.481146Z",
     "shell.execute_reply": "2021-01-07T14:03:36.480272Z"
    },
    "papermill": {
     "duration": 1.822954,
     "end_time": "2021-01-07T14:03:36.481315",
     "exception": false,
     "start_time": "2021-01-07T14:03:34.658361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cython\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.nonecheck(False)\n",
    "def post_round(df,list use_tags,list use_content):\n",
    "    df.loc[~df['enc_tags'].isin(use_tags),'enc_tags'] = 65535\n",
    "    df.loc[~df['content_id'].isin(use_content),'content_id'] = 532 #暫定\n",
    "    return df\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.nonecheck(False)\n",
    "def post_features(df):\n",
    "    cdef int i\n",
    "    df['lag_mean'] = (df['lag_sum'] / df['count_u'])\n",
    "    df.loc[df['lag_mean'] > 65535,'lag_mean'] = 65535\n",
    "    df['lag_mean'] = df['lag_mean'].astype('float16')\n",
    "    \n",
    "    df['elapsed_time_per_mean'] = df['elapsed_time_per_mean'] / df['count_u']\n",
    "    df['elapsed_time_per_mean'].fillna(1,inplace=True)\n",
    "    df['elapsed_time_per_mean'] = df['elapsed_time_per_mean'].astype('float16')\n",
    "    \n",
    "    cdef list parts = list(df['part'].unique())\n",
    "    cdef str p\n",
    "    for i in parts:\n",
    "        p = str(i)\n",
    "        df.loc[df['part']==i,'part_elapsed_time_per_mean'] = df['part_elapsed_time_per_mean'] / df['p' + p + '_count_u']\n",
    "        df.loc[df['p' + p  + '_count_u']>0,'repeat_part_per'] = df['repeat_part_per'] / df['p' + p  + '_count_u']\n",
    "\n",
    "    df['prior_question_elapsed_time'] = df['prior_question_elapsed_time'] / df['part_elapsed_time_per_mean']\n",
    "    \n",
    "    df.loc[df['part_user_answer_per_mean'] == 0, 'part_user_answer_per_mean'] = np.nan\n",
    "    df['repeat_part_per'] = df['repeat_part_per'].astype('float16')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T14:03:36.546607Z",
     "iopub.status.busy": "2021-01-07T14:03:36.545809Z",
     "iopub.status.idle": "2021-01-07T14:03:39.711338Z",
     "shell.execute_reply": "2021-01-07T14:03:39.711960Z"
    },
    "papermill": {
     "duration": 3.203027,
     "end_time": "2021-01-07T14:03:39.712156",
     "exception": false,
     "start_time": "2021-01-07T14:03:36.509129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cat round\n",
    "round_max = np.iinfo(np.uint16).max\n",
    "\n",
    "use_tags = list(train['enc_tags'].value_counts()[train['enc_tags'].value_counts()>3].index)\n",
    "use_content = list(train['content_id'].value_counts()[train['content_id'].value_counts()>3].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T14:03:39.771690Z",
     "iopub.status.busy": "2021-01-07T14:03:39.770620Z",
     "iopub.status.idle": "2021-01-07T14:03:40.544756Z",
     "shell.execute_reply": "2021-01-07T14:03:40.545389Z"
    },
    "papermill": {
     "duration": 0.806058,
     "end_time": "2021-01-07T14:03:40.545572",
     "exception": false,
     "start_time": "2021-01-07T14:03:39.739514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del train,valid\n",
    "_=gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027207,
     "end_time": "2021-01-07T14:03:40.599968",
     "exception": false,
     "start_time": "2021-01-07T14:03:40.572761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-01-07T14:03:40.662384Z",
     "iopub.status.busy": "2021-01-07T14:03:40.661079Z",
     "iopub.status.idle": "2021-01-07T14:03:40.671820Z",
     "shell.execute_reply": "2021-01-07T14:03:40.671205Z"
    },
    "papermill": {
     "duration": 0.043096,
     "end_time": "2021-01-07T14:03:40.671966",
     "exception": false,
     "start_time": "2021-01-07T14:03:40.628870",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET = 'answered_correctly'\n",
    "FEATS = ['answered_correctly_avg_u','prior_root',#, 'answered_correctly_sum_u',, 'prior_question_had_explanation' \n",
    "         'answered_cumsum_u',#'q_elapsed_time_mean',#'prior_prior_question_elapsed_time_per','q_elapsed_time_per',\n",
    "         'answered_correctly_avg_c','avg_c_per_u','part_avg_c_mean','elapsed_time_per_mean','part_answered_cumsum_u',\n",
    "         'part','lag_mean','user_answer_per_mean','part_user_answer_per_mean',#'lag_time_per',\n",
    "         'count_u','prior_question_elapsed_time','lag_time','prior_avg_c',#'prior_prior_avg_c',#,'lag_day',,'is_same_prior_content'\n",
    "         'part_count_per','lr_count_per','part_elapsed_time_per_mean','last_incorrect_timelag','last_correct_timelag',\n",
    "         'p0_mean_u','p1_mean_u','p2_mean_u','p3_mean_u','p4_mean_u','p5_mean_u','p6_mean_u','done_content_tag','avg_c_mean',#'done_tags',\n",
    "         'content_id','lecture_count','content_lv','part_content_lv','is_same_prior','prior_content_diff',#'enc_tags'\n",
    "         'answered_diff_mean','prior_lag_time','prior_prior_lag_time','elapsed_lag_per','is_like_answer','is_dislike_answer','repeat_part_per']#,'lag_lag_time','lag_tail_half_mean'\n",
    "#categorical_feature:high-cardinalityなカテゴリ変数\n",
    "CATEGORICAL = ['part','content_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T14:03:40.740031Z",
     "iopub.status.busy": "2021-01-07T14:03:40.739264Z",
     "iopub.status.idle": "2021-01-07T14:03:49.200637Z",
     "shell.execute_reply": "2021-01-07T14:03:49.201789Z"
    },
    "papermill": {
     "duration": 8.501288,
     "end_time": "2021-01-07T14:03:49.202015",
     "exception": false,
     "start_time": "2021-01-07T14:03:40.700727",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "root = '../input/model-deploy-20210104-root-samplingoutput/'\n",
    "file = root + 'lgb.pkl'\n",
    "models.append(pickle.load(open(file, 'rb'))) \n",
    "root = '../input/modeldeploy20210104rootsamplinguserchangeoutput/'\n",
    "file = root + 'lgb.pkl'\n",
    "models.append(pickle.load(open(file, 'rb'))) \n",
    "root = '../input/modeldeploy20210104rootsamplinguserchangev2output/'\n",
    "file = root + 'lgb.pkl'\n",
    "models.append(pickle.load(open(file, 'rb'))) \n",
    "root = '../input/model-deploy-20210106-loutput/'\n",
    "file = root + 'lgb.pkl'\n",
    "models.append(pickle.load(open(file, 'rb'))) \n",
    "root = '../input/model-deploy-20210106-woutput/'\n",
    "file = root + 'lgb.pkl'\n",
    "models.append(pickle.load(open(file, 'rb'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T14:03:49.289756Z",
     "iopub.status.busy": "2021-01-07T14:03:49.272539Z",
     "iopub.status.idle": "2021-01-07T14:04:30.699397Z",
     "shell.execute_reply": "2021-01-07T14:04:30.698724Z"
    },
    "papermill": {
     "duration": 41.463917,
     "end_time": "2021-01-07T14:04:30.699545",
     "exception": false,
     "start_time": "2021-01-07T14:03:49.235628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = '../input/data-deploy-20210101output/'\n",
    "\n",
    "content_df = pd.read_csv(root + 'content_df.csv')\n",
    "content_df = content_df.set_index('content_id')\n",
    "content_df.index.name = 'content_id'\n",
    "content_df['answered_correctly_avg_c'] = content_df['answered_correctly_avg_c'].astype(np.uint8)\n",
    "\n",
    "with open(root + 'time_u_dict.pickle', 'rb') as f:\n",
    "    time_u_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'prior_content_dict.pickle', 'rb') as f:\n",
    "    prior_content_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'prior_prior_content_dict.pickle', 'rb') as f:\n",
    "    prior_prior_content_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'answered_correctly_sum_u_dict', 'rb') as f:\n",
    "    answered_correctly_sum_u_dict = pickle.load(f)   \n",
    "        \n",
    "with open(root + 'answered_correctly_cumsum_u_dict.pickle', 'rb') as f:\n",
    "    answered_correctly_cumsum_u_dict = pickle.load(f)  \n",
    "        \n",
    "with open(root + 'answered_incorrectly_cumsum_u_dict.pickle', 'rb') as f:\n",
    "    answered_incorrectly_cumsum_u_dict = pickle.load(f) \n",
    "        \n",
    "with open(root + 'count_u_dict', 'rb') as f:\n",
    "    count_u_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'parts_count_u_dict.pickle', 'rb') as f:\n",
    "    parts_count_u_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'parts_u_dict.pickle', 'rb') as f:\n",
    "    parts_u_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'answered_diff_sum_u_dict.pickle', 'rb') as f:\n",
    "    answered_diff_sum_u_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'user_content_dict.pickle', 'rb') as f:\n",
    "    user_content_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'user_tags_dict.pickle', 'rb') as f:\n",
    "    user_tags_dict = pickle.load(f)\n",
    "    \n",
    "with open(root + 'prior_lag_dict.pickle','rb') as f:\n",
    "    prior_lag_dict = pickle.load(f)\n",
    "\n",
    "with open(root + 'prior_prior_lag_dict.pickle','rb') as f:\n",
    "    prior_prior_lag_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'prior_time_dict.pickle', 'rb') as f:\n",
    "    prior_time_dict = pickle.load(f)\n",
    "    \n",
    "with open(root + 'prior_time_per_sum_dict.pickle','rb') as f:\n",
    "    prior_time_per_sum_dict = pickle.load(f)   \n",
    "    \n",
    "with open(root + 'part_lag_sum_dict.pickle','rb') as f:\n",
    "    part_lag_sum_dict = pickle.load(f)\n",
    "    \n",
    "with open(root + 'prior_part_dict.pickle','rb') as f:\n",
    "    prior_part_dict = pickle.load(f)\n",
    "    \n",
    "with open(root + 'lag_sum_dict.pickle','rb') as f:\n",
    "    lag_sum_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'avg_c_sum_u_dict.pickle','rb') as f:\n",
    "    avg_c_sum_u_dict = pickle.load(f)\n",
    "    \n",
    "with open(root + 'user_answer_per_sum_dict.pickle','rb') as f:\n",
    "    user_answer_per_sum_dict = pickle.load(f)\n",
    "    \n",
    "with open(root + 'parts_user_answer_per_sum_dict.pickle','rb') as f:\n",
    "    parts_user_answer_per_sum_dict = pickle.load(f)\n",
    "    \n",
    "with open(root + 'content_correct_user_mean_dict.pickle', 'rb') as f:\n",
    "    content_correct_user_mean_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'content_correct_count_dict.pickle', 'rb') as f:\n",
    "    content_correct_count_dict = pickle.load(f)\n",
    "\n",
    "with open(root + 'parts_content_correct_user_mean_dict.pickle', 'rb') as f:\n",
    "    parts_content_correct_user_mean_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'prior_avg_c_dict.pickle', 'rb') as f:\n",
    "    prior_avg_c_dict = pickle.load(f)\n",
    "\n",
    "with open(root + 'prior_prior_avg_c_dict.pickle', 'rb') as f:\n",
    "    prior_prior_avg_c_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'parts_avg_c_dict.pickle', 'rb') as f:\n",
    "    parts_avg_c_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'lect_u_dict.pickle', 'rb') as f:\n",
    "    lect_u_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'last_correct_timestamp_dict.pickle','rb') as f:\n",
    "    last_correct_timestamp_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'last_incorrect_timestamp_dict.pickle','rb') as f:\n",
    "    last_incorrect_timestamp_dict = pickle.load(f)       \n",
    "        \n",
    "with open(root + 'like_answer_three_dict.pickle','rb') as f:\n",
    "    like_answer_three_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'like_answer_dict.pickle', 'rb') as f:\n",
    "    like_answer_dict = pickle.load(f)\n",
    "\n",
    "with open(root + 'dislike_answer_three_dict.pickle','rb') as f:\n",
    "    dislike_answer_three_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'dislike_answer_dict.pickle', 'rb') as f:\n",
    "    dislike_answer_dict = pickle.load(f)\n",
    "        \n",
    "with open(root + 'parts_answered_correctly_cumsum_u_dict.pickle','rb') as f:\n",
    "    parts_answered_correctly_cumsum_u_dict = pickle.load(f)\n",
    "\n",
    "with open(root + 'parts_answered_incorrectly_cumsum_u_dict.pickle','rb') as f:\n",
    "    parts_answered_incorrectly_cumsum_u_dict = pickle.load(f)\n",
    "    \n",
    "with open(root + 'user_repeat_count_dict.pickle', 'rb') as f:\n",
    "    user_repeat_count_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027504,
     "end_time": "2021-01-07T14:04:30.755929",
     "exception": false,
     "start_time": "2021-01-07T14:04:30.728425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# model weight initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T14:04:30.824739Z",
     "iopub.status.busy": "2021-01-07T14:04:30.823701Z",
     "iopub.status.idle": "2021-01-07T14:04:31.370762Z",
     "shell.execute_reply": "2021-01-07T14:04:31.369979Z"
    },
    "papermill": {
     "duration": 0.587375,
     "end_time": "2021-01-07T14:04:31.370928",
     "exception": false,
     "start_time": "2021-01-07T14:04:30.783553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_count = defaultdict(int)\n",
    "model_weight = {}\n",
    "users = {}\n",
    "loss = {}\n",
    "for m in range(len(models)):\n",
    "    model_weight[m] = defaultdict(int)\n",
    "    users[m] = defaultdict(int)\n",
    "\n",
    "root = '../input/model-deploy-20210104-root-samplingoutput/'\n",
    "file = root + 'train_users.pickle'\n",
    "users[0] = pickle.load(open(file, 'rb'))\n",
    "loss[0] = defaultdict(int)\n",
    "root = '../input/modeldeploy20210104rootsamplinguserchangeoutput/'\n",
    "file = root + 'train_users.pickle'\n",
    "users[1] = pickle.load(open(file, 'rb'))\n",
    "loss[1] = defaultdict(int)\n",
    "root = '../input/modeldeploy20210104rootsamplinguserchangev2output/'\n",
    "file = root + 'train_users.pickle'\n",
    "users[2] = pickle.load(open(file, 'rb'))\n",
    "loss[2] = defaultdict(int)\n",
    "\n",
    "\n",
    "for d in range(len(users)):\n",
    "    for u in users[d]:\n",
    "        model_weight[d][u] = 1\n",
    "        user_count[u] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T14:04:31.437051Z",
     "iopub.status.busy": "2021-01-07T14:04:31.436219Z",
     "iopub.status.idle": "2021-01-07T14:04:35.996007Z",
     "shell.execute_reply": "2021-01-07T14:04:35.995266Z"
    },
    "papermill": {
     "duration": 4.596078,
     "end_time": "2021-01-07T14:04:35.996147",
     "exception": false,
     "start_time": "2021-01-07T14:04:31.400069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cython\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DTYPE = np.int32\n",
    "ctypedef np.int32_t np_int_t\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.nonecheck(False)\n",
    "def get_model_weight(df,dict model_weight,user_count):\n",
    "    \n",
    "    cdef np.ndarray[np_int_t, ndim=1] row\n",
    "    cdef int arr_size = len(df)\n",
    "    cdef int cnt\n",
    "    cdef np.ndarray[float, ndim=1] weight0 = np.zeros(arr_size,dtype=np.float32)\n",
    "    cdef np.ndarray[float, ndim=1] weight1 = np.zeros(arr_size,dtype=np.float32)\n",
    "    cdef np.ndarray[float, ndim=1] weight2 = np.zeros(arr_size,dtype=np.float32)\n",
    "    cdef np.ndarray[float, ndim=1] weight3 = np.zeros(arr_size,dtype=np.float32)\n",
    "    cdef np.ndarray[float, ndim=1] weight4 = np.zeros(arr_size,dtype=np.float32)\n",
    "    for cnt,row in enumerate(df[['user_id','content_type_id','part']].values):\n",
    "        if row[1] == 0:\n",
    "            if user_count[row[0]] == 0:\n",
    "                weight0[cnt] = 1/3\n",
    "                weight1[cnt] = 1/3\n",
    "                weight2[cnt] = 1/3\n",
    "            else:\n",
    "                weight0[cnt] = model_weight[0][row[0]] / user_count[row[0]]\n",
    "                weight1[cnt] = model_weight[1][row[0]] / user_count[row[0]]\n",
    "                weight2[cnt] = model_weight[2][row[0]] / user_count[row[0]]\n",
    "        if row[2]<4:\n",
    "            weight3[cnt] = 0.15\n",
    "            weight4[cnt] = 0\n",
    "        else:\n",
    "            weight3[cnt] = 0\n",
    "            weight4[cnt] = 0.15\n",
    "            \n",
    "          \n",
    "    df['weight0'] = weight0 / (weight0 + weight1 + weight2  + weight3 + weight4)\n",
    "    df['weight1'] = weight1 / (weight0 + weight1 + weight2  + weight3 + weight4)\n",
    "    df['weight2'] = weight2 / (weight0 + weight1 + weight2  + weight3 + weight4)\n",
    "    df['weight3'] = weight3 / (weight0 + weight1 + weight2  + weight3 + weight4)\n",
    "    df['weight4'] = weight4 / (weight0 + weight1 + weight2  + weight3 + weight4)\n",
    "\n",
    "    df['weight_all'] = df['weight0'] + df['weight1'] + df['weight2'] + df['weight3'] + df['weight4']\n",
    "    return df\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.nonecheck(False)\n",
    "def update_model_weight(df,dict model_weight,user_count,loss):\n",
    "    cdef int best,taget,cnt\n",
    "    cdef np.ndarray[np_int_t, ndim=1] row\n",
    "    cdef int arr_size = len(df)\n",
    "    df['predicts0'] = (df['predicts0'] * 100).astype('uint8')\n",
    "    df['predicts1'] = (df['predicts1'] * 100).astype('uint8')\n",
    "    df['predicts2'] = (df['predicts2'] * 100).astype('uint8')\n",
    "    \n",
    "    #                       　　　   0                  1         　　       2             3           4            5       \n",
    "    for cnt,row in enumerate(df[['user_id','answered_correctly','content_type_id','predicts0','predicts1','predicts2']].values):\n",
    "        if row[2] == 0:\n",
    "            target = row[1] * 100\n",
    "            loss[0][row[0]] = loss[0][row[0]] + abs(target - row[3]) \n",
    "            loss[1][row[0]] = loss[1][row[0]] + abs(target - row[4]) \n",
    "            loss[2][row[0]] = loss[2][row[0]] + abs(target - row[5])\n",
    "            best = np.argmin([loss[0][row[0]],loss[1][row[0]],loss[2][row[0]]])\n",
    "            model_weight[best][row[0]] = model_weight[best][row[0]] + 1\n",
    "            user_count[row[0]] = user_count[row[0]] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T14:04:36.083252Z",
     "iopub.status.busy": "2021-01-07T14:04:36.064071Z",
     "iopub.status.idle": "2021-01-07T14:04:36.086609Z",
     "shell.execute_reply": "2021-01-07T14:04:36.086029Z"
    },
    "papermill": {
     "duration": 0.061422,
     "end_time": "2021-01-07T14:04:36.086810",
     "exception": false,
     "start_time": "2021-01-07T14:04:36.025388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Iter_Valid(object):\n",
    "    def __init__(self, df, max_user=1000):\n",
    "        df = df.reset_index(drop=True)\n",
    "        self.df = df\n",
    "        self.user_answer = df['user_answer'].astype(str).values\n",
    "        self.answered_correctly = df['answered_correctly'].astype(str).values\n",
    "        df['prior_group_responses'] = \"[]\"\n",
    "        df['prior_group_answers_correct'] = \"[]\"\n",
    "        self.sample_df = df[df['content_type_id'] == 0][['row_id']]\n",
    "        self.sample_df['answered_correctly'] = 0\n",
    "        self.len = len(df)\n",
    "        self.user_id = df.user_id.values\n",
    "        self.task_container_id = df.task_container_id.values\n",
    "        self.content_type_id = df.content_type_id.values\n",
    "        self.max_user = max_user\n",
    "        self.current = 0\n",
    "        self.pre_user_answer_list = []\n",
    "        self.pre_answered_correctly_list = []\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def fix_df(self, user_answer_list, answered_correctly_list, pre_start):\n",
    "        df= self.df[pre_start:self.current].copy()\n",
    "        sample_df = self.sample_df[pre_start:self.current].copy()\n",
    "        df.loc[pre_start,'prior_group_responses'] = '[' + \",\".join(self.pre_user_answer_list) + ']'\n",
    "        df.loc[pre_start,'prior_group_answers_correct'] = '[' + \",\".join(self.pre_answered_correctly_list) + ']'\n",
    "        self.pre_user_answer_list = user_answer_list\n",
    "        self.pre_answered_correctly_list = answered_correctly_list\n",
    "        return df, sample_df\n",
    "\n",
    "    def __next__(self):\n",
    "        added_user = set()\n",
    "        pre_start = self.current\n",
    "        pre_added_user = -1\n",
    "        pre_task_container_id = -1\n",
    "        pre_content_type_id = -1\n",
    "        user_answer_list = []\n",
    "        answered_correctly_list = []\n",
    "        while self.current < self.len:\n",
    "            crr_user_id = self.user_id[self.current]\n",
    "            crr_task_container_id = self.task_container_id[self.current]\n",
    "            crr_content_type_id = self.content_type_id[self.current]\n",
    "            if crr_user_id in added_user and (crr_user_id != pre_added_user or (crr_task_container_id != pre_task_container_id and crr_content_type_id == 0 and pre_content_type_id == 0)):\n",
    "                # known user(not prev user or (differnt task container and both question))\n",
    "                return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n",
    "            if len(added_user) == self.max_user:\n",
    "                if  crr_user_id == pre_added_user and (crr_task_container_id == pre_task_container_id or crr_content_type_id == 1):\n",
    "                    user_answer_list.append(self.user_answer[self.current])\n",
    "                    answered_correctly_list.append(self.answered_correctly[self.current])\n",
    "                    self.current += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n",
    "            added_user.add(crr_user_id)\n",
    "            pre_added_user = crr_user_id\n",
    "            pre_task_container_id = crr_task_container_id\n",
    "            pre_content_type_id = crr_content_type_id\n",
    "            user_answer_list.append(self.user_answer[self.current])\n",
    "            answered_correctly_list.append(self.answered_correctly[self.current])\n",
    "            self.current += 1\n",
    "        if pre_start < self.current:\n",
    "            return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n",
    "        else:\n",
    "            raise StopIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T14:04:36.154440Z",
     "iopub.status.busy": "2021-01-07T14:04:36.153669Z",
     "iopub.status.idle": "2021-01-07T14:04:36.180212Z",
     "shell.execute_reply": "2021-01-07T14:04:36.181229Z"
    },
    "papermill": {
     "duration": 0.064056,
     "end_time": "2021-01-07T14:04:36.181435",
     "exception": false,
     "start_time": "2021-01-07T14:04:36.117379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import riiideducation\n",
    "if debug:\n",
    "    target_df = pd.read_csv('debug.csv',index_col=0)\n",
    "    iter_test = Iter_Valid(target_df,max_user=1000)\n",
    "    predicted = []\n",
    "    def set_predict(df):\n",
    "        predicted.append(df)\n",
    "else:\n",
    "    env = riiideducation.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    set_predict = env.predict   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-07T14:04:36.254947Z",
     "iopub.status.busy": "2021-01-07T14:04:36.249107Z",
     "iopub.status.idle": "2021-01-07T14:04:37.304578Z",
     "shell.execute_reply": "2021-01-07T14:04:37.303808Z"
    },
    "papermill": {
     "duration": 1.094727,
     "end_time": "2021-01-07T14:04:37.304749",
     "exception": false,
     "start_time": "2021-01-07T14:04:36.210022",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_itr = 0:00:00.213102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_itr = 0:00:00.248566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_itr = 0:00:00.248934\n",
      "test_itr = 0:00:00.256500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "#0.55 sec/iter\n",
    "#test_itr = 0:00:01.182652\n",
    "previous_test_df = None\n",
    "predicts0 = None\n",
    "predicts1 = None\n",
    "predicts2 = None\n",
    "predicts_final = None\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    start = datetime.datetime.now()\n",
    "    #講座の対処ができていないので暫定で講座コンテンツID置換(集計対象外)\n",
    "    test_df.loc[test_df['content_type_id'] == 1,'content_id'] = 0\n",
    "    test_df = data_format(test_df,questions_df,content_df,prior_question_elapsed_time_mean)\n",
    "    test_df = post_round(test_df,use_tags,use_content)\n",
    "    \n",
    "    if previous_test_df is not None:\n",
    "        previous_test_df[TARGET] = eval(test_df[\"prior_group_answers_correct\"].iloc[0])\n",
    "        previous_test_df[TARGET] = previous_test_df[TARGET].astype('uint8')\n",
    "        previous_test_df['user_answer'] = eval(test_df[\"prior_group_responses\"].iloc[0])\n",
    "        previous_test_df['user_answer'] = previous_test_df['user_answer'].astype('uint8')\n",
    "\n",
    "        update_user_content_feats(previous_test_df, user_content_dict, user_tags_dict, user_repeat_count_dict)\n",
    "        update_user_feats(previous_test_df,\n",
    "                          answer_per_dict,\n",
    "                          answered_correctly_sum_u_dict,\n",
    "                          answered_correctly_cumsum_u_dict,\n",
    "                          answered_incorrectly_cumsum_u_dict,\n",
    "                          count_u_dict,\n",
    "                          parts_u_dict,\n",
    "                          parts_count_u_dict,\n",
    "                          answered_diff_sum_u_dict,\n",
    "                          avg_c_sum_u_dict,\n",
    "                          parts_avg_c_dict,\n",
    "                          user_answer_per_sum_dict,\n",
    "                          parts_user_answer_per_sum_dict,\n",
    "                          content_correct_user_mean_dict,\n",
    "                          content_correct_count_dict,\n",
    "                          parts_content_correct_user_mean_dict,\n",
    "                          last_correct_timestamp_dict,\n",
    "                          last_incorrect_timestamp_dict,\n",
    "                          like_answer_dict,\n",
    "                          like_answer_three_dict,\n",
    "                          dislike_answer_dict,\n",
    "                          dislike_answer_three_dict,\n",
    "                          parts_answered_correctly_cumsum_u_dict,\n",
    "                          parts_answered_incorrectly_cumsum_u_dict)\n",
    "        \n",
    "        previous_test_df = previous_test_df[previous_test_df['content_type_id'] == 0].reset_index(drop=True)\n",
    "        previous_test_df['predicts0'] = predicts0\n",
    "        previous_test_df['predicts1'] = predicts1\n",
    "        previous_test_df['predicts2'] = predicts2\n",
    "        previous_test_df['predicts3'] = predicts3\n",
    "        previous_test_df['predicts4'] = predicts4\n",
    "        ##DEBUG\n",
    "        #previous_test_df['predicts_final'] = predicts_final\n",
    "        #display(previous_test_df[['weight0','weight1','weight2','weight3','weight4','weight_all','part',\n",
    "        #                          'predicts0','predicts1','predicts2','predicts3','predicts4',TARGET]])\n",
    "        ##\n",
    "        update_model_weight(previous_test_df,model_weight,user_count,loss)\n",
    "    \n",
    "    test_df = add_time_feats(test_df,time_u_dict,lect_u_dict)\n",
    "    test_df = add_user_content_feats_without_update(test_df,\n",
    "                                                    user_content_dict,\n",
    "                                                    user_tags_dict,\n",
    "                                                    user_repeat_count_dict)\n",
    "    \n",
    "    test_df = get_model_weight(test_df,model_weight,user_count)\n",
    "    \n",
    "    #Type Safeとするため暫定で存在するコンテンツに置換\n",
    "    previous_test_df = test_df.copy()\n",
    "    test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop=True)\n",
    "    test_df = add_user_feats_without_update(test_df, \n",
    "                                            answer_per_dict,\n",
    "                                            answered_correctly_sum_u_dict,\n",
    "                                            answered_correctly_cumsum_u_dict,\n",
    "                                            answered_incorrectly_cumsum_u_dict,\n",
    "                                            count_u_dict,\n",
    "                                            parts_u_dict,\n",
    "                                            parts_count_u_dict,\n",
    "                                            answered_diff_sum_u_dict,\n",
    "                                            avg_c_sum_u_dict,\n",
    "                                            parts_avg_c_dict,\n",
    "                                            user_answer_per_sum_dict,\n",
    "                                            parts_user_answer_per_sum_dict,\n",
    "                                            content_correct_user_mean_dict,\n",
    "                                            content_correct_count_dict,\n",
    "                                            parts_content_correct_user_mean_dict,\n",
    "                                            last_correct_timestamp_dict,\n",
    "                                            last_incorrect_timestamp_dict,\n",
    "                                            like_answer_dict,\n",
    "                                            like_answer_three_dict,\n",
    "                                            dislike_answer_dict,\n",
    "                                            dislike_answer_three_dict,\n",
    "                                            parts_answered_correctly_cumsum_u_dict,\n",
    "                                            parts_answered_incorrectly_cumsum_u_dict)\n",
    "    test_df = add_prior_feats(test_df, \n",
    "                              q_stats_dict,\n",
    "                              q_enc_tag_dict,\n",
    "                              q_prior_root_dict,\n",
    "                              prior_content_dict,\n",
    "                              prior_prior_content_dict,\n",
    "                              prior_time_dict,\n",
    "                              prior_time_per_sum_dict,\n",
    "                              prior_lag_dict,\n",
    "                              prior_prior_lag_dict,\n",
    "                              lag_sum_dict,\n",
    "                              prior_avg_c_dict,\n",
    "                              prior_prior_avg_c_dict,\n",
    "                              part_lag_sum_dict,\n",
    "                              prior_part_dict)\n",
    "    \n",
    "    test_df = post_features(test_df)\n",
    "    \n",
    "    predicts0 =  models[0].predict(test_df[FEATS])\n",
    "    predicts1 =  models[1].predict(test_df[FEATS])\n",
    "    predicts2 =  models[2].predict(test_df[FEATS])\n",
    "    predicts3 =  models[3].predict(test_df[FEATS])\n",
    "    predicts4 =  models[4].predict(test_df[FEATS])\n",
    "    \n",
    "    predicts_final = ((predicts0 * test_df['weight0']) + (predicts1 * test_df['weight1']) + (predicts2 * test_df['weight2']) + (predicts3 * test_df['weight3']) + (predicts4 * test_df['weight4']))\n",
    "    test_df[TARGET] = predicts_final \n",
    "    \n",
    "    set_predict(test_df[['row_id', TARGET]])\n",
    "    print('test_itr =',(datetime.datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.040824,
     "end_time": "2021-01-07T14:04:37.386756",
     "exception": false,
     "start_time": "2021-01-07T14:04:37.345932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 404.190574,
   "end_time": "2021-01-07T14:04:38.652740",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-07T13:57:54.462166",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
