{"cells":[{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"%load_ext Cython","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-12T18:21:01.107461Z","iopub.status.busy":"2020-10-12T18:21:01.1067Z","iopub.status.idle":"2020-10-12T18:21:02.19541Z","shell.execute_reply":"2020-10-12T18:21:02.194464Z"},"lines_to_next_cell":2,"papermill":{"duration":1.131405,"end_time":"2020-10-12T18:21:02.195556","exception":false,"start_time":"2020-10-12T18:21:01.064151","status":"completed"},"tags":[],"trusted":true,"scrolled":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gc\nfrom sklearn.metrics import roc_auc_score\nfrom collections import defaultdict\nimport lightgbm as lgb\nimport pickle\nimport datetime\nimport collections\nfrom sklearn.preprocessing import LabelEncoder\nimport random\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def seed_everything(seed: int):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n\nseed_everything(707)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"train_pickle = '../input/riiid-cross-validation-files/cv1_train.pickle'\nvalid_pickle = '../input/riiid-cross-validation-files/cv1_valid.pickle'\nquestion_file = '../input/riiid-test-answer-prediction/questions.csv'\ndebug = False\nbuild = True\nroot = '../input/base-0794-20201224output/'\n\n# read data\nfeld_needed = ['row_id','timestamp', 'user_id', 'content_id', 'content_type_id', 'answered_correctly', 'prior_question_elapsed_time', 'prior_question_had_explanation','user_answer']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## feature engineering"},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# Transform tags into lists of ints:\nquestions_df = pd.read_csv(question_file)\nquestions_df['part'] = (questions_df['part'] - 1).astype('uint8')\nquestions_df['correct_answer'] = questions_df['correct_answer'].astype('uint8')\nquestions_df['tags'] = questions_df['tags'].apply(lambda ts: [int(x) for x in str(ts).split() if x != 'nan'])\n\ntag_rank = []\ntag_columns = []\ntag_to_questions = {}\nfor i, row in questions_df.iterrows():\n    for t in row['tags']:\n        tag_rank.append(t)\n        if t not in tag_to_questions:\n            tag_to_questions[t] = set()\n        tag_to_questions[t].add(row['question_id'])\ntags_df = pd.DataFrame([{'tag':t,'questions':qs}for t,qs in tag_to_questions.items()])\ntag_rank, counts = zip(*collections.Counter(tag_rank).most_common(1))\nprint(tag_rank)\nfor t in tag_rank:\n    tag_columns.append('tags_' + str(t))\n    for i in range(len(questions_df)):\n        if t in questions_df.iloc[i]['tags']:\n            questions_df.at[i,'tags_' + str(t)] = 1\n        else:\n            questions_df.at[i,'tags_' + str(t)] = 0\n    questions_df['tags_' + str(t)] = questions_df['tags_' + str(t)].astype('uint8')\n\ndel questions_df['bundle_id']\nprint(tag_columns)\n\nle = LabelEncoder()\nencoded = le.fit_transform(questions_df['tags'].astype(str))\ndecoded = le.inverse_transform(encoded)\nquestions_df['enc_tags'] = encoded.astype('uint16')\ndel questions_df['tags'], le\n\nquestions_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_pickle(train_pickle)[feld_needed]\nvalid = pd.read_pickle(valid_pickle)[feld_needed]\ntmp = pd.concat([train[['content_type_id','content_id','answered_correctly']],valid[['content_type_id','content_id','answered_correctly']]])\ncontent_df = tmp.loc[tmp['content_type_id']==0][['content_id','answered_correctly']].groupby(['content_id']).agg(['mean']).reset_index()\ncontent_df.columns = ['content_id', 'answered_correctly_avg_c']\ncontent_df['answered_correctly_avg_c'] = (content_df['answered_correctly_avg_c'] * 100).astype(np.uint8)\ncontent_df = content_df.set_index('content_id')\ncontent_df.index.name = 'content_id'\ncontent_df.to_csv('content_df.csv')\ndel content_df,tmp,train,valid\n_=gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"%%cython\nimport cython\ncimport cython\nimport numpy as np\ncimport numpy as np\nimport pandas as pd\nimport gc\n\nDTYPE = np.int32\nctypedef np.int32_t np_int_t\n#dict\n@cython.boundscheck(False)\n@cython.wraparound(False)\n@cython.nonecheck(False)\ndef add_user_feats(df, \n                   answer_per_dict,\n                   answered_correctly_sum_u_dict,\n                   answered_correctly_cumsum_u_dict,\n                   answered_incorrectly_cumsum_u_dict,\n                   count_u_dict,\n                   parts_u_dict,\n                   parts_count_u_dict,\n                   answered_diff_sum_u_dict,\n                   avg_c_sum_u_dict,\n                   parts_avg_c_dict,\n                   user_answer_per_sum_dict,\n                   parts_user_answer_per_sum_dict,\n                   content_correct_user_mean_dict,\n                   content_correct_count_dict,\n                   parts_content_correct_user_mean_dict,\n                   last_correct_timestamp_dict,\n                   last_incorrect_timestamp_dict,\n                   like_answer_dict,\n                   like_answer_three_dict,\n                   dislike_answer_dict,\n                   dislike_answer_three_dict,\n                   parts_answered_correctly_cumsum_u_dict,\n                   parts_answered_incorrectly_cumsum_u_dict):\n    \n    cdef int arr_size = len(df)\n    \n    cdef np.ndarray[np_int_t, ndim=1] acsu = np.zeros(arr_size, dtype=DTYPE)\n    cdef np.ndarray[np_int_t, ndim=1] accu = np.zeros(arr_size, dtype=DTYPE)\n    cdef np.ndarray[np_int_t, ndim=1] aicu = np.zeros(arr_size, dtype=DTYPE)\n    cdef np.ndarray[np_int_t, ndim=1] cu = np.zeros(arr_size, dtype=DTYPE)\n    cdef np.ndarray[np_int_t, ndim=2] ptu = np.zeros([arr_size,7], dtype=DTYPE)\n    cdef np.ndarray[np_int_t, ndim=2] ptcu = np.zeros([arr_size,7], dtype=DTYPE)\n    cdef np.ndarray[np_int_t, ndim=1] paccu = np.zeros(arr_size, dtype=DTYPE)#\n    cdef np.ndarray[np_int_t, ndim=1] paicu = np.zeros(arr_size, dtype=DTYPE)#\n    cdef np.ndarray[np_int_t, ndim=1] adsu = np.zeros(arr_size, dtype=DTYPE)\n    cdef np.ndarray[np_int_t, ndim=1] avcu = np.zeros(arr_size, dtype=DTYPE)\n    cdef np.ndarray[np_int_t, ndim=1] pavc = np.zeros(arr_size, dtype=DTYPE)\n    cdef np.ndarray[float, ndim=1] uaps = np.zeros(arr_size,dtype=np.float32)\n    cdef np.ndarray[float, ndim=1] puaps = np.zeros(arr_size,dtype=np.float32)\n    cdef np.ndarray[float, ndim=1] cucm = np.zeros(arr_size,dtype=np.float32)\n    cdef np.ndarray[float, ndim=1] pcucm = np.zeros(arr_size,dtype=np.float32)\n    cdef np.ndarray[long, ndim=1] lct = np.zeros(arr_size, dtype=long)\n    cdef np.ndarray[long, ndim=1] lit = np.zeros(arr_size, dtype=long)\n    cdef np.ndarray[float, ndim=1] like = np.zeros(arr_size, dtype=np.float32)\n    cdef np.ndarray[float, ndim=1] dislike = np.zeros(arr_size, dtype=np.float32)\n    cdef int cnt, i, j\n    cdef np.ndarray[long, ndim=1] row\n    #                                0             1              2                3                     4           5            6                7                     \n    for cnt,row in enumerate(df[['user_id','answered_correctly','part','answered_correctly_avg_c','content_id','user_answer','timestamp','correct_answer']].values):\n        acsu[cnt] = answered_correctly_sum_u_dict[row[0]]\n        accu[cnt] = answered_correctly_cumsum_u_dict[row[0]]\n        aicu[cnt] = answered_incorrectly_cumsum_u_dict[row[0]]\n        paccu[cnt] = parts_answered_correctly_cumsum_u_dict[row[2]][row[0]]\n        paicu[cnt] = parts_answered_incorrectly_cumsum_u_dict[row[2]][row[0]]\n        cu[cnt] = count_u_dict[row[0]]\n        adsu[cnt] = answered_diff_sum_u_dict[row[0]]\n        avcu[cnt] = avg_c_sum_u_dict[row[0]]\n        uaps[cnt] = user_answer_per_sum_dict[row[0]]\n        lct[cnt] = row[6] - last_correct_timestamp_dict[row[0]]\n        lit[cnt] = row[6] - last_incorrect_timestamp_dict[row[0]]\n\n        if row[2] == 1:\n            if (row[6] == 0) or (dict_sub(answered_correctly_sum_u_dict[row[0]] ,count_u_dict[row[0]])==0):\n                like[cnt] = np.nan\n                dislike[cnt] = np.nan\n            else:\n                like[cnt] = like_answer_three_dict[row[7]][row[0]] / dict_sub(cu[cnt] ,acsu[cnt])\n                dislike[cnt] = dislike_answer_three_dict[row[7]][row[0]] / dict_sub(cu[cnt] ,acsu[cnt])\n        else:\n            if (row[6] == 0) or (dict_sub(answered_correctly_sum_u_dict[row[0]] , count_u_dict[row[0]])==0):\n                like[cnt] = np.nan\n                dislike[cnt] = np.nan\n            else:\n                like[cnt] = like_answer_dict[row[7]][row[0]] / dict_sub(cu[cnt] , acsu[cnt])\n                dislike[cnt] = dislike_answer_dict[row[7]][row[0]] / dict_sub(cu[cnt] , acsu[cnt])\n        if content_correct_count_dict[row[4]] > 0:\n            cucm[cnt] = content_correct_user_mean_dict[row[4]] / content_correct_count_dict[row[4]]\n            pcucm[cnt] = parts_content_correct_user_mean_dict[row[4]] / content_correct_count_dict[row[4]]\n        for i in range(7):\n            ptu[cnt,i] = parts_u_dict[i][row[0]]\n            ptcu[cnt,i] = parts_count_u_dict[i][row[0]]\n            if i == row[2]:\n                pavc[cnt] = parts_avg_c_dict[i][row[0]] / dict_sum(parts_count_u_dict[i][row[0]] , 1)\n                parts_avg_c_dict[i][row[0]] = dict_sum(parts_avg_c_dict[row[2]][row[0]],row[3])\n                \n        if ptcu[cnt,row[2]] != 0:\n            puaps[cnt] = parts_user_answer_per_sum_dict[row[2]][row[0]] / ptcu[cnt,row[2]]\n        \n        if row[1] == 1:\n            answered_correctly_sum_u_dict[row[0]] = dict_sum(answered_correctly_sum_u_dict[row[0]],1)\n            answered_correctly_cumsum_u_dict[row[0]] = dict_sum(answered_correctly_cumsum_u_dict[row[0]],1)\n            answered_incorrectly_cumsum_u_dict[row[0]] = 0\n            last_correct_timestamp_dict[row[0]] = row[6]\n            parts_answered_correctly_cumsum_u_dict[row[2]][row[0]] = dict_sum(parts_answered_correctly_cumsum_u_dict[row[2]][row[0]],1)\n            parts_answered_incorrectly_cumsum_u_dict[row[2]][row[0]] = 0\n        else:\n            answered_correctly_cumsum_u_dict[row[0]] = 0\n            answered_incorrectly_cumsum_u_dict[row[0]] = dict_sum(answered_incorrectly_cumsum_u_dict[row[0]],1)\n            last_incorrect_timestamp_dict[row[0]] = row[6]\n            parts_answered_correctly_cumsum_u_dict[row[2]][row[0]] = 0\n            parts_answered_incorrectly_cumsum_u_dict[row[2]][row[0]] = dict_sum(parts_answered_incorrectly_cumsum_u_dict[row[2]][row[0]],1) \n            if row[2] == 1:\n                #answer0,1,3\n                like_answer_three_dict[row[5]][row[0]] = dict_sum(like_answer_three_dict[row[5]][row[0]],1)\n                for j in [0,1,3]:\n                    if row[5] != j:\n                        dislike_answer_three_dict[j][row[0]] = dict_sum(dislike_answer_three_dict[j][row[0]],1)\n            else:\n                like_answer_dict[row[5]][row[0]] = dict_sum(like_answer_dict[row[5]][row[0]],1)\n                for j in [0,1,2,3]:\n                    if row[5] != j:\n                        dislike_answer_dict[j][row[0]] = dict_sum(dislike_answer_dict[j][row[0]],1)\n            \n            \n            \n        answered_diff_sum_u_dict[row[0]] = dict_sum(answered_diff_sum_u_dict[row[0]],abs(row[3] - (row[1] * 100)))\n        count_u_dict[row[0]] = dict_sum(count_u_dict[row[0]],1)\n        avg_c_sum_u_dict[row[0]] = dict_sum(avg_c_sum_u_dict[row[0]],row[3])\n        \n        if row[4] in answer_per_dict[row[5]]:\n            user_answer_per_sum_dict[row[0]] = user_answer_per_sum_dict[row[0]] + answer_per_dict[row[5]][row[4]]\n            parts_user_answer_per_sum_dict[row[2]][row[0]] = parts_user_answer_per_sum_dict[row[2]][row[0]] + answer_per_dict[row[5]][row[4]]\n        else:\n            user_answer_per_sum_dict[row[0]] = user_answer_per_sum_dict[row[0]] + 0.33\n            parts_user_answer_per_sum_dict[row[2]][row[0]] = parts_user_answer_per_sum_dict[row[2]][row[0]] + 0.33\n       \n        parts_u_dict[row[2]][row[0]] = dict_sum(parts_u_dict[row[2]][row[0]],row[1])\n        parts_count_u_dict[row[2]][row[0]] = dict_sum(parts_count_u_dict[row[2]][row[0]],1)\n        \n        if row[1] == 1:\n            content_correct_count_dict[row[4]] =  dict_sum(content_correct_count_dict[row[4]],1)\n            content_correct_user_mean_dict[row[4]] = content_correct_user_mean_dict[row[4]] + (answered_correctly_sum_u_dict[row[0]] / count_u_dict[row[0]])\n            parts_content_correct_user_mean_dict[row[4]] = parts_content_correct_user_mean_dict[row[4]] + (parts_u_dict[row[2]][row[0]] / parts_count_u_dict[row[2]][row[0]])\n \n    df['answered_correctly_sum_u'] = acsu\n    df['answered_correctly_sum_u'] = df['answered_correctly_sum_u'].astype('uint16')\n    df['answered_cumsum_u'] = accu - aicu\n    df['answered_cumsum_u'] = df['answered_cumsum_u'].astype('int8')\n    df['part_answered_cumsum_u'] = paccu - paicu\n    df['part_answered_cumsum_u'] = df['part_answered_cumsum_u'].astype('int8')    \n    df['count_u'] = cu\n    df['count_u'] = df['count_u'].astype('uint16')\n    df['answered_correctly_avg_u'] = df['answered_correctly_sum_u'] / df['count_u']\n    df['answered_correctly_avg_u'] = df['answered_correctly_avg_u'].astype('float16')\n    df['answered_diff_mean'] = adsu  / cu\n    df['answered_diff_mean'] = df['answered_diff_mean'].astype('float16')\n    df['avg_c_mean'] = avcu / cu\n    df['avg_c_mean'] = df['avg_c_mean'].astype('float16')\n    df['part_avg_c_mean'] = pavc\n    df['part_avg_c_mean'] = df['part_avg_c_mean'].astype('uint8')\n    \n    df['avg_c_per_u'] = df['avg_c_mean'] / (df['answered_correctly_avg_u'] * 100)\n    df['avg_c_per_u'] = df['avg_c_per_u'].astype('float16')\n    \n    df['user_answer_per_mean'] = uaps\n    df['user_answer_per_mean'] = df['user_answer_per_mean']  / df['count_u']\n    df['user_answer_per_mean'] = df['user_answer_per_mean'].astype('float16')\n    \n    df['part_user_answer_per_mean']= puaps\n    df['part_user_answer_per_mean'] = df['part_user_answer_per_mean'].astype('float16')\n    \n    df['content_lv'] = cucm\n    df['content_lv'] = df['content_lv'].astype('float16')\n    df['part_content_lv'] = pcucm\n    df['part_content_lv'] = df['part_content_lv'].astype('float16')\n    df.loc[df['content_lv']==0,'content_lv']=0.5\n    df.loc[df['part_content_lv']==0,'part_content_lv']=0.5\n\n    df['last_correct_timelag'] = lct\n    df['last_correct_timelag'] = df['last_correct_timelag'].astype('uint32')\n    df['last_incorrect_timelag'] = lit\n    df['last_incorrect_timelag'] = df['last_incorrect_timelag'].astype('uint32')\n    \n    df['is_like_answer'] = like\n    df['is_like_answer'] = df['is_like_answer'].astype('float16')\n    df['is_dislike_answer'] = dislike\n    df['is_dislike_answer'] = df['is_dislike_answer'].astype('float16')\n    df['part_count_per'] = 0\n    df['lr_count_per'] = 0\n    cdef str pnum\n    for i in range(7):\n        pnum = str(i)\n        df['p' + pnum + '_count_u'] = ptcu[:,i]\n        df['p' + pnum + '_count_u'] = df['p' + pnum + '_count_u']\n        df['p' + pnum + '_count_u'] = df['p' + pnum + '_count_u'].astype('uint32')\n        df['p' + pnum + '_mean_u'] = ptu[:,i] / ptcu[:,i]\n        df['p' + pnum + '_mean_u']  = df['p' + pnum + '_mean_u'] * (df['p' + pnum + '_count_u'] / df['count_u'])\n        df['p' + pnum + '_mean_u'] = df['p' + pnum + '_mean_u'].astype('float16')\n        df.loc[df['part']==i,'part_count_per'] = df['p' + pnum + '_count_u'] / df['count_u']\n    df['part_count_per'] = df['part_count_per'].astype('float16')    \n    df.loc[df['part']<4,'lr_count_per'] = ((df['p0_count_u'] + df['p1_count_u'] + df['p2_count_u'] + df['p3_count_u']) / df['count_u'])\n    df.loc[df['part']>3,'lr_count_per'] = ((df['p4_count_u'] + df['p5_count_u'] + df['p6_count_u']) / df['count_u']).astype('float16')\n    df['lr_count_per'] = df['lr_count_per'].astype('float16')\n    df.replace([np.inf, -np.inf], np.nan,inplace=True)\n    return df\n\n@cython.boundscheck(False)\n@cython.wraparound(False)\n@cython.nonecheck(False)\ncdef int dict_sum(int a, int b):\n    return a + b\n@cython.boundscheck(False)\n@cython.wraparound(False)\n@cython.nonecheck(False)\ncdef int dict_sub(int a, int b):\n    return a - b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"%%cython\nimport cython\ncimport cython\nimport numpy as np\ncimport numpy as np\nimport pandas as pd\n\n@cython.boundscheck(False)\n@cython.wraparound(False)\n@cython.nonecheck(False)\ndef add_time_feats(df,time_u_dict,lect_u_dict):\n    cdef int arr_size = len(df)\n    cdef int cnt\n    cdef np.ndarray[long, ndim=1] row\n    cdef np.ndarray[long, ndim=1] tu = np.zeros(arr_size,dtype=long)\n    cdef np.ndarray[long, ndim=1] lc = np.zeros(arr_size,dtype=long)\n    for cnt,row in enumerate(df[['user_id','timestamp','content_type_id']].values):\n        if (row[1] - time_u_dict[row[0]]>0):\n            tu[cnt] = dict_sub(row[1],time_u_dict[row[0]])\n        elif (row[1] == 0):\n            tu[cnt] = 0\n        else:\n            tu[cnt] = tu[cnt - 1]\n        lc[cnt] = lect_u_dict[row[0]]\n        \n        time_u_dict[row[0]] = row[1]\n        if (row[2] == 1):\n            lect_u_dict[row[0]] = lect_u_dict[row[0]] + 1\n    \n    cdef int split = 60*60*24\n    cdef np.ndarray[long, ndim=1] tu_day = tu // split\n    cdef np.ndarray[long, ndim=1] tu_time = tu % split \n\n    df['lag_time'] = tu_time\n    df['lag_time'] = df['lag_time'].astype('uint16')\n    df['lag_day'] = tu_day\n    df['lag_day'] = df['lag_day'].astype('uint16')\n    df.loc[df['lag_day']>0,'lag_time'] = np.iinfo(np.uint16).max\n    df['lecture_count'] = lc\n    df.loc[df['lecture_count']>np.iinfo(np.uint8).max,'lecture_count'] = np.iinfo(np.uint8).max\n    df['lecture_count'] = df['lecture_count'].astype('uint8')\n    return df\n\n@cython.boundscheck(False)\n@cython.wraparound(False)\n@cython.nonecheck(False)\ndef update_time_feats(df,time_u_dict,lect_u_dict):\n    cdef int arr_size = len(df)\n    cdef int cnt\n    cdef np.ndarray[long, ndim=1] row\n    for cnt,row in enumerate(df[['user_id','timestamp','content_type_id']].values):\n        time_u_dict[row[0]] = row[1]\n        if (row[2] == 1):\n            lect_u_dict[row[0]] = lect_u_dict[row[0]] + 1\n            \n@cython.boundscheck(False)\n@cython.wraparound(False)\n@cython.nonecheck(False)\ncdef int dict_sub(long a, int b):\n    return a - b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df = questions_df.set_index('question_id')\nquestions_df.index.name = 'content_id'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#content_answer_per生成\ntrain = pd.read_pickle(train_pickle)[feld_needed]\ntrain = train.loc[train['content_type_id']==0][['content_id','user_answer']]\ntmp = train.groupby('content_id').count()\ntmp.rename(columns={'user_answer':'count'},inplace=True)\ntrain = pd.read_pickle(train_pickle)[feld_needed]\ntrain = train.loc[train['content_type_id']==0][['content_id','user_answer','content_type_id']]\ntmp2 = train.groupby(['content_id','user_answer']).count().reset_index()\ntmp2 = tmp2.merge(tmp,left_on='content_id',right_index=True,how='left')\ntmp2['answer_per'] = tmp2['content_type_id'] / tmp2['count']\ntmp2 = tmp2[['content_id','user_answer','answer_per']]\ntmp2['answer_per'].fillna(0.3,inplace=True)\nanswer_per_dict = {}\nfor i in range(4):\n    answer_per_dict[i] = tmp2.loc[tmp2['user_answer']==i].set_index('content_id')[['answer_per']].to_dict()['answer_per']\ndel train, tmp2, tmp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_pickle(train_pickle)[feld_needed]\nvalid = pd.read_pickle(valid_pickle)[feld_needed]\n# answered correctly average for each content\n# content_type_idが異なっていて同じコンテンツIDが存在する\ncontent_df = train.loc[train['content_type_id']==0][['content_id','answered_correctly']].groupby(['content_id']).agg(['mean']).reset_index()\ncontent_df.columns = ['content_id', 'answered_correctly_avg_c']\ncontent_df['answered_correctly_avg_c'] = (content_df['answered_correctly_avg_c'] * 100).astype(np.uint8)\ncontent_df = content_df.set_index('content_id')\ncontent_df.index.name = 'content_id'\n\nif debug:\n    train = train[:1000000]\n    valid = valid[:10000]\nelse:\n    #user_id split because user trace\n    #current active user trace \n    print('all =',train['row_id'].min(),train['row_id'].max())\n    train = train.sort_values('row_id')\n    train = train[int(len(train)/2):]\n    print('current =',train['row_id'].min(),train['row_id'].max())\n    users = np.random.choice(train['user_id'].unique(), int(len(train['user_id'].unique()) * 8 / 10), replace=True)\n\n    train = pd.read_pickle(train_pickle)[feld_needed]\n    train = train.loc[train['user_id'].isin(users)]\n\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%cython\nimport cython\ncimport cython\nimport numpy as np\ncimport numpy as np\nimport pandas as pd\n\n@cython.boundscheck(False)\n@cython.wraparound(False)\n@cython.nonecheck(False)\ndef data_format(df,questions_df,content_df,prior_question_elapsed_time_mean):\n    df['row_id'] = df['row_id'].astype('uint32')\n    df['user_id'] = df['user_id'].astype('int32')\n    df['content_type_id'] = df['content_type_id'].astype('uint8')\n    df.loc[df['content_type_id'] != 0,'content_id'] = 532 #暫定\n    df['content_id'] = df['content_id'].astype('uint16')\n    # changing dtype to avoid lightgbm error\n    df['prior_question_had_explanation'] = df.prior_question_had_explanation.fillna(False).astype('uint8')\n    df['prior_question_elapsed_time'] = df.prior_question_elapsed_time.fillna(prior_question_elapsed_time_mean)\n    df['prior_question_elapsed_time'] = (df['prior_question_elapsed_time'] / 1000).astype('uint16')\n    df['timestamp'] = (df['timestamp'] / 1000).astype(np.uint32)\n    # merge\n    df = pd.concat([df.reset_index(drop=True), questions_df.reindex(df['content_id'].values).reset_index(drop=True)], axis=1)\n    df = pd.concat([df.reset_index(drop=True), content_df.reindex(df['content_id'].values).reset_index(drop=True)], axis=1)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill with mean value for prior_question_elapsed_time\n# note that `train.prior_question_elapsed_time.mean()` dose not work!\n# please refer https://www.kaggle.com/its7171/can-we-trust-pandas-mean for detail.\nprior_question_elapsed_time_mean = train.prior_question_elapsed_time.dropna().values.mean()\n\ntrain = data_format(train,questions_df,content_df,prior_question_elapsed_time_mean)\nvalid = data_format(valid,questions_df,content_df,prior_question_elapsed_time_mean)\n\n# memory compaction\ntrain.loc[train['answered_correctly'] < 0,'answered_correctly'] = 0\ntrain['answered_correctly'] = train['answered_correctly'].astype('uint8')\ntrain['user_answer'] = train['user_answer'].astype('uint8')\nvalid.loc[valid['answered_correctly'] < 0,'answered_correctly'] = 0\nvalid['answered_correctly'] = valid['answered_correctly'].astype('uint8')\nvalid['user_answer'] = valid['user_answer'].astype('uint8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#経過時間(講義列も考慮)\n#train add_time_feats = 0:00:40.409987\n#valid add_time_feats = 0:00:03.369860\ntime_u_dict = defaultdict(int)\nlect_u_dict = defaultdict(int)\n\nstart = datetime.datetime.now()\ntrain = add_time_feats(train,time_u_dict,lect_u_dict)\nprint('train add_time_feats =',(datetime.datetime.now()- start))\nstart = datetime.datetime.now()\nvalid = add_time_feats(valid,time_u_dict,lect_u_dict)\nprint('valid add_time_feats =',(datetime.datetime.now()- start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.loc[train.content_type_id == False].reset_index(drop=True)\nvalid = valid.loc[valid.content_type_id == False].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"%%cython\nimport cython\ncimport cython\nimport numpy as np\ncimport numpy as np\nimport pandas as pd\n\nDTYPE = np.int32\nctypedef np.int32_t np_int_t\n\n@cython.boundscheck(False)\n@cython.wraparound(False)\n@cython.nonecheck(False)\ndef add_prior_feats(df, dict q_stats_dict,dict q_enc_tag_dict,\n                    prior_content_dict, prior_prior_content_dict, prior_time_dict, \n                    prior_time_per_sum_dict,\n                    prior_lag_dict, prior_prior_lag_dict,\n                    lag_sum_dict, prior_avg_c_dict, prior_prior_avg_c_dict,\n                    part_lag_sum_dict, prior_part_dict):\n    cdef int arr_size = len(df)\n    cdef int cnt\n    cdef np.ndarray[int, ndim=1] row\n    cdef np.ndarray[np_int_t, ndim=1] pc = np.zeros(arr_size,dtype=DTYPE)\n    cdef np.ndarray[np_int_t, ndim=1] ppc = np.zeros(arr_size,dtype=DTYPE)\n    cdef np.ndarray[np_int_t, ndim=1] eqtag = np.zeros(arr_size,dtype=DTYPE)\n    cdef np.ndarray[float, ndim=1] tp = np.zeros(arr_size,dtype=np.float32)\n    cdef np.ndarray[np_int_t, ndim=1] pt = np.zeros(arr_size,dtype=DTYPE)\n    cdef np.ndarray[np_int_t, ndim=1] ul = np.zeros(arr_size,dtype=DTYPE)\n    cdef np.ndarray[np_int_t, ndim=1] ull = np.zeros(arr_size,dtype=DTYPE)\n    #cdef np.ndarray[np_int_t, ndim=1] pe = np.zeros(arr_size,dtype=DTYPE)\n    cdef np.ndarray[np_int_t, ndim=1] ls = np.zeros(arr_size,dtype=DTYPE)\n    cdef np.ndarray[np_int_t, ndim=1] pac = np.zeros(arr_size,dtype=DTYPE)\n    #cdef np.ndarray[np_int_t, ndim=1] ppac = np.zeros(arr_size,dtype=DTYPE)\n    cdef np.ndarray[float, ndim=1] ptps = np.zeros(arr_size,dtype=np.float32)\n    cdef np.ndarray[np_int_t, ndim=1] pls = np.zeros(arr_size,dtype=DTYPE)\n    \n    for cnt,row in enumerate(df[['user_id','content_id','prior_question_elapsed_time','lag_time' ,'prior_question_had_explanation','answered_correctly_avg_c','part']].values):\n        ppc[cnt] = prior_prior_content_dict[row[0]]\n        pc[cnt] = prior_content_dict[row[0]]\n        if prior_prior_content_dict[row[0]] in q_stats_dict:\n            pt[cnt] = prior_time_dict[row[0]] / q_stats_dict[prior_prior_content_dict[row[0]]]\n        else:\n            pt[cnt] = 1\n        ls[cnt] = lag_sum_dict[row[0]]\n        pac[cnt] = prior_avg_c_dict[row[0]]\n        pls[cnt] = part_lag_sum_dict[row[6]][row[0]]\n        if (q_enc_tag_dict[pc[cnt]] == q_enc_tag_dict[row[1]]):\n            eqtag[cnt] = 1\n        else:\n            eqtag[cnt] = 0\n\n        if (prior_content_dict[row[0]] > 0) & (prior_content_dict[row[0]] in q_stats_dict):\n            tp[cnt] = row[2] / q_stats_dict[prior_content_dict[row[0]]]\n            prior_time_per_sum_dict[row[0]] = prior_time_per_sum_dict[row[0]] + tp[cnt]\n        else:\n            tp[cnt] = 1\n        ptps[cnt] = prior_time_per_sum_dict[row[0]]\n        \n        if prior_content_dict[row[0]] > 0:\n            prior_part_dict[row[0]] = row[6]\n            part_lag_sum_dict[prior_part_dict[row[0]]][row[0]] = part_lag_sum_dict[prior_part_dict[row[0]]][row[0]] + tp[cnt]\n        prior_prior_content_dict[row[0]] = prior_content_dict[row[0]]\n        prior_content_dict[row[0]] = row[1]\n        prior_time_dict[row[0]] = row[2] #1つ前のコンテンツの回答時間\n        ul[cnt] = prior_lag_dict[row[0]]\n        ull[cnt] = prior_prior_lag_dict[row[0]]\n        prior_prior_lag_dict[row[0]] = prior_lag_dict[row[0]]\n        prior_lag_dict[row[0]] = row[3]\n        lag_sum_dict[row[0]] = lag_sum_dict[row[0]] + row[3]\n        prior_prior_avg_c_dict[row[0]] = prior_avg_c_dict[row[0]]\n        prior_avg_c_dict[row[0]] = row[5]\n            \n    df['prior_content_id'] = pc\n    df['prior_content_id'] = df['prior_content_id'].astype('uint16')\n    df['prior_content_diff'] = df['content_id'] - df['prior_content_id'].astype('int16')\n    df['is_same_tags'] = eqtag\n    df.loc[df['prior_content_id'] == df['content_id'],'is_same_tags'] = df['is_same_tags'] + 2\n    df['is_same_tags'] = df['is_same_tags'].astype('uint8')\n    df['lag_time_per'] = df['lag_time'] / df['prior_question_elapsed_time'].astype('float32')\n    df['elapsed_lag_per'] = tp\n    df['elapsed_lag_per'] = df['elapsed_lag_per'].astype('float16')\n    df['elapsed_time_per_mean'] = ptps\n    df['elapsed_time_per_mean'] = df['elapsed_time_per_mean'].astype('float16')\n    \n    df['part_elapsed_time_per_mean'] = pls\n    df['part_elapsed_time_per_mean'] = df['part_elapsed_time_per_mean'].astype('float16')\n    \n    df['prior_prior_question_elapsed_time_per'] = pt\n    df['prior_prior_question_elapsed_time_per'] = df['prior_prior_question_elapsed_time_per'].astype('float16')\n    #df['prior_prior_question_had_explanation'] = pe\n    #df['prior_prior_question_had_explanation'] = df['prior_prior_question_had_explanation'].astype('uint8')\n    df['prior_prior_lag_time'] = ull\n    df['prior_prior_lag_time'] = df['prior_prior_lag_time'].astype('uint16')\n    df['prior_lag_time'] = ul\n    df['prior_lag_time'] = df['prior_lag_time'].astype('uint16')\n    df['lag_lag_time'] = df['lag_time'] / df['prior_lag_time']\n    df['lag_lag_time'] = df['lag_lag_time'].astype('float16')\n    df['lag_sum'] = ls\n    df['prior_avg_c'] = pac\n    df['prior_avg_c'] = df['prior_avg_c'].astype('uint8')\n    #df['prior_prior_avg_c'] = ppac\n    #df['prior_prior_avg_c'] = df['prior_prior_avg_c'].astype('uint8')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#q_stats_dict = pd.read_csv('../input/riiiddataset/question_stats.csv').set_index('content_id')[['q_elapsed_time_mean']].to_dict()['q_elapsed_time_mean']\n#correct answer only\nq_stats_dict = pd.read_csv('../input/riiiddataset/correct_q_elapsed_time_mean.csv').set_index('content_id')[['correct_q_elapsed_time_mean']].to_dict()['correct_q_elapsed_time_mean']\nq_enc_tag_dict = questions_df[['enc_tags']].to_dict()['enc_tags']\nq_ans_dict = questions_df[['correct_answer']].to_dict()['correct_answer']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#train add_prior_feats = 0:02:22.203537\n#valid add_prior_feats = 0:00:12.576596\n\nprior_content_dict = defaultdict(int)\nprior_prior_content_dict = defaultdict(int)\nprior_time_dict = defaultdict(int)\nprior_time_per_sum_dict = defaultdict(int)\nprior_lag_dict = defaultdict(int)\nprior_prior_lag_dict = defaultdict(int)\nlag_sum_dict = defaultdict(int)\nprior_avg_c_dict = defaultdict(int)\nprior_prior_avg_c_dict = defaultdict(int)\npart_lag_sum_dict = {}\nfor p in range(0,7):\n    part_lag_sum_dict[p] = defaultdict(int)\n\nprior_part_dict = defaultdict(int)\nstart = datetime.datetime.now()\ntrain = add_prior_feats(train,\n                        q_stats_dict,\n                        q_enc_tag_dict,\n                        prior_content_dict,\n                        prior_prior_content_dict,\n                        prior_time_dict,\n                        prior_time_per_sum_dict,\n                        prior_lag_dict,\n                        prior_prior_lag_dict,\n                        lag_sum_dict,\n                        prior_avg_c_dict,\n                        prior_prior_avg_c_dict,\n                        part_lag_sum_dict,\n                        prior_part_dict)\nprint('train add_prior_feats =',(datetime.datetime.now()- start))\nstart = datetime.datetime.now()\nvalid = add_prior_feats(valid,\n                        q_stats_dict,\n                        q_enc_tag_dict,\n                        prior_content_dict,\n                        prior_prior_content_dict,\n                        prior_time_dict,\n                        prior_time_per_sum_dict,\n                        prior_lag_dict,\n                        prior_prior_lag_dict,\n                        lag_sum_dict,\n                        prior_avg_c_dict,\n                        prior_prior_avg_c_dict,\n                        part_lag_sum_dict,\n                        prior_part_dict)\nprint('valid add_prior_feats =',(datetime.datetime.now()- start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#train add_user_feats = 0:05:06.433533\n#valid add_user_feats = 0:00:27.512900\n#正解数\nanswered_correctly_sum_u_dict = defaultdict(int)\n#連続正答数\nanswered_correctly_cumsum_u_dict = defaultdict(int)\n#連続不正解\nanswered_incorrectly_cumsum_u_dict = defaultdict(int)\n#回答数\ncount_u_dict = defaultdict(int)\n#パート回答数\nparts_count_u_dict = {}\nparts_u_dict = {}\nparts_avg_c_dict = {}\nparts_user_answer_per_sum_dict = {}\nparts_answered_correctly_cumsum_u_dict = {}\nparts_answered_incorrectly_cumsum_u_dict = {}\nfor p in range(0,7):\n    parts_u_dict[p] = defaultdict(int)\n    parts_count_u_dict[p] = defaultdict(int)\n    parts_avg_c_dict[p] = defaultdict(int)\n    parts_user_answer_per_sum_dict[p] = defaultdict(int)\n    parts_answered_correctly_cumsum_u_dict[p] = defaultdict(int)\n    parts_answered_incorrectly_cumsum_u_dict[p] = defaultdict(int)\n    \n#回答期待値との差\nanswered_diff_sum_u_dict = defaultdict(int)\navg_c_sum_u_dict = defaultdict(int)\nuser_answer_per_sum_dict = defaultdict(int)\n\ncontent_correct_user_mean_dict = defaultdict(int)\ncontent_correct_count_dict = defaultdict(int)\nparts_content_correct_user_mean_dict = defaultdict(int)\n\nlast_correct_timestamp_dict = defaultdict(int)\nlast_incorrect_timestamp_dict = defaultdict(int)\n\nlike_answer_dict = {}\nlike_answer_three_dict = {}\ndislike_answer_dict = {}\ndislike_answer_three_dict = {}\nfor p in range(0,4):\n    like_answer_dict[p] = defaultdict(int)\n    like_answer_three_dict[p] = defaultdict(int)\n    dislike_answer_dict[p] = defaultdict(int)\n    dislike_answer_three_dict[p] = defaultdict(int)\n\nstart = datetime.datetime.now()\ntrain = add_user_feats(train,\n                       answer_per_dict,\n                       answered_correctly_sum_u_dict, \n                       answered_correctly_cumsum_u_dict,\n                       answered_incorrectly_cumsum_u_dict,\n                       count_u_dict,\n                       parts_u_dict,\n                       parts_count_u_dict,\n                       answered_diff_sum_u_dict,\n                       avg_c_sum_u_dict,\n                       parts_avg_c_dict,\n                       user_answer_per_sum_dict,\n                       parts_user_answer_per_sum_dict,\n                       content_correct_user_mean_dict,\n                       content_correct_count_dict,\n                       parts_content_correct_user_mean_dict,\n                       last_correct_timestamp_dict,\n                       last_incorrect_timestamp_dict,\n                       like_answer_dict,\n                       like_answer_three_dict,\n                       dislike_answer_dict,\n                       dislike_answer_three_dict,\n                       parts_answered_correctly_cumsum_u_dict,\n                       parts_answered_incorrectly_cumsum_u_dict)\n\nprint('train add_user_feats =',(datetime.datetime.now() - start))\n\nstart = datetime.datetime.now()\nvalid = add_user_feats(valid,\n                       answer_per_dict,\n                       answered_correctly_sum_u_dict,\n                       answered_correctly_cumsum_u_dict,\n                       answered_incorrectly_cumsum_u_dict,\n                       count_u_dict,\n                       parts_u_dict,\n                       parts_count_u_dict,\n                       answered_diff_sum_u_dict,\n                       avg_c_sum_u_dict,\n                       parts_avg_c_dict,\n                       user_answer_per_sum_dict,\n                       parts_user_answer_per_sum_dict,\n                       content_correct_user_mean_dict,\n                       content_correct_count_dict,\n                       parts_content_correct_user_mean_dict,\n                       last_correct_timestamp_dict,\n                       last_incorrect_timestamp_dict,\n                       like_answer_dict,\n                       like_answer_three_dict,\n                       dislike_answer_dict,\n                       dislike_answer_three_dict,\n                       parts_answered_correctly_cumsum_u_dict,\n                       parts_answered_incorrectly_cumsum_u_dict)\nprint('valid add_user_feats =',(datetime.datetime.now() - start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%cython\nimport cython\ncimport cython\nimport numpy as np\ncimport numpy as np\nimport pandas as pd\n\nDTYPE = np.int32\nctypedef np.int32_t np_int_t\n\n@cython.boundscheck(False)\n@cython.wraparound(False)\n@cython.nonecheck(False)\ndef add_user_content_feats(df, user_content_dict, user_tags_dict, user_repeat_count_dict):\n    cdef int arr_size = len(df)\n    cdef int cnt,i\n    cdef np.ndarray[np_int_t, ndim=1] row\n    cdef np.ndarray[np_int_t, ndim=1] uc = np.zeros(arr_size,dtype=DTYPE)\n    cdef np.ndarray[np_int_t, ndim=1] rc = np.zeros(arr_size,dtype=DTYPE)\n    for cnt,row in enumerate(df[['user_id','content_id','answered_correctly','enc_tags','part']].values):\n        if (row[1] in user_content_dict[row[0]]):\n            uc[cnt] = user_content_dict[row[0]][row[1]]\n        else:\n            uc[cnt] = 0\n        if (row[3] in user_tags_dict[row[0]]):\n            uc[cnt] = uc[cnt] + (user_tags_dict[row[0]][row[3]] * 2)\n\n        rc[cnt] = user_repeat_count_dict[row[4]][row[0]]\n        \n        if row[2] == 0:\n            user_content_dict[row[0]][row[1]] = 1\n            user_tags_dict[row[0]][row[3]] = 1\n        else:\n            user_content_dict[row[0]][row[1]] = 2\n            user_tags_dict[row[0]][row[3]] = 2\n            \n        if row[1] in user_content_dict[row[0]]:\n            if not row[0] in user_repeat_count_dict[row[4]]:\n                user_repeat_count_dict[row[4]][row[0]] = 0\n            user_repeat_count_dict[row[4]][row[0]] = user_repeat_count_dict[row[4]][row[0]] + 1\n    df['done_content_tag'] = uc\n    df['done_content_tag'] = df['done_content_tag'].astype('uint8')\n    df['repeat_part_per'] = rc\n    df['repeat_part_per'] = df['repeat_part_per'].astype('uint16')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#回答数\nuser_content_dict = defaultdict(dict)\nuser_tags_dict = defaultdict(dict)\nuser_repeat_count_dict = {}\nfor p in range(0,7):\n    user_repeat_count_dict[p] = defaultdict(int)\nstart = datetime.datetime.now()\ntrain = add_user_content_feats(train, user_content_dict, user_tags_dict, user_repeat_count_dict)\nprint('train add_user_content_feats =',(datetime.datetime.now() - start))\nstart = datetime.datetime.now()\nvalid = add_user_content_feats(valid, user_content_dict, user_tags_dict, user_repeat_count_dict)\nprint('valid add_user_content_feats =',(datetime.datetime.now() - start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%cython\nimport cython\ncimport cython\nimport numpy as np\ncimport numpy as np\nimport pandas as pd\n\n@cython.boundscheck(False)\n@cython.wraparound(False)\n@cython.nonecheck(False)\ndef post_round(df,list use_tags,list use_content):\n    df.loc[~df['enc_tags'].isin(use_tags),'enc_tags'] = 65535\n    df.loc[~df['content_id'].isin(use_content),'content_id'] = 532 #暫定\n    return df\n\n@cython.boundscheck(False)\n@cython.wraparound(False)\n@cython.nonecheck(False)\ndef post_features(df):\n    cdef int i\n    df['lag_mean'] = (df['lag_sum'] / df['count_u'])\n    df.loc[df['lag_mean'] > 65535,'lag_mean'] = 65535\n    df['lag_mean'] = df['lag_mean'].astype('float16')\n    \n    df['elapsed_time_per_mean'] = df['elapsed_time_per_mean'] / df['count_u']\n    df['elapsed_time_per_mean'].fillna(1,inplace=True)\n    df['elapsed_time_per_mean'] = df['elapsed_time_per_mean'].astype('float16')\n    \n    cdef list parts = list(df['part'].unique())\n    for i in parts:\n        df.loc[df['part']==i,'part_elapsed_time_per_mean'] = df['part_elapsed_time_per_mean'] / df['p' + str(i) + '_count_u']\n        df.loc[df['p' +str(i)  + '_count_u']>0,'repeat_part_per'] = df['repeat_part_per'] / df['p' +str(i)  + '_count_u']\n    \n    df['part_elapsed_time_per_mean'].fillna(1,inplace=True)\n    df.loc[df['part_elapsed_time_per_mean'] ==0,'part_elapsed_time_per_mean'] = 1\n    df.loc[df['part_user_answer_per_mean'] == 0, 'part_user_answer_per_mean'] = np.nan\n    df['repeat_part_per'] = df['repeat_part_per'].astype('float16')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cat round\nround_max = np.iinfo(np.uint16).max\n\nuse_tags = list(train['enc_tags'].value_counts()[train['enc_tags'].value_counts()>3].index)\nuse_content = list(train['content_id'].value_counts()[train['content_id'].value_counts()>3].index)\n\ntrain = post_round(train,use_tags,use_content)\nvalid = post_round(valid,use_tags,use_content)\n\ntrain = post_features(train)\nvalid = post_features(valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"print(train.info())\nprint(train.memory_usage(deep=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train,valid\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## modeling"},{"metadata":{},"cell_type":"markdown","source":"### Stack All Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"if build == True:\n    #経過時間\n    time_u_dict= defaultdict(int)\n    lect_u_dict = defaultdict(int)\n    prior_content_dict = defaultdict(int)\n\n    #正解数\n    answered_correctly_sum_u_dict = defaultdict(int)\n    #連続正答数\n    answered_correctly_cumsum_u_dict = defaultdict(int)\n    #連続不正解\n    answered_incorrectly_cumsum_u_dict = defaultdict(int)\n    #回答数\n    count_u_dict = defaultdict(int)\n    #パート回答数\n    parts_count_u_dict = {}\n    parts_u_dict = {}\n    parts_avg_c_dict = {}\n    parts_user_answer_per_sum_dict = {}\n    part_lag_sum_dict = {}\n    parts_answered_correctly_cumsum_u_dict = {}\n    parts_answered_incorrectly_cumsum_u_dict = {}\n    user_repeat_count_dict = {}\n    for p in range(0,7):\n        parts_u_dict[p] = defaultdict(int)\n        parts_count_u_dict[p] = defaultdict(int)\n        parts_avg_c_dict[p] = defaultdict(int)\n        parts_user_answer_per_sum_dict[p] = defaultdict(int)\n        part_lag_sum_dict[p] = defaultdict(int)\n        parts_answered_correctly_cumsum_u_dict[p] = defaultdict(int)\n        parts_answered_incorrectly_cumsum_u_dict[p] = defaultdict(int)\n        user_repeat_count_dict[p] = defaultdict(int)\n    answered_diff_sum_u_dict = defaultdict(int)\n    avg_c_sum_u_dict= defaultdict(int)\n    user_answer_per_sum_dict = defaultdict(int)\n    user_content_dict = defaultdict(dict)\n    user_tags_dict = defaultdict(dict)\n    prior_lag_dict = defaultdict(int)\n    prior_prior_lag_dict = defaultdict(int)\n    prior_time_dict = defaultdict(int)\n    prior_time_per_sum_dict = defaultdict(int)\n    lag_sum_dict = defaultdict(int)\n    prior_avg_c_dict = defaultdict(int)\n    prior_prior_avg_c_dict = defaultdict(int)\n    prior_part_dict = defaultdict(int)\n    content_correct_user_mean_dict = defaultdict(int)\n    content_correct_count_dict = defaultdict(int)\n    parts_content_correct_user_mean_dict = defaultdict(int)\n    last_correct_timestamp_dict = defaultdict(int)\n    last_incorrect_timestamp_dict = defaultdict(int)\n    like_answer_dict = {}\n    like_answer_three_dict = {}\n    for p in range(0,4):\n        like_answer_dict[p] = defaultdict(int)\n        like_answer_three_dict[p] = defaultdict(int)\n    # OOM \n    for n, train_part in enumerate(pd.read_csv('../input/riiid-test-answer-prediction/train.csv', chunksize=10**7, iterator=True)):\n        start = datetime.datetime.now()\n        train_part = train_part[feld_needed]\n        train_part = data_format(train_part,questions_df,content_df,prior_question_elapsed_time_mean)\n        del train_part['row_id']\n        train_part.loc[train_part['answered_correctly'] < 0,'answered_correctly'] = 0\n        train_part['answered_correctly'] = train_part['answered_correctly'].astype('uint8')\n        train_part['user_answer'] = train_part['user_answer'].astype('uint8')\n        train_part = add_time_feats(train_part,time_u_dict,lect_u_dict)\n        train_part = train_part.loc[train_part.content_type_id == False].reset_index(drop=True)\n        del train_part['content_type_id']\n        _=gc.collect()\n        train_part = add_prior_feats(train_part,\n                                     q_stats_dict,\n                                     q_enc_tag_dict,\n                                     prior_content_dict,\n                                     prior_prior_content_dict,\n                                     prior_time_dict,\n                                     prior_time_per_sum_dict,\n                                     prior_lag_dict,\n                                     prior_prior_lag_dict,\n                                     lag_sum_dict,\n                                     prior_avg_c_dict,\n                                     prior_prior_avg_c_dict,\n                                     part_lag_sum_dict,\n                                     prior_part_dict)\n        \n        train_part = add_user_feats(train_part,\n                       answer_per_dict,\n                       answered_correctly_sum_u_dict, \n                       answered_correctly_cumsum_u_dict,\n                       answered_incorrectly_cumsum_u_dict,\n                       count_u_dict,\n                       parts_u_dict,\n                       parts_count_u_dict,\n                       answered_diff_sum_u_dict,\n                       avg_c_sum_u_dict,\n                       parts_avg_c_dict,\n                       user_answer_per_sum_dict,\n                       parts_user_answer_per_sum_dict,\n                       content_correct_user_mean_dict,\n                       content_correct_count_dict,\n                       parts_content_correct_user_mean_dict,\n                       last_correct_timestamp_dict,\n                       last_incorrect_timestamp_dict,\n                       like_answer_dict,\n                       like_answer_three_dict,\n                       dislike_answer_dict,\n                       dislike_answer_three_dict,\n                       parts_answered_correctly_cumsum_u_dict,\n                       parts_answered_incorrectly_cumsum_u_dict)\n        add_user_content_feats(train_part, user_content_dict, user_tags_dict,user_repeat_count_dict)\n        del train_part\n        print('train add_feats =',(datetime.datetime.now() - start), n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if True == True:\n    with open('time_u_dict.pickle', 'wb') as f:\n        pickle.dump(time_u_dict, f)\n\n    with open('prior_content_dict.pickle', 'wb') as f:\n        pickle.dump(prior_content_dict, f)\n        \n    with open('prior_prior_content_dict.pickle', 'wb') as f:\n        pickle.dump(prior_prior_content_dict, f)\n    \n    with open('answered_correctly_sum_u_dict', 'wb') as f:\n        pickle.dump(answered_correctly_sum_u_dict, f)  \n        \n    with open('answered_correctly_cumsum_u_dict.pickle', 'wb') as f:\n        pickle.dump(answered_correctly_cumsum_u_dict, f) \n        \n    with open('answered_incorrectly_cumsum_u_dict.pickle', 'wb') as f:\n        pickle.dump(answered_incorrectly_cumsum_u_dict, f) \n        \n    with open('count_u_dict', 'wb') as f:\n        pickle.dump(count_u_dict, f)\n        \n    with open('parts_count_u_dict.pickle', 'wb') as f:\n        pickle.dump(parts_count_u_dict, f)\n        \n    with open('parts_u_dict.pickle', 'wb') as f:\n        pickle.dump(parts_u_dict, f)\n        \n    with open('answered_diff_sum_u_dict.pickle', 'wb') as f:\n        pickle.dump(answered_diff_sum_u_dict, f)\n        \n    with open('user_content_dict.pickle','wb') as f:\n        pickle.dump(user_content_dict, f)\n        \n    with open('user_tags_dict.pickle','wb') as f:\n        pickle.dump(user_tags_dict, f)\n        \n    with open('prior_lag_dict.pickle','wb') as f:\n        pickle.dump(prior_lag_dict, f)\n    \n    with open('prior_prior_lag_dict.pickle','wb') as f:\n        pickle.dump(prior_prior_lag_dict, f)\n        \n    with open('prior_time_dict.pickle','wb') as f:\n        pickle.dump(prior_time_dict, f)\n        \n    with open('prior_time_per_sum_dict.pickle','wb') as f:\n        pickle.dump(prior_time_per_sum_dict, f)\n    \n    with open('part_lag_sum_dict.pickle','wb') as f:\n        pickle.dump(part_lag_sum_dict, f)\n    \n    with open('prior_part_dict.pickle','wb') as f:\n        pickle.dump(prior_part_dict, f)\n    \n    with open('lag_sum_dict.pickle','wb') as f:\n        pickle.dump(lag_sum_dict, f)\n        \n    with open('avg_c_sum_u_dict.pickle','wb') as f:\n        pickle.dump(avg_c_sum_u_dict, f)\n    \n    with open('user_answer_per_sum_dict.pickle','wb') as f:\n        pickle.dump(user_answer_per_sum_dict, f)\n    \n    with open('parts_user_answer_per_sum_dict.pickle','wb') as f:\n        pickle.dump(parts_user_answer_per_sum_dict, f)\n    \n    with open('content_correct_user_mean_dict.pickle','wb') as f:\n        pickle.dump(content_correct_user_mean_dict, f)\n        \n    with open('content_correct_count_dict.pickle','wb') as f:\n        pickle.dump(content_correct_count_dict, f)\n        \n    with open('parts_content_correct_user_mean_dict.pickle','wb') as f:\n        pickle.dump(parts_content_correct_user_mean_dict, f)\n    \n    with open('prior_avg_c_dict.pickle','wb') as f:\n        pickle.dump(prior_avg_c_dict, f)\n\n    with open('prior_prior_avg_c_dict.pickle','wb') as f:\n        pickle.dump(prior_prior_avg_c_dict, f)\n        \n    with open('parts_avg_c_dict.pickle','wb') as f:\n        pickle.dump(parts_avg_c_dict, f)\n    \n    with open('lect_u_dict.pickle','wb') as f:\n        pickle.dump(lect_u_dict, f)\n        \n    with open('last_correct_timestamp_dict.pickle','wb') as f:\n        pickle.dump(last_correct_timestamp_dict,f)\n      \n    with open('last_incorrect_timestamp_dict.pickle','wb') as f:\n        pickle.dump(last_incorrect_timestamp_dict,f)\n        \n    with open('like_answer_dict.pickle','wb') as f:\n        pickle.dump(like_answer_dict,f)\n        \n    with open('like_answer_three_dict.pickle','wb') as f:\n        pickle.dump(like_answer_three_dict,f)\n    \n    with open('dislike_answer_dict.pickle','wb') as f:\n        pickle.dump(dislike_answer_dict,f)\n        \n    with open('dislike_answer_three_dict.pickle','wb') as f:\n        pickle.dump(dislike_answer_three_dict,f) \n        \n    with open('parts_answered_correctly_cumsum_u_dict.pickle','wb') as f:\n        pickle.dump(parts_answered_correctly_cumsum_u_dict, f)\n        \n    with open('parts_answered_incorrectly_cumsum_u_dict.pickle','wb') as f:\n        pickle.dump(parts_answered_incorrectly_cumsum_u_dict, f)\n        \n    with open('user_repeat_count_dict.pickle','wb') as f:\n        pickle.dump(user_repeat_count_dict, f)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}