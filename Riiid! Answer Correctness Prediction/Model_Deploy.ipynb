{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Deploy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbjI8I0QC5Zb"
      },
      "source": [
        "モデル生成用ノートブック  \r\n",
        "LB0.794 PB0.796位だったと思います"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONLr9jBWqiyL"
      },
      "source": [
        "%load_ext Cython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaB-iVHjAFvO"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import gc\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from collections import defaultdict\r\n",
        "import lightgbm as lgb\r\n",
        "import pickle\r\n",
        "import datetime\r\n",
        "import collections\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "import random\r\n",
        "import os\r\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHh3v2-dAIRL"
      },
      "source": [
        "def seed_everything(seed: int):\r\n",
        "    random.seed(seed)\r\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\r\n",
        "    np.random.seed(seed)\r\n",
        "\r\n",
        "seed_everything(707)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrTvwTmHAJyb"
      },
      "source": [
        "train_pickle = '../input/riiid-cross-validation-files/cv1_train.pickle'\r\n",
        "valid_pickle = '../input/riiid-cross-validation-files/cv1_valid.pickle'\r\n",
        "question_file = '../input/riiid-test-answer-prediction/questions.csv'\r\n",
        "debug = False\r\n",
        "build = True\r\n",
        "root = '../input/base-0794-20201224output/'\r\n",
        "\r\n",
        "# read data\r\n",
        "feld_needed = ['row_id','timestamp', 'user_id', 'content_id', 'content_type_id', 'answered_correctly', 'prior_question_elapsed_time', 'prior_question_had_explanation','user_answer']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnnitOa3ALWk"
      },
      "source": [
        "# Transform tags into lists of ints:\r\n",
        "questions_df = pd.read_csv(question_file)\r\n",
        "questions_df['part'] = (questions_df['part'] - 1).astype('uint8')\r\n",
        "questions_df['correct_answer'] = questions_df['correct_answer'].astype('uint8')\r\n",
        "questions_df['tags'] = questions_df['tags'].apply(lambda ts: [int(x) for x in str(ts).split() if x != 'nan'])\r\n",
        "\r\n",
        "tag_rank = []\r\n",
        "tag_columns = []\r\n",
        "tag_to_questions = {}\r\n",
        "for i, row in questions_df.iterrows():\r\n",
        "    for t in row['tags']:\r\n",
        "        tag_rank.append(t)\r\n",
        "        if t not in tag_to_questions:\r\n",
        "            tag_to_questions[t] = set()\r\n",
        "        tag_to_questions[t].add(row['question_id'])\r\n",
        "tags_df = pd.DataFrame([{'tag':t,'questions':qs}for t,qs in tag_to_questions.items()])\r\n",
        "tag_rank, counts = zip(*collections.Counter(tag_rank).most_common(1))\r\n",
        "print(tag_rank)\r\n",
        "for t in tag_rank:\r\n",
        "    tag_columns.append('tags_' + str(t))\r\n",
        "    for i in range(len(questions_df)):\r\n",
        "        if t in questions_df.iloc[i]['tags']:\r\n",
        "            questions_df.at[i,'tags_' + str(t)] = 1\r\n",
        "        else:\r\n",
        "            questions_df.at[i,'tags_' + str(t)] = 0\r\n",
        "    questions_df['tags_' + str(t)] = questions_df['tags_' + str(t)].astype('uint8')\r\n",
        "\r\n",
        "del questions_df['bundle_id']\r\n",
        "print(tag_columns)\r\n",
        "\r\n",
        "le = LabelEncoder()\r\n",
        "encoded = le.fit_transform(questions_df['tags'].astype(str))\r\n",
        "decoded = le.inverse_transform(encoded)\r\n",
        "questions_df['enc_tags'] = encoded.astype('uint16')\r\n",
        "del questions_df['tags'], le\r\n",
        "questions_df = questions_df.set_index('question_id')\r\n",
        "questions_df.index.name = 'content_id'\r\n",
        "\r\n",
        "questions_df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fsML6qvAc-j"
      },
      "source": [
        "train = pd.read_pickle(train_pickle)[feld_needed]\r\n",
        "valid = pd.read_pickle(valid_pickle)[feld_needed]\r\n",
        "tmp = pd.concat([train[['content_type_id','content_id','answered_correctly']],valid[['content_type_id','content_id','answered_correctly']]])\r\n",
        "content_df = tmp.loc[tmp['content_type_id']==0][['content_id','answered_correctly']].groupby(['content_id']).agg(['mean']).reset_index()\r\n",
        "content_df.columns = ['content_id', 'answered_correctly_avg_c']\r\n",
        "content_df['answered_correctly_avg_c'] = (content_df['answered_correctly_avg_c'] * 100).astype(np.uint8)\r\n",
        "content_df = content_df.set_index('content_id')\r\n",
        "content_df.index.name = 'content_id'\r\n",
        "content_df.to_csv('content_df.csv')\r\n",
        "del content_df,tmp,train,valid\r\n",
        "_=gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxqoxB9iAeT8"
      },
      "source": [
        "%%cython\r\n",
        "import cython\r\n",
        "cimport cython\r\n",
        "import numpy as np\r\n",
        "cimport numpy as np\r\n",
        "import pandas as pd\r\n",
        "import gc\r\n",
        "\r\n",
        "DTYPE = np.int32\r\n",
        "ctypedef np.int32_t np_int_t\r\n",
        "#dict\r\n",
        "@cython.boundscheck(False)\r\n",
        "@cython.wraparound(False)\r\n",
        "@cython.nonecheck(False)\r\n",
        "def add_user_feats(df, \r\n",
        "                   answer_per_dict,\r\n",
        "                   answered_correctly_sum_u_dict,\r\n",
        "                   answered_correctly_cumsum_u_dict,\r\n",
        "                   answered_incorrectly_cumsum_u_dict,\r\n",
        "                   count_u_dict,\r\n",
        "                   parts_u_dict,\r\n",
        "                   parts_count_u_dict,\r\n",
        "                   answered_diff_sum_u_dict,\r\n",
        "                   avg_c_sum_u_dict,\r\n",
        "                   parts_avg_c_dict,\r\n",
        "                   user_answer_per_sum_dict,\r\n",
        "                   parts_user_answer_per_sum_dict,\r\n",
        "                   content_correct_user_mean_dict,\r\n",
        "                   content_correct_count_dict,\r\n",
        "                   parts_content_correct_user_mean_dict,\r\n",
        "                   last_correct_timestamp_dict,\r\n",
        "                   last_incorrect_timestamp_dict,\r\n",
        "                   like_answer_dict,\r\n",
        "                   like_answer_three_dict,\r\n",
        "                   dislike_answer_dict,\r\n",
        "                   dislike_answer_three_dict,\r\n",
        "                   parts_answered_correctly_cumsum_u_dict,\r\n",
        "                   parts_answered_incorrectly_cumsum_u_dict):\r\n",
        "    \r\n",
        "    cdef int arr_size = len(df)\r\n",
        "    \r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] acsu = np.zeros(arr_size, dtype=DTYPE)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] accu = np.zeros(arr_size, dtype=DTYPE)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] aicu = np.zeros(arr_size, dtype=DTYPE)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] cu = np.zeros(arr_size, dtype=DTYPE)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=2] ptu = np.zeros([arr_size,7], dtype=DTYPE)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=2] ptcu = np.zeros([arr_size,7], dtype=DTYPE)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] paccu = np.zeros(arr_size, dtype=DTYPE)#\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] paicu = np.zeros(arr_size, dtype=DTYPE)#\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] adsu = np.zeros(arr_size, dtype=DTYPE)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] avcu = np.zeros(arr_size, dtype=DTYPE)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] pavc = np.zeros(arr_size, dtype=DTYPE)\r\n",
        "    cdef np.ndarray[float, ndim=1] uaps = np.zeros(arr_size,dtype=np.float32)\r\n",
        "    cdef np.ndarray[float, ndim=1] puaps = np.zeros(arr_size,dtype=np.float32)\r\n",
        "    cdef np.ndarray[float, ndim=1] cucm = np.zeros(arr_size,dtype=np.float32)\r\n",
        "    cdef np.ndarray[float, ndim=1] pcucm = np.zeros(arr_size,dtype=np.float32)\r\n",
        "    cdef np.ndarray[long, ndim=1] lct = np.zeros(arr_size, dtype=long)\r\n",
        "    cdef np.ndarray[long, ndim=1] lit = np.zeros(arr_size, dtype=long)\r\n",
        "    cdef np.ndarray[float, ndim=1] like = np.zeros(arr_size, dtype=np.float32)\r\n",
        "    cdef np.ndarray[float, ndim=1] dislike = np.zeros(arr_size, dtype=np.float32)\r\n",
        "    cdef int cnt, i, j\r\n",
        "    cdef np.ndarray[long, ndim=1] row\r\n",
        "    #                                0             1              2                3                     4           5            6                7                     \r\n",
        "    for cnt,row in enumerate(df[['user_id','answered_correctly','part','answered_correctly_avg_c','content_id','user_answer','timestamp','correct_answer']].values):\r\n",
        "        acsu[cnt] = answered_correctly_sum_u_dict[row[0]]\r\n",
        "        accu[cnt] = answered_correctly_cumsum_u_dict[row[0]]\r\n",
        "        aicu[cnt] = answered_incorrectly_cumsum_u_dict[row[0]]\r\n",
        "        paccu[cnt] = parts_answered_correctly_cumsum_u_dict[row[2]][row[0]]\r\n",
        "        paicu[cnt] = parts_answered_incorrectly_cumsum_u_dict[row[2]][row[0]]\r\n",
        "        cu[cnt] = count_u_dict[row[0]]\r\n",
        "        adsu[cnt] = answered_diff_sum_u_dict[row[0]]\r\n",
        "        avcu[cnt] = avg_c_sum_u_dict[row[0]]\r\n",
        "        uaps[cnt] = user_answer_per_sum_dict[row[0]]\r\n",
        "        lct[cnt] = row[6] - last_correct_timestamp_dict[row[0]]\r\n",
        "        lit[cnt] = row[6] - last_incorrect_timestamp_dict[row[0]]\r\n",
        "\r\n",
        "        if row[2] == 1:\r\n",
        "            if (row[6] == 0) or (dict_sub(answered_correctly_sum_u_dict[row[0]] ,count_u_dict[row[0]])==0):\r\n",
        "                like[cnt] = np.nan\r\n",
        "                dislike[cnt] = np.nan\r\n",
        "            else:\r\n",
        "                like[cnt] = like_answer_three_dict[row[7]][row[0]] / dict_sub(cu[cnt] ,acsu[cnt])\r\n",
        "                dislike[cnt] = dislike_answer_three_dict[row[7]][row[0]] / dict_sub(cu[cnt] ,acsu[cnt])\r\n",
        "        else:\r\n",
        "            if (row[6] == 0) or (dict_sub(answered_correctly_sum_u_dict[row[0]] , count_u_dict[row[0]])==0):\r\n",
        "                like[cnt] = np.nan\r\n",
        "                dislike[cnt] = np.nan\r\n",
        "            else:\r\n",
        "                like[cnt] = like_answer_dict[row[7]][row[0]] / dict_sub(cu[cnt] , acsu[cnt])\r\n",
        "                dislike[cnt] = dislike_answer_dict[row[7]][row[0]] / dict_sub(cu[cnt] , acsu[cnt])\r\n",
        "        if content_correct_count_dict[row[4]] > 0:\r\n",
        "            cucm[cnt] = content_correct_user_mean_dict[row[4]] / content_correct_count_dict[row[4]]\r\n",
        "            pcucm[cnt] = parts_content_correct_user_mean_dict[row[4]] / content_correct_count_dict[row[4]]\r\n",
        "        for i in range(7):\r\n",
        "            ptu[cnt,i] = parts_u_dict[i][row[0]]\r\n",
        "            ptcu[cnt,i] = parts_count_u_dict[i][row[0]]\r\n",
        "            if i == row[2]:\r\n",
        "                pavc[cnt] = parts_avg_c_dict[i][row[0]] / dict_sum(parts_count_u_dict[i][row[0]] , 1)\r\n",
        "                parts_avg_c_dict[i][row[0]] = dict_sum(parts_avg_c_dict[row[2]][row[0]],row[3])\r\n",
        "                \r\n",
        "        if ptcu[cnt,row[2]] != 0:\r\n",
        "            puaps[cnt] = parts_user_answer_per_sum_dict[row[2]][row[0]] / ptcu[cnt,row[2]]\r\n",
        "        \r\n",
        "        if row[1] == 1:\r\n",
        "            answered_correctly_sum_u_dict[row[0]] = dict_sum(answered_correctly_sum_u_dict[row[0]],1)\r\n",
        "            answered_correctly_cumsum_u_dict[row[0]] = dict_sum(answered_correctly_cumsum_u_dict[row[0]],100-row[3])\r\n",
        "            answered_incorrectly_cumsum_u_dict[row[0]] = 0\r\n",
        "            last_correct_timestamp_dict[row[0]] = row[6]\r\n",
        "            parts_answered_correctly_cumsum_u_dict[row[2]][row[0]] = dict_sum(parts_answered_correctly_cumsum_u_dict[row[2]][row[0]],100-row[3])\r\n",
        "            parts_answered_incorrectly_cumsum_u_dict[row[2]][row[0]] = 0\r\n",
        "        else:\r\n",
        "            answered_correctly_cumsum_u_dict[row[0]] = 0\r\n",
        "            answered_incorrectly_cumsum_u_dict[row[0]] = dict_sum(answered_incorrectly_cumsum_u_dict[row[0]],row[3])\r\n",
        "            last_incorrect_timestamp_dict[row[0]] = row[6]\r\n",
        "            parts_answered_correctly_cumsum_u_dict[row[2]][row[0]] = 0\r\n",
        "            parts_answered_incorrectly_cumsum_u_dict[row[2]][row[0]] = dict_sum(parts_answered_incorrectly_cumsum_u_dict[row[2]][row[0]],row[3]) \r\n",
        "            if row[2] == 1:\r\n",
        "                #answer0,1,3\r\n",
        "                like_answer_three_dict[row[5]][row[0]] = dict_sum(like_answer_three_dict[row[5]][row[0]],1)\r\n",
        "                for j in [0,1,3]:\r\n",
        "                    if row[5] != j:\r\n",
        "                        dislike_answer_three_dict[j][row[0]] = dict_sum(dislike_answer_three_dict[j][row[0]],1)\r\n",
        "            else:\r\n",
        "                like_answer_dict[row[5]][row[0]] = dict_sum(like_answer_dict[row[5]][row[0]],1)\r\n",
        "                for j in [0,1,2,3]:\r\n",
        "                    if row[5] != j:\r\n",
        "                        dislike_answer_dict[j][row[0]] = dict_sum(dislike_answer_dict[j][row[0]],1)\r\n",
        "            \r\n",
        "            \r\n",
        "            \r\n",
        "        answered_diff_sum_u_dict[row[0]] = dict_sum(answered_diff_sum_u_dict[row[0]],abs(row[3] - (row[1] * 100)))\r\n",
        "        count_u_dict[row[0]] = dict_sum(count_u_dict[row[0]],1)\r\n",
        "        avg_c_sum_u_dict[row[0]] = dict_sum(avg_c_sum_u_dict[row[0]],row[3])\r\n",
        "        \r\n",
        "        if row[4] in answer_per_dict[row[5]]:\r\n",
        "            user_answer_per_sum_dict[row[0]] = user_answer_per_sum_dict[row[0]] + answer_per_dict[row[5]][row[4]]\r\n",
        "            parts_user_answer_per_sum_dict[row[2]][row[0]] = parts_user_answer_per_sum_dict[row[2]][row[0]] + answer_per_dict[row[5]][row[4]]\r\n",
        "        else:\r\n",
        "            user_answer_per_sum_dict[row[0]] = user_answer_per_sum_dict[row[0]] + 0.33\r\n",
        "            parts_user_answer_per_sum_dict[row[2]][row[0]] = parts_user_answer_per_sum_dict[row[2]][row[0]] + 0.33\r\n",
        "       \r\n",
        "        parts_u_dict[row[2]][row[0]] = dict_sum(parts_u_dict[row[2]][row[0]],row[1])\r\n",
        "        parts_count_u_dict[row[2]][row[0]] = dict_sum(parts_count_u_dict[row[2]][row[0]],1)\r\n",
        "        \r\n",
        "        if row[1] == 1:\r\n",
        "            content_correct_count_dict[row[4]] =  dict_sum(content_correct_count_dict[row[4]],1)\r\n",
        "            content_correct_user_mean_dict[row[4]] = content_correct_user_mean_dict[row[4]] + (answered_correctly_sum_u_dict[row[0]] / count_u_dict[row[0]])\r\n",
        "            parts_content_correct_user_mean_dict[row[4]] = parts_content_correct_user_mean_dict[row[4]] + (parts_u_dict[row[2]][row[0]] / parts_count_u_dict[row[2]][row[0]])\r\n",
        " \r\n",
        "    df['answered_correctly_sum_u'] = acsu\r\n",
        "    df['answered_correctly_sum_u'] = df['answered_correctly_sum_u'].astype('uint16')\r\n",
        "    df['answered_cumsum_u'] = accu - aicu\r\n",
        "    df['answered_cumsum_u'] = df['answered_cumsum_u'].astype('int16')\r\n",
        "    df['part_answered_cumsum_u'] = paccu - paicu\r\n",
        "    df['part_answered_cumsum_u'] = df['part_answered_cumsum_u'].astype('int16')    \r\n",
        "    df['count_u'] = cu\r\n",
        "    df['count_u'] = df['count_u'].astype('uint16')\r\n",
        "    df['answered_correctly_avg_u'] = df['answered_correctly_sum_u'] / df['count_u']\r\n",
        "    df['answered_correctly_avg_u'] = df['answered_correctly_avg_u'].astype('float16')\r\n",
        "    df['answered_diff_mean'] = adsu  / cu\r\n",
        "    df['answered_diff_mean'] = df['answered_diff_mean'].astype('float16')\r\n",
        "    df['avg_c_mean'] = avcu / cu\r\n",
        "    df['avg_c_mean'] = df['avg_c_mean'].astype('float16')\r\n",
        "    df['part_avg_c_mean'] = pavc\r\n",
        "    df['part_avg_c_mean'] = df['part_avg_c_mean'].astype('uint8')\r\n",
        "    \r\n",
        "    df['avg_c_per_u'] = df['avg_c_mean'] / (df['answered_correctly_avg_u'] * 100)\r\n",
        "    df['avg_c_per_u'] = df['avg_c_per_u'].astype('float16')\r\n",
        "    \r\n",
        "    df['user_answer_per_mean'] = uaps\r\n",
        "    df['user_answer_per_mean'] = df['user_answer_per_mean']  / df['count_u']\r\n",
        "    df['user_answer_per_mean'] = df['user_answer_per_mean'].astype('float16')\r\n",
        "    \r\n",
        "    df['part_user_answer_per_mean']= puaps\r\n",
        "    df['part_user_answer_per_mean'] = df['part_user_answer_per_mean'].astype('float16')\r\n",
        "    \r\n",
        "    df['content_lv'] = cucm\r\n",
        "    df['content_lv'] = df['content_lv'].astype('float16')\r\n",
        "    df['part_content_lv'] = pcucm\r\n",
        "    df['part_content_lv'] = df['part_content_lv'].astype('float16')\r\n",
        "    df.loc[df['content_lv']==0,'content_lv']=0.5\r\n",
        "    df.loc[df['part_content_lv']==0,'part_content_lv']=0.5\r\n",
        "\r\n",
        "    df['last_correct_timelag'] = lct\r\n",
        "    df['last_correct_timelag'] = df['last_correct_timelag'].astype('uint32')\r\n",
        "    df['last_incorrect_timelag'] = lit\r\n",
        "    df['last_incorrect_timelag'] = df['last_incorrect_timelag'].astype('uint32')\r\n",
        "    \r\n",
        "    df['is_like_answer'] = like\r\n",
        "    df['is_like_answer'] = df['is_like_answer'].astype('float16')\r\n",
        "    df['is_dislike_answer'] = dislike\r\n",
        "    df['is_dislike_answer'] = df['is_dislike_answer'].astype('float16')\r\n",
        "    df['part_count_per'] = 0\r\n",
        "    df['lr_count_per'] = 0\r\n",
        "    cdef str pnum\r\n",
        "    for i in range(7):\r\n",
        "        pnum = str(i)\r\n",
        "        df['p' + pnum + '_count_u'] = ptcu[:,i]\r\n",
        "        df['p' + pnum + '_count_u'] = df['p' + pnum + '_count_u']\r\n",
        "        df['p' + pnum + '_count_u'] = df['p' + pnum + '_count_u'].astype('uint32')\r\n",
        "        df['p' + pnum + '_mean_u'] = ptu[:,i] / ptcu[:,i]\r\n",
        "        df['p' + pnum + '_mean_u']  = df['p' + pnum + '_mean_u'] * (df['p' + pnum + '_count_u'] / df['count_u'])\r\n",
        "        df['p' + pnum + '_mean_u'] = df['p' + pnum + '_mean_u'].astype('float16')\r\n",
        "        df.loc[df['part']==i,'part_count_per'] = df['p' + pnum + '_count_u'] / df['count_u']\r\n",
        "    df['part_count_per'] = df['part_count_per'].astype('float16')    \r\n",
        "    df.loc[df['part']<4,'lr_count_per'] = ((df['p0_count_u'] + df['p1_count_u'] + df['p2_count_u'] + df['p3_count_u']) / df['count_u'])\r\n",
        "    df.loc[df['part']>3,'lr_count_per'] = ((df['p4_count_u'] + df['p5_count_u'] + df['p6_count_u']) / df['count_u']).astype('float16')\r\n",
        "    df['lr_count_per'] = df['lr_count_per'].astype('float16')\r\n",
        "    df.replace([np.inf, -np.inf], np.nan,inplace=True)\r\n",
        "    return df\r\n",
        "\r\n",
        "@cython.boundscheck(False)\r\n",
        "@cython.wraparound(False)\r\n",
        "@cython.nonecheck(False)\r\n",
        "cdef int dict_sum(int a, int b):\r\n",
        "    return a + b\r\n",
        "@cython.boundscheck(False)\r\n",
        "@cython.wraparound(False)\r\n",
        "@cython.nonecheck(False)\r\n",
        "cdef int dict_sub(int a, int b):\r\n",
        "    return a - b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFdJAVVmArK1"
      },
      "source": [
        "%%cython\r\n",
        "import cython\r\n",
        "cimport cython\r\n",
        "import numpy as np\r\n",
        "cimport numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "@cython.boundscheck(False)\r\n",
        "@cython.wraparound(False)\r\n",
        "@cython.nonecheck(False)\r\n",
        "def add_time_feats(df,time_u_dict,lect_u_dict):\r\n",
        "    cdef int arr_size = len(df)\r\n",
        "    cdef int cnt\r\n",
        "    cdef np.ndarray[long, ndim=1] row\r\n",
        "    cdef np.ndarray[long, ndim=1] tu = np.zeros(arr_size,dtype=long)\r\n",
        "    cdef np.ndarray[long, ndim=1] lc = np.zeros(arr_size,dtype=long)\r\n",
        "    for cnt,row in enumerate(df[['user_id','timestamp','content_type_id']].values):\r\n",
        "        if (row[1] - time_u_dict[row[0]]>0):\r\n",
        "            tu[cnt] = dict_sub(row[1],time_u_dict[row[0]])\r\n",
        "        elif (row[1] == 0):\r\n",
        "            tu[cnt] = 0\r\n",
        "        else:\r\n",
        "            tu[cnt] = tu[cnt - 1]\r\n",
        "        lc[cnt] = lect_u_dict[row[0]]\r\n",
        "        \r\n",
        "        time_u_dict[row[0]] = row[1]\r\n",
        "        if (row[2] == 1):\r\n",
        "            lect_u_dict[row[0]] = lect_u_dict[row[0]] + 1\r\n",
        "    \r\n",
        "    cdef int split = 60*60*24\r\n",
        "    cdef np.ndarray[long, ndim=1] tu_day = tu // split\r\n",
        "    cdef np.ndarray[long, ndim=1] tu_time = tu % split \r\n",
        "\r\n",
        "    df['lag_time'] = tu_time\r\n",
        "    df['lag_time'] = df['lag_time'].astype('uint16')\r\n",
        "    df['lag_day'] = tu_day\r\n",
        "    df['lag_day'] = df['lag_day'].astype('uint16')\r\n",
        "    df.loc[df['lag_day']>0,'lag_time'] = np.iinfo(np.uint16).max\r\n",
        "    df['lecture_count'] = lc\r\n",
        "    df.loc[df['lecture_count']>np.iinfo(np.uint8).max,'lecture_count'] = np.iinfo(np.uint8).max\r\n",
        "    df['lecture_count'] = df['lecture_count'].astype('uint8')\r\n",
        "    return df\r\n",
        "            \r\n",
        "@cython.boundscheck(False)\r\n",
        "@cython.wraparound(False)\r\n",
        "@cython.nonecheck(False)\r\n",
        "cdef int dict_sub(long a, int b):\r\n",
        "    return a - b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9nvMBw4A2qb"
      },
      "source": [
        "#content_answer_per生成\r\n",
        "train = pd.read_pickle(train_pickle)[feld_needed]\r\n",
        "train = train.loc[train['content_type_id']==0][['content_id','user_answer']]\r\n",
        "tmp = train.groupby('content_id').count()\r\n",
        "tmp.rename(columns={'user_answer':'count'},inplace=True)\r\n",
        "train = pd.read_pickle(train_pickle)[feld_needed]\r\n",
        "train = train.loc[train['content_type_id']==0][['content_id','user_answer','content_type_id']]\r\n",
        "tmp2 = train.groupby(['content_id','user_answer']).count().reset_index()\r\n",
        "tmp2 = tmp2.merge(tmp,left_on='content_id',right_index=True,how='left')\r\n",
        "tmp2['answer_per'] = tmp2['content_type_id'] / tmp2['count']\r\n",
        "tmp2 = tmp2[['content_id','user_answer','answer_per']]\r\n",
        "tmp2['answer_per'].fillna(0.3,inplace=True)\r\n",
        "answer_per_dict = {}\r\n",
        "for i in range(4):\r\n",
        "    answer_per_dict[i] = tmp2.loc[tmp2['user_answer']==i].set_index('content_id')[['answer_per']].to_dict()['answer_per']\r\n",
        "del train, tmp2, tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVDaUV5sA4lb"
      },
      "source": [
        "train = pd.read_pickle(train_pickle)[feld_needed]\r\n",
        "valid = pd.read_pickle(valid_pickle)[feld_needed]\r\n",
        "# answered correctly average for each content\r\n",
        "# content_type_idが異なっていて同じコンテンツIDが存在する\r\n",
        "content_df = train.loc[train['content_type_id']==0][['content_id','answered_correctly']].groupby(['content_id']).agg(['mean']).reset_index()\r\n",
        "content_df.columns = ['content_id', 'answered_correctly_avg_c']\r\n",
        "content_df['answered_correctly_avg_c'] = (content_df['answered_correctly_avg_c'] * 100).astype(np.uint8)\r\n",
        "content_df = content_df.set_index('content_id')\r\n",
        "content_df.index.name = 'content_id'\r\n",
        "\r\n",
        "if debug:\r\n",
        "    train = train[:1000000]\r\n",
        "    valid = valid[:10000]\r\n",
        "else:\r\n",
        "    #user_id split because user trace\r\n",
        "    #current active user trace \r\n",
        "    print('all =',train['row_id'].min(),train['row_id'].max())\r\n",
        "    train = train.sort_values('row_id')\r\n",
        "    train = train[int(len(train)/2):]\r\n",
        "    print('current =',train['row_id'].min(),train['row_id'].max())\r\n",
        "    #usersグループを３つ作成し、それぞれのグループ毎にモデル生成\r\n",
        "    users = np.random.choice(train['user_id'].unique(), int(len(train['user_id'].unique()) * 8 / 10), replace=True)\r\n",
        "\r\n",
        "    train = pd.read_pickle(train_pickle)[feld_needed]\r\n",
        "    train = train.loc[train['user_id'].isin(users)]\r\n",
        "    #推論時のアンサンブルモデルの重みに使用\r\n",
        "    with open('train_users.pickle', 'wb') as f:\r\n",
        "        pickle.dump(users, f)  \r\n",
        "print(train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-rBwj0DA6az"
      },
      "source": [
        "%%cython\r\n",
        "import cython\r\n",
        "cimport cython\r\n",
        "import numpy as np\r\n",
        "cimport numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "@cython.boundscheck(False)\r\n",
        "@cython.wraparound(False)\r\n",
        "@cython.nonecheck(False)\r\n",
        "def data_format(df,questions_df,content_df,float prior_question_elapsed_time_mean):\r\n",
        "    df['row_id'] = df['row_id'].astype('uint32')\r\n",
        "    df['user_id'] = df['user_id'].astype('int32')\r\n",
        "    df['content_type_id'] = df['content_type_id'].astype('uint8')\r\n",
        "    df.loc[df['content_type_id'] != 0,'content_id'] = 532 #暫定\r\n",
        "    df['content_id'] = df['content_id'].astype('uint16')\r\n",
        "    # changing dtype to avoid lightgbm error\r\n",
        "    df['prior_question_had_explanation'] = df.prior_question_had_explanation.fillna(False).astype('uint8')\r\n",
        "    df['prior_question_elapsed_time'] = df.prior_question_elapsed_time.fillna(prior_question_elapsed_time_mean)\r\n",
        "    df['prior_question_elapsed_time'] = (df['prior_question_elapsed_time'] / 1000).astype('uint16')\r\n",
        "    df['timestamp'] = (df['timestamp'] / 1000).astype(np.uint32)\r\n",
        "    # merge\r\n",
        "    df = pd.concat([df.reset_index(drop=True), questions_df.reindex(df['content_id'].values).reset_index(drop=True)], axis=1)\r\n",
        "    df = pd.concat([df.reset_index(drop=True), content_df.reindex(df['content_id'].values).reset_index(drop=True)], axis=1)\r\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDcXbgkSBTjj"
      },
      "source": [
        "# fill with mean value for prior_question_elapsed_time\r\n",
        "# note that `train.prior_question_elapsed_time.mean()` dose not work!\r\n",
        "# please refer https://www.kaggle.com/its7171/can-we-trust-pandas-mean for detail.\r\n",
        "prior_question_elapsed_time_mean = train.prior_question_elapsed_time.dropna().values.mean()\r\n",
        "\r\n",
        "train = data_format(train,questions_df,content_df,prior_question_elapsed_time_mean)\r\n",
        "valid = data_format(valid,questions_df,content_df,prior_question_elapsed_time_mean)\r\n",
        "\r\n",
        "# memory compaction\r\n",
        "train.loc[train['answered_correctly'] < 0,'answered_correctly'] = 0\r\n",
        "train['answered_correctly'] = train['answered_correctly'].astype('uint8')\r\n",
        "train['user_answer'] = train['user_answer'].astype('uint8')\r\n",
        "valid.loc[valid['answered_correctly'] < 0,'answered_correctly'] = 0\r\n",
        "valid['answered_correctly'] = valid['answered_correctly'].astype('uint8')\r\n",
        "valid['user_answer'] = valid['user_answer'].astype('uint8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvrK41mIBWZR"
      },
      "source": [
        "#経過時間(講義列も考慮)\r\n",
        "#train add_time_feats = 0:00:43.003496\r\n",
        "#valid add_time_feats = 0:00:03.887652\r\n",
        "time_u_dict = defaultdict(int)\r\n",
        "lect_u_dict = defaultdict(int)\r\n",
        "\r\n",
        "start = datetime.datetime.now()\r\n",
        "train = add_time_feats(train,time_u_dict,lect_u_dict)\r\n",
        "print('train add_time_feats =',(datetime.datetime.now()- start))\r\n",
        "start = datetime.datetime.now()\r\n",
        "valid = add_time_feats(valid,time_u_dict,lect_u_dict)\r\n",
        "print('valid add_time_feats =',(datetime.datetime.now()- start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gsI9-wfBYLJ"
      },
      "source": [
        "train = train.loc[train.content_type_id == False].reset_index(drop=True)\r\n",
        "valid = valid.loc[valid.content_type_id == False].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXimpeWiBZZ6"
      },
      "source": [
        "%%cython\r\n",
        "import cython\r\n",
        "cimport cython\r\n",
        "import numpy as np\r\n",
        "cimport numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "DTYPE = np.int32\r\n",
        "ctypedef np.int32_t np_int_t\r\n",
        "\r\n",
        "@cython.boundscheck(False)\r\n",
        "@cython.wraparound(False)\r\n",
        "@cython.nonecheck(False)\r\n",
        "def add_prior_feats(df, q_stats_dict,q_enc_tag_dict,q_prior_root_dict,\r\n",
        "                    prior_content_dict, prior_prior_content_dict, prior_time_dict, \r\n",
        "                    prior_time_per_sum_dict,\r\n",
        "                    prior_lag_dict, prior_prior_lag_dict,\r\n",
        "                    lag_sum_dict, prior_avg_c_dict, prior_prior_avg_c_dict,\r\n",
        "                    part_lag_sum_dict, prior_part_dict):\r\n",
        "    cdef int arr_size = len(df)\r\n",
        "    cdef int cnt\r\n",
        "    cdef np.ndarray[int, ndim=1] row\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] pc = np.zeros(arr_size,dtype=DTYPE)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] ppc = np.zeros(arr_size,dtype=DTYPE)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] eqtag = np.zeros(arr_size,dtype=DTYPE)\r\n",
        "    cdef np.ndarray[float, ndim=1] tp = np.zeros(arr_size,dtype=np.float32)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] pt = np.zeros(arr_size,dtype=DTYPE)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] ul = np.zeros(arr_size,dtype=DTYPE)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] ull = np.zeros(arr_size,dtype=DTYPE)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] pe = np.zeros(arr_size,dtype=DTYPE)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] ls = np.zeros(arr_size,dtype=DTYPE)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] pac = np.zeros(arr_size,dtype=DTYPE)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] ppac = np.zeros(arr_size,dtype=DTYPE)\r\n",
        "    cdef np.ndarray[float, ndim=1] ptps = np.zeros(arr_size,dtype=np.float32)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] pls = np.zeros(arr_size,dtype=DTYPE)\r\n",
        "    cdef np.ndarray[float, ndim=1] pr = np.zeros(arr_size,dtype=np.float32)\r\n",
        "    \r\n",
        "    for cnt,row in enumerate(df[['user_id','content_id','prior_question_elapsed_time','lag_time' ,'prior_question_had_explanation','answered_correctly_avg_c','part']].values):\r\n",
        "        ppc[cnt] = prior_prior_content_dict[row[0]]\r\n",
        "        pc[cnt] = prior_content_dict[row[0]]\r\n",
        "        if prior_prior_content_dict[row[0]] in q_stats_dict:\r\n",
        "            pt[cnt] = prior_time_dict[row[0]] / q_stats_dict[prior_prior_content_dict[row[0]]]\r\n",
        "        else:\r\n",
        "            pt[cnt] = 1\r\n",
        "        ls[cnt] = lag_sum_dict[row[0]]\r\n",
        "        pac[cnt] = prior_avg_c_dict[row[0]]\r\n",
        "        ppac[cnt] = prior_prior_avg_c_dict[row[0]]\r\n",
        "        pls[cnt] = part_lag_sum_dict[row[6]][row[0]]\r\n",
        "        if (q_enc_tag_dict[pc[cnt]] == q_enc_tag_dict[row[1]]):\r\n",
        "            eqtag[cnt] = 1\r\n",
        "        else:\r\n",
        "            eqtag[cnt] = 0\r\n",
        "        if prior_content_dict[row[0]] > 0:\r\n",
        "            if (row[1],prior_content_dict[row[0]]) in q_prior_root_dict:\r\n",
        "                pr[cnt] = q_prior_root_dict[(row[1],prior_content_dict[row[0]])]\r\n",
        "        else:\r\n",
        "            if (row[1],-999) in q_prior_root_dict:\r\n",
        "                pr[cnt] = q_prior_root_dict[(row[1],-999)]\r\n",
        "        if (prior_content_dict[row[0]] > 0) & (prior_content_dict[row[0]] in q_stats_dict):\r\n",
        "            tp[cnt] = row[2] / q_stats_dict[prior_content_dict[row[0]]]\r\n",
        "            prior_time_per_sum_dict[row[0]] = prior_time_per_sum_dict[row[0]] + tp[cnt]\r\n",
        "        else:\r\n",
        "            tp[cnt] = 1\r\n",
        "        ptps[cnt] = prior_time_per_sum_dict[row[0]]\r\n",
        "        \r\n",
        "        if prior_content_dict[row[0]] > 0:\r\n",
        "            prior_part_dict[row[0]] = row[6]\r\n",
        "            part_lag_sum_dict[prior_part_dict[row[0]]][row[0]] = part_lag_sum_dict[prior_part_dict[row[0]]][row[0]] + tp[cnt]\r\n",
        "        prior_prior_content_dict[row[0]] = prior_content_dict[row[0]]\r\n",
        "        prior_content_dict[row[0]] = row[1]\r\n",
        "        prior_time_dict[row[0]] = row[2] #1つ前のコンテンツの回答時間\r\n",
        "        ul[cnt] = prior_lag_dict[row[0]]\r\n",
        "        ull[cnt] = prior_prior_lag_dict[row[0]]\r\n",
        "        prior_prior_lag_dict[row[0]] = prior_lag_dict[row[0]]\r\n",
        "        prior_lag_dict[row[0]] = row[3]\r\n",
        "        lag_sum_dict[row[0]] = lag_sum_dict[row[0]] + row[3]\r\n",
        "        prior_prior_avg_c_dict[row[0]] = prior_avg_c_dict[row[0]]\r\n",
        "        prior_avg_c_dict[row[0]] = row[5]\r\n",
        "            \r\n",
        "    df['prior_content_id'] = pc\r\n",
        "    df['prior_content_id'] = df['prior_content_id'].astype('uint16')\r\n",
        "    df['prior_content_diff'] = df['content_id'] - df['prior_content_id']\r\n",
        "    df.loc[df['timestamp']==0, 'prior_content_diff'] = -999\r\n",
        "    #現在のコンテンツ回答前に実施したコンテンツの割合\r\n",
        "    df['prior_root'] = pr\r\n",
        "    df['prior_root'] = df['prior_root'].astype('float16')\r\n",
        "    \r\n",
        "    df['is_same_prior'] = eqtag\r\n",
        "    df.loc[df['prior_content_id'] == df['content_id'],'is_same_prior'] = df['is_same_prior'] + 2\r\n",
        "    df['is_same_prior'] = df['is_same_prior'].astype('uint8')\r\n",
        "    df['lag_time_per'] = df['lag_time'] / df['prior_question_elapsed_time'].astype('float32')\r\n",
        "    df['elapsed_lag_per'] = tp\r\n",
        "    df['elapsed_lag_per'] = df['elapsed_lag_per'].astype('float16')\r\n",
        "    df['elapsed_time_per_mean'] = ptps\r\n",
        "    df['elapsed_time_per_mean'] = df['elapsed_time_per_mean'].astype('float16')\r\n",
        "    \r\n",
        "    df['part_elapsed_time_per_mean'] = pls\r\n",
        "    df['part_elapsed_time_per_mean'] = df['part_elapsed_time_per_mean'].astype('float16')\r\n",
        "\r\n",
        "    df['prior_prior_lag_time'] = ull\r\n",
        "    df['prior_prior_lag_time'] = df['prior_prior_lag_time'].astype('uint16')\r\n",
        "    df['prior_lag_time'] = ul\r\n",
        "    df['prior_lag_time'] = df['prior_lag_time'].astype('uint16')\r\n",
        "    df['lag_lag_time'] = df['lag_time'] / df['prior_lag_time']\r\n",
        "    df['lag_lag_time'] = df['lag_lag_time'].astype('float16')\r\n",
        "    df['lag_sum'] = ls\r\n",
        "    df['prior_avg_c'] = pac\r\n",
        "    df['prior_avg_c'] = df['prior_avg_c'].astype('uint8')\r\n",
        "    df['prior_prior_avg_c'] = ppac\r\n",
        "    df['prior_prior_avg_c'] = df['prior_prior_avg_c'].astype('uint8')\r\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJK4-kMMBbRS"
      },
      "source": [
        "#q_stats_dict = pd.read_csv('../input/riiiddataset/question_stats.csv').set_index('content_id')[['q_elapsed_time_mean']].to_dict()['q_elapsed_time_mean']\r\n",
        "#correct answer only\r\n",
        "q_stats_dict = pd.read_csv('../input/riiiddataset/correct_q_elapsed_time_mean.csv').set_index('content_id')[['correct_q_elapsed_time_mean']].to_dict()['correct_q_elapsed_time_mean']\r\n",
        "q_enc_tag_dict = questions_df[['enc_tags']].to_dict()['enc_tags']\r\n",
        "q_ans_dict = questions_df[['correct_answer']].to_dict()['correct_answer']\r\n",
        "#現在実行中コンテンツ前に実行されたコンテンツの確率\r\n",
        "q_prior_root_dict = pd.read_csv('../input/riiiddataset/prior_position_per.csv').fillna(-999).set_index(['content_id','prior_content_id']).to_dict()['prior_position_per']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk3X80pHBdFz"
      },
      "source": [
        "#train add_prior_feats = 0:02:22.203537\r\n",
        "#valid add_prior_feats = 0:00:12.576596\r\n",
        "\r\n",
        "prior_content_dict = defaultdict(int)\r\n",
        "prior_prior_content_dict = defaultdict(int)\r\n",
        "prior_time_dict = defaultdict(int)\r\n",
        "prior_time_per_sum_dict = defaultdict(int)\r\n",
        "prior_lag_dict = defaultdict(int)\r\n",
        "prior_prior_lag_dict = defaultdict(int)\r\n",
        "lag_sum_dict = defaultdict(int)\r\n",
        "prior_avg_c_dict = defaultdict(int)\r\n",
        "prior_prior_avg_c_dict = defaultdict(int)\r\n",
        "part_lag_sum_dict = {}\r\n",
        "for p in range(0,7):\r\n",
        "    part_lag_sum_dict[p] = defaultdict(int)\r\n",
        "\r\n",
        "prior_part_dict = defaultdict(int)\r\n",
        "start = datetime.datetime.now()\r\n",
        "train = add_prior_feats(train,\r\n",
        "                        q_stats_dict,\r\n",
        "                        q_enc_tag_dict,\r\n",
        "                        q_prior_root_dict,\r\n",
        "                        prior_content_dict,\r\n",
        "                        prior_prior_content_dict,\r\n",
        "                        prior_time_dict,\r\n",
        "                        prior_time_per_sum_dict,\r\n",
        "                        prior_lag_dict,\r\n",
        "                        prior_prior_lag_dict,\r\n",
        "                        lag_sum_dict,\r\n",
        "                        prior_avg_c_dict,\r\n",
        "                        prior_prior_avg_c_dict,\r\n",
        "                        part_lag_sum_dict,\r\n",
        "                        prior_part_dict)\r\n",
        "print('train add_prior_feats =',(datetime.datetime.now()- start))\r\n",
        "start = datetime.datetime.now()\r\n",
        "valid = add_prior_feats(valid,\r\n",
        "                        q_stats_dict,\r\n",
        "                        q_enc_tag_dict,\r\n",
        "                        q_prior_root_dict,\r\n",
        "                        prior_content_dict,\r\n",
        "                        prior_prior_content_dict,\r\n",
        "                        prior_time_dict,\r\n",
        "                        prior_time_per_sum_dict,\r\n",
        "                        prior_lag_dict,\r\n",
        "                        prior_prior_lag_dict,\r\n",
        "                        lag_sum_dict,\r\n",
        "                        prior_avg_c_dict,\r\n",
        "                        prior_prior_avg_c_dict,\r\n",
        "                        part_lag_sum_dict,\r\n",
        "                        prior_part_dict)\r\n",
        "print('valid add_prior_feats =',(datetime.datetime.now()- start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkYvVVFIBe3h"
      },
      "source": [
        "del q_prior_root_dict\r\n",
        "_=gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxfGMy-9BgOR"
      },
      "source": [
        "#train add_user_feats = 0:07:19.055945\r\n",
        "#valid add_user_feats = 0:00:38.820698\r\n",
        "#正解数\r\n",
        "answered_correctly_sum_u_dict = defaultdict(int)\r\n",
        "#連続正答数\r\n",
        "answered_correctly_cumsum_u_dict = defaultdict(int)\r\n",
        "#連続不正解\r\n",
        "answered_incorrectly_cumsum_u_dict = defaultdict(int)\r\n",
        "#回答数\r\n",
        "count_u_dict = defaultdict(int)\r\n",
        "#パート回答数\r\n",
        "parts_count_u_dict = {}\r\n",
        "parts_u_dict = {}\r\n",
        "parts_avg_c_dict = {}\r\n",
        "parts_user_answer_per_sum_dict = {}\r\n",
        "parts_answered_correctly_cumsum_u_dict = {}\r\n",
        "parts_answered_incorrectly_cumsum_u_dict = {}\r\n",
        "for p in range(0,7):\r\n",
        "    parts_u_dict[p] = defaultdict(int)\r\n",
        "    parts_count_u_dict[p] = defaultdict(int)\r\n",
        "    parts_avg_c_dict[p] = defaultdict(int)\r\n",
        "    parts_user_answer_per_sum_dict[p] = defaultdict(int)\r\n",
        "    parts_answered_correctly_cumsum_u_dict[p] = defaultdict(int)\r\n",
        "    parts_answered_incorrectly_cumsum_u_dict[p] = defaultdict(int)\r\n",
        "    \r\n",
        "#回答期待値との差\r\n",
        "answered_diff_sum_u_dict = defaultdict(int)\r\n",
        "avg_c_sum_u_dict = defaultdict(int)\r\n",
        "user_answer_per_sum_dict = defaultdict(int)\r\n",
        "\r\n",
        "content_correct_user_mean_dict = defaultdict(int)\r\n",
        "content_correct_count_dict = defaultdict(int)\r\n",
        "parts_content_correct_user_mean_dict = defaultdict(int)\r\n",
        "\r\n",
        "last_correct_timestamp_dict = defaultdict(int)\r\n",
        "last_incorrect_timestamp_dict = defaultdict(int)\r\n",
        "\r\n",
        "like_answer_dict = {}\r\n",
        "like_answer_three_dict = {}\r\n",
        "dislike_answer_dict = {}\r\n",
        "dislike_answer_three_dict = {}\r\n",
        "for p in range(0,4):\r\n",
        "    like_answer_dict[p] = defaultdict(int)\r\n",
        "    like_answer_three_dict[p] = defaultdict(int)\r\n",
        "    dislike_answer_dict[p] = defaultdict(int)\r\n",
        "    dislike_answer_three_dict[p] = defaultdict(int)\r\n",
        "\r\n",
        "start = datetime.datetime.now()\r\n",
        "train = add_user_feats(train,\r\n",
        "                       answer_per_dict,\r\n",
        "                       answered_correctly_sum_u_dict, \r\n",
        "                       answered_correctly_cumsum_u_dict,\r\n",
        "                       answered_incorrectly_cumsum_u_dict,\r\n",
        "                       count_u_dict,\r\n",
        "                       parts_u_dict,\r\n",
        "                       parts_count_u_dict,\r\n",
        "                       answered_diff_sum_u_dict,\r\n",
        "                       avg_c_sum_u_dict,\r\n",
        "                       parts_avg_c_dict,\r\n",
        "                       user_answer_per_sum_dict,\r\n",
        "                       parts_user_answer_per_sum_dict,\r\n",
        "                       content_correct_user_mean_dict,\r\n",
        "                       content_correct_count_dict,\r\n",
        "                       parts_content_correct_user_mean_dict,\r\n",
        "                       last_correct_timestamp_dict,\r\n",
        "                       last_incorrect_timestamp_dict,\r\n",
        "                       like_answer_dict,\r\n",
        "                       like_answer_three_dict,\r\n",
        "                       dislike_answer_dict,\r\n",
        "                       dislike_answer_three_dict,\r\n",
        "                       parts_answered_correctly_cumsum_u_dict,\r\n",
        "                       parts_answered_incorrectly_cumsum_u_dict)\r\n",
        "\r\n",
        "print('train add_user_feats =',(datetime.datetime.now() - start))\r\n",
        "\r\n",
        "start = datetime.datetime.now()\r\n",
        "valid = add_user_feats(valid,\r\n",
        "                       answer_per_dict,\r\n",
        "                       answered_correctly_sum_u_dict,\r\n",
        "                       answered_correctly_cumsum_u_dict,\r\n",
        "                       answered_incorrectly_cumsum_u_dict,\r\n",
        "                       count_u_dict,\r\n",
        "                       parts_u_dict,\r\n",
        "                       parts_count_u_dict,\r\n",
        "                       answered_diff_sum_u_dict,\r\n",
        "                       avg_c_sum_u_dict,\r\n",
        "                       parts_avg_c_dict,\r\n",
        "                       user_answer_per_sum_dict,\r\n",
        "                       parts_user_answer_per_sum_dict,\r\n",
        "                       content_correct_user_mean_dict,\r\n",
        "                       content_correct_count_dict,\r\n",
        "                       parts_content_correct_user_mean_dict,\r\n",
        "                       last_correct_timestamp_dict,\r\n",
        "                       last_incorrect_timestamp_dict,\r\n",
        "                       like_answer_dict,\r\n",
        "                       like_answer_three_dict,\r\n",
        "                       dislike_answer_dict,\r\n",
        "                       dislike_answer_three_dict,\r\n",
        "                       parts_answered_correctly_cumsum_u_dict,\r\n",
        "                       parts_answered_incorrectly_cumsum_u_dict)\r\n",
        "print('valid add_user_feats =',(datetime.datetime.now() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcYtUb6XBipB"
      },
      "source": [
        "%%cython\r\n",
        "import cython\r\n",
        "cimport cython\r\n",
        "import numpy as np\r\n",
        "cimport numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "DTYPE = np.int32\r\n",
        "ctypedef np.int32_t np_int_t\r\n",
        "\r\n",
        "@cython.boundscheck(False)\r\n",
        "@cython.wraparound(False)\r\n",
        "@cython.nonecheck(False)\r\n",
        "def add_user_content_feats(df, user_content_dict, user_tags_dict, user_repeat_count_dict):\r\n",
        "    cdef int arr_size = len(df)\r\n",
        "    cdef int cnt,i\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] row\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] uc = np.zeros(arr_size,dtype=DTYPE)\r\n",
        "    cdef np.ndarray[np_int_t, ndim=1] rc = np.zeros(arr_size,dtype=DTYPE)\r\n",
        "    for cnt,row in enumerate(df[['user_id','content_id','answered_correctly','enc_tags','part']].values):\r\n",
        "        if (row[1] in user_content_dict[row[0]]):\r\n",
        "            uc[cnt] = user_content_dict[row[0]][row[1]]\r\n",
        "        else:\r\n",
        "            uc[cnt] = 0\r\n",
        "        if (row[3] in user_tags_dict[row[0]]):\r\n",
        "            uc[cnt] = uc[cnt] + (user_tags_dict[row[0]][row[3]] * 2)\r\n",
        "\r\n",
        "        rc[cnt] = user_repeat_count_dict[row[4]][row[0]]\r\n",
        "        \r\n",
        "        if row[2] == 0:\r\n",
        "            user_content_dict[row[0]][row[1]] = 1\r\n",
        "            user_tags_dict[row[0]][row[3]] = 1\r\n",
        "        else:\r\n",
        "            user_content_dict[row[0]][row[1]] = 2\r\n",
        "            user_tags_dict[row[0]][row[3]] = 2\r\n",
        "            \r\n",
        "        if row[1] in user_content_dict[row[0]]:\r\n",
        "            if not row[0] in user_repeat_count_dict[row[4]]:\r\n",
        "                user_repeat_count_dict[row[4]][row[0]] = 0\r\n",
        "            user_repeat_count_dict[row[4]][row[0]] = user_repeat_count_dict[row[4]][row[0]] + 1\r\n",
        "    df['done_content_tag'] = uc\r\n",
        "    df['done_content_tag'] = df['done_content_tag'].astype('uint8')\r\n",
        "    df['repeat_part_per'] = rc\r\n",
        "    return df\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_h5oJsJBkfK"
      },
      "source": [
        "#train add_user_content_feats = 0:01:37.861307\r\n",
        "#valid add_user_content_feats = 0:00:08.414493\r\n",
        "#回答数\r\n",
        "user_content_dict = defaultdict(dict)\r\n",
        "user_tags_dict = defaultdict(dict)\r\n",
        "user_repeat_count_dict = {}\r\n",
        "for p in range(0,7):\r\n",
        "    user_repeat_count_dict[p] = defaultdict(int)\r\n",
        "start = datetime.datetime.now()\r\n",
        "train = add_user_content_feats(train, user_content_dict, user_tags_dict, user_repeat_count_dict)\r\n",
        "print('train add_user_content_feats =',(datetime.datetime.now() - start))\r\n",
        "start = datetime.datetime.now()\r\n",
        "valid = add_user_content_feats(valid, user_content_dict, user_tags_dict, user_repeat_count_dict)\r\n",
        "print('valid add_user_content_feats =',(datetime.datetime.now() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR0BkhyABl_j"
      },
      "source": [
        "%%cython\r\n",
        "import cython\r\n",
        "cimport cython\r\n",
        "import numpy as np\r\n",
        "cimport numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "@cython.boundscheck(False)\r\n",
        "@cython.wraparound(False)\r\n",
        "@cython.nonecheck(False)\r\n",
        "def post_round(df,list use_tags,list use_content):\r\n",
        "    df.loc[~df['enc_tags'].isin(use_tags),'enc_tags'] = 65535\r\n",
        "    df.loc[~df['content_id'].isin(use_content),'content_id'] = 532 #暫定\r\n",
        "    return df\r\n",
        "\r\n",
        "@cython.boundscheck(False)\r\n",
        "@cython.wraparound(False)\r\n",
        "@cython.nonecheck(False)\r\n",
        "def post_features(df):\r\n",
        "    cdef int i\r\n",
        "    df['lag_mean'] = (df['lag_sum'] / df['count_u'])\r\n",
        "    df.loc[df['lag_mean'] > 65535,'lag_mean'] = 65535\r\n",
        "    df['lag_mean'] = df['lag_mean'].astype('float16')\r\n",
        "    \r\n",
        "    df['elapsed_time_per_mean'] = df['elapsed_time_per_mean'] / df['count_u']\r\n",
        "    df['elapsed_time_per_mean'].fillna(1,inplace=True)\r\n",
        "    df['elapsed_time_per_mean'] = df['elapsed_time_per_mean'].astype('float16')\r\n",
        "    \r\n",
        "    cdef list parts = list(df['part'].unique())\r\n",
        "    cdef str p\r\n",
        "    for i in parts:\r\n",
        "        p = str(i)\r\n",
        "        df.loc[df['part']==i,'part_elapsed_time_per_mean'] = df['part_elapsed_time_per_mean'] / df['p' + p + '_count_u']\r\n",
        "        df.loc[df['p' + p  + '_count_u']>0,'repeat_part_per'] = df['repeat_part_per'] / df['p' + p  + '_count_u']\r\n",
        "\r\n",
        "    df['prior_question_elapsed_time'] = df['prior_question_elapsed_time'] / df['part_elapsed_time_per_mean']\r\n",
        "    \r\n",
        "    df.loc[df['part_user_answer_per_mean'] == 0, 'part_user_answer_per_mean'] = np.nan\r\n",
        "    df['repeat_part_per'] = df['repeat_part_per'].astype('float16')\r\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKxDYN22Bnmp"
      },
      "source": [
        "#少数カテゴリ値を丸める。推論時に未知のカテゴリが出てきた場合にも丸めます\r\n",
        "round_max = np.iinfo(np.uint16).max\r\n",
        "\r\n",
        "use_tags = list(train['enc_tags'].value_counts()[train['enc_tags'].value_counts()>3].index)\r\n",
        "use_content = list(train['content_id'].value_counts()[train['content_id'].value_counts()>3].index)\r\n",
        "\r\n",
        "train = post_round(train,use_tags,use_content)\r\n",
        "valid = post_round(valid,use_tags,use_content)\r\n",
        "\r\n",
        "train = post_features(train)\r\n",
        "valid = post_features(valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao_SEqaiBzPq"
      },
      "source": [
        "print(train.info())\r\n",
        "print(train.memory_usage(deep=True))\r\n",
        "'''\r\n",
        "<class 'pandas.core.frame.DataFrame'>\r\n",
        "RangeIndex: 26742859 entries, 0 to 26742858\r\n",
        "Data columns (total 67 columns):\r\n",
        " #   Column                          Dtype  \r\n",
        "---  ------                          -----  \r\n",
        " 0   row_id                          uint32 \r\n",
        " 1   timestamp                       uint32 \r\n",
        " 2   user_id                         int32  \r\n",
        " 3   content_id                      uint16 \r\n",
        " 4   content_type_id                 uint8  \r\n",
        " 5   answered_correctly              uint8  \r\n",
        " 6   prior_question_elapsed_time     float32\r\n",
        " 7   prior_question_had_explanation  uint8  \r\n",
        " 8   user_answer                     uint8  \r\n",
        " 9   correct_answer                  uint8  \r\n",
        " 10  part                            uint8  \r\n",
        " 11  tags_92                         uint8  \r\n",
        " 12  enc_tags                        uint16 \r\n",
        " 13  answered_correctly_avg_c        uint8  \r\n",
        " 14  lag_time                        uint16 \r\n",
        " 15  lag_day                         uint16 \r\n",
        " 16  lecture_count                   uint8  \r\n",
        " 17  prior_content_id                uint16 \r\n",
        " 18  prior_content_diff              uint16 \r\n",
        " 19  prior_root                      float16\r\n",
        " 20  is_same_prior                   uint8  \r\n",
        " 21  lag_time_per                    float32\r\n",
        " 22  elapsed_lag_per                 float16\r\n",
        " 23  elapsed_time_per_mean           float16\r\n",
        " 24  part_elapsed_time_per_mean      float16\r\n",
        " 25  prior_prior_lag_time            uint16 \r\n",
        " 26  prior_lag_time                  uint16 \r\n",
        " 27  lag_lag_time                    float16\r\n",
        " 28  lag_sum                         int32  \r\n",
        " 29  prior_avg_c                     uint8  \r\n",
        " 30  prior_prior_avg_c               uint8  \r\n",
        " 31  answered_correctly_sum_u        uint16 \r\n",
        " 32  answered_cumsum_u               int16  \r\n",
        " 33  part_answered_cumsum_u          int16  \r\n",
        " 34  count_u                         uint16 \r\n",
        " 35  answered_correctly_avg_u        float16\r\n",
        " 36  answered_diff_mean              float16\r\n",
        " 37  avg_c_mean                      float16\r\n",
        " 38  part_avg_c_mean                 uint8  \r\n",
        " 39  avg_c_per_u                     float16\r\n",
        " 40  user_answer_per_mean            float16\r\n",
        " 41  part_user_answer_per_mean       float16\r\n",
        " 42  content_lv                      float16\r\n",
        " 43  part_content_lv                 float16\r\n",
        " 44  last_correct_timelag            uint32 \r\n",
        " 45  last_incorrect_timelag          uint32 \r\n",
        " 46  is_like_answer                  float16\r\n",
        " 47  is_dislike_answer               float16\r\n",
        " 48  part_count_per                  float16\r\n",
        " 49  lr_count_per                    float16\r\n",
        " 50  p0_count_u                      uint32 \r\n",
        " 51  p0_mean_u                       float16\r\n",
        " 52  p1_count_u                      uint32 \r\n",
        " 53  p1_mean_u                       float16\r\n",
        " 54  p2_count_u                      uint32 \r\n",
        " 55  p2_mean_u                       float16\r\n",
        " 56  p3_count_u                      uint32 \r\n",
        " 57  p3_mean_u                       float16\r\n",
        " 58  p4_count_u                      uint32 \r\n",
        " 59  p4_mean_u                       float16\r\n",
        " 60  p5_count_u                      uint32 \r\n",
        " 61  p5_mean_u                       float16\r\n",
        " 62  p6_count_u                      uint32 \r\n",
        " 63  p6_mean_u                       float16\r\n",
        " 64  done_content_tag                uint8  \r\n",
        " 65  repeat_part_per                 float16\r\n",
        " 66  lag_mean                        float16\r\n",
        "dtypes: float16(26), float32(2), int16(2), int32(2), uint16(10), uint32(11), uint8(14)\r\n",
        "memory usage: 3.7 GB\r\n",
        "None\r\n",
        "Index                     128\r\n",
        "row_id              106971436\r\n",
        "timestamp           106971436\r\n",
        "user_id             106971436\r\n",
        "content_id           53485718\r\n",
        "                      ...    \r\n",
        "p6_count_u          106971436\r\n",
        "p6_mean_u            53485718\r\n",
        "done_content_tag     26742859\r\n",
        "repeat_part_per      53485718\r\n",
        "lag_mean             53485718\r\n",
        "Length: 68, dtype: int64\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAq6IhGbB5N9"
      },
      "source": [
        "TARGET = 'answered_correctly'\r\n",
        "FEATS = ['answered_correctly_avg_u','prior_root',#, 'answered_correctly_sum_u',, 'prior_question_had_explanation' \r\n",
        "         'answered_cumsum_u',#'q_elapsed_time_mean',#'prior_prior_question_elapsed_time_per','q_elapsed_time_per',\r\n",
        "         'answered_correctly_avg_c','avg_c_per_u','part_avg_c_mean','elapsed_time_per_mean','part_answered_cumsum_u',\r\n",
        "         'part','lag_mean','user_answer_per_mean','part_user_answer_per_mean',#'lag_time_per',\r\n",
        "         'count_u','prior_question_elapsed_time','lag_time','prior_avg_c',#'prior_prior_avg_c',#,'lag_day',,'is_same_prior_content'\r\n",
        "         'part_count_per','lr_count_per','part_elapsed_time_per_mean','last_incorrect_timelag','last_correct_timelag',\r\n",
        "         'p0_mean_u','p1_mean_u','p2_mean_u','p3_mean_u','p4_mean_u','p5_mean_u','p6_mean_u','done_content_tag','avg_c_mean',#'done_tags',\r\n",
        "         'content_id','lecture_count','content_lv','part_content_lv','is_same_prior','prior_content_diff',#'enc_tags'\r\n",
        "         'answered_diff_mean','prior_lag_time','prior_prior_lag_time','elapsed_lag_per','is_like_answer','is_dislike_answer','repeat_part_per']#,'lag_lag_time','lag_tail_half_mean'\r\n",
        "#categorical_feature:high-cardinalityなカテゴリ変数\r\n",
        "CATEGORICAL = ['part','content_id']\r\n",
        "dro_cols = list(set(train.columns) - set(FEATS))\r\n",
        "y_tr = train[TARGET]\r\n",
        "y_va = valid[TARGET]\r\n",
        "train.drop(dro_cols, axis=1, inplace=True)\r\n",
        "valid.drop(dro_cols, axis=1, inplace=True)\r\n",
        "_=gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYt01pOzB8Fw"
      },
      "source": [
        "num_cols = list(set(FEATS) - set(CATEGORICAL))\r\n",
        "for f in FEATS:\r\n",
        "    train[f] = train[f].values.astype(np.float32)\r\n",
        "    valid[f] = valid[f].values.astype(np.float32)\r\n",
        "_=gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KflgIDdYB9lJ"
      },
      "source": [
        "#MemorySpike前のclean up\r\n",
        "del answered_correctly_sum_u_dict,answered_correctly_cumsum_u_dict,answered_incorrectly_cumsum_u_dict\r\n",
        "del count_u_dict,parts_count_u_dict,parts_u_dict,user_content_dict, user_tags_dict\r\n",
        "del prior_lag_dict, prior_prior_lag_dict, avg_c_sum_u_dict,user_answer_per_sum_dict, parts_user_answer_per_sum_dict\r\n",
        "del lag_sum_dict,prior_time_dict,prior_time_per_sum_dict,parts_avg_c_dict,lect_u_dict\r\n",
        "del content_correct_user_mean_dict,content_correct_count_dict,parts_content_correct_user_mean_dict\r\n",
        "del last_correct_timestamp_dict,last_incorrect_timestamp_dict,like_answer_dict,like_answer_three_dict, dislike_answer_dict, dislike_answer_three_dict\r\n",
        "del parts_answered_correctly_cumsum_u_dict,parts_answered_incorrectly_cumsum_u_dict,user_repeat_count_dict\r\n",
        "\r\n",
        "valid.to_pickle('valid.pickle')\r\n",
        "del valid\r\n",
        "_=gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOwtj_McB-9i"
      },
      "source": [
        "# [Tips] https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/55325\r\n",
        "lgb_train = lgb.Dataset(train[FEATS], label=y_tr, feature_name=FEATS, categorical_feature=CATEGORICAL)\r\n",
        "print('Dataset Constructed')\r\n",
        "lgb_train.raw_data=None\r\n",
        "del train, y_tr\r\n",
        "_=gc.collect()\r\n",
        "lgb_train.save_binary('train_data.bin')\r\n",
        "lgb_train = lgb.Dataset('train_data.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMg4D5X-CAgS"
      },
      "source": [
        "valid = pd.read_pickle('valid.pickle')\r\n",
        "lgb_valid  = lgb.Dataset(valid[FEATS], label=y_va, feature_name=FEATS, categorical_feature=CATEGORICAL, reference=lgb_train)\r\n",
        "lgb_valid.raw_data=None\r\n",
        "_=gc.collect()\r\n",
        "lgb_valid.save_binary('valid_data.bin')\r\n",
        "lgb_valid = lgb.Dataset('valid_data.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYoiyWV0CB5M"
      },
      "source": [
        "'''\r\n",
        "Training until validation scores don't improve for 10 rounds\r\n",
        "[10]\ttraining's auc: 0.771457\tvalid_1's auc: 0.773254\r\n",
        "[20]\ttraining's auc: 0.776792\tvalid_1's auc: 0.778237\r\n",
        "[30]\ttraining's auc: 0.77924\tvalid_1's auc: 0.780527\r\n",
        "[40]\ttraining's auc: 0.781663\tvalid_1's auc: 0.782359\r\n",
        "[50]\ttraining's auc: 0.783615\tvalid_1's auc: 0.783822\r\n",
        "[60]\ttraining's auc: 0.785135\tvalid_1's auc: 0.784998\r\n",
        "[70]\ttraining's auc: 0.786532\tvalid_1's auc: 0.785971\r\n",
        "[80]\ttraining's auc: 0.787862\tvalid_1's auc: 0.786724\r\n",
        "[90]\ttraining's auc: 0.788684\tvalid_1's auc: 0.787326\r\n",
        "[100]\ttraining's auc: 0.789814\tvalid_1's auc: 0.787998\r\n",
        "[110]\ttraining's auc: 0.790783\tvalid_1's auc: 0.78862\r\n",
        "[120]\ttraining's auc: 0.791562\tvalid_1's auc: 0.789039\r\n",
        "[130]\ttraining's auc: 0.792353\tvalid_1's auc: 0.789446\r\n",
        "[140]\ttraining's auc: 0.793102\tvalid_1's auc: 0.789791\r\n",
        "[150]\ttraining's auc: 0.793807\tvalid_1's auc: 0.790098\r\n",
        "[160]\ttraining's auc: 0.794459\tvalid_1's auc: 0.79032\r\n",
        "[170]\ttraining's auc: 0.794939\tvalid_1's auc: 0.790598\r\n",
        "[180]\ttraining's auc: 0.795422\tvalid_1's auc: 0.790802\r\n",
        "[190]\ttraining's auc: 0.79589\tvalid_1's auc: 0.790938\r\n",
        "[200]\ttraining's auc: 0.796324\tvalid_1's auc: 0.791165\r\n",
        "[210]\ttraining's auc: 0.79669\tvalid_1's auc: 0.791364\r\n",
        "[220]\ttraining's auc: 0.797034\tvalid_1's auc: 0.791546\r\n",
        "[230]\ttraining's auc: 0.797332\tvalid_1's auc: 0.791711\r\n",
        "[240]\ttraining's auc: 0.797628\tvalid_1's auc: 0.791806\r\n",
        "[250]\ttraining's auc: 0.797834\tvalid_1's auc: 0.791886\r\n",
        "[260]\ttraining's auc: 0.798119\tvalid_1's auc: 0.79205\r\n",
        "[270]\ttraining's auc: 0.79832\tvalid_1's auc: 0.792104\r\n",
        "[280]\ttraining's auc: 0.798571\tvalid_1's auc: 0.792239\r\n",
        "[290]\ttraining's auc: 0.798764\tvalid_1's auc: 0.792327\r\n",
        "[300]\ttraining's auc: 0.798994\tvalid_1's auc: 0.792462\r\n",
        "[310]\ttraining's auc: 0.799199\tvalid_1's auc: 0.792573\r\n",
        "[320]\ttraining's auc: 0.799337\tvalid_1's auc: 0.792614\r\n",
        "[330]\ttraining's auc: 0.799499\tvalid_1's auc: 0.79267\r\n",
        "[340]\ttraining's auc: 0.799664\tvalid_1's auc: 0.792735\r\n",
        "[350]\ttraining's auc: 0.799802\tvalid_1's auc: 0.792778\r\n",
        "[360]\ttraining's auc: 0.799954\tvalid_1's auc: 0.792852\r\n",
        "[370]\ttraining's auc: 0.800113\tvalid_1's auc: 0.792922\r\n",
        "[380]\ttraining's auc: 0.800264\tvalid_1's auc: 0.792988\r\n",
        "[390]\ttraining's auc: 0.800418\tvalid_1's auc: 0.793066\r\n",
        "[400]\ttraining's auc: 0.800556\tvalid_1's auc: 0.793128\r\n",
        "[410]\ttraining's auc: 0.800692\tvalid_1's auc: 0.793165\r\n",
        "[420]\ttraining's auc: 0.800842\tvalid_1's auc: 0.793236\r\n",
        "[430]\ttraining's auc: 0.800973\tvalid_1's auc: 0.793294\r\n",
        "[440]\ttraining's auc: 0.801097\tvalid_1's auc: 0.793344\r\n",
        "[450]\ttraining's auc: 0.801238\tvalid_1's auc: 0.793414\r\n",
        "[460]\ttraining's auc: 0.801364\tvalid_1's auc: 0.793441\r\n",
        "[470]\ttraining's auc: 0.801504\tvalid_1's auc: 0.793494\r\n",
        "[480]\ttraining's auc: 0.80163\tvalid_1's auc: 0.793549\r\n",
        "[490]\ttraining's auc: 0.801747\tvalid_1's auc: 0.793594\r\n",
        "[500]\ttraining's auc: 0.801871\tvalid_1's auc: 0.793645\r\n",
        "[510]\ttraining's auc: 0.801976\tvalid_1's auc: 0.793667\r\n",
        "[520]\ttraining's auc: 0.802099\tvalid_1's auc: 0.793706\r\n",
        "[530]\ttraining's auc: 0.802214\tvalid_1's auc: 0.79373\r\n",
        "[540]\ttraining's auc: 0.802321\tvalid_1's auc: 0.793758\r\n",
        "[550]\ttraining's auc: 0.802421\tvalid_1's auc: 0.793775\r\n",
        "[560]\ttraining's auc: 0.802532\tvalid_1's auc: 0.793807\r\n",
        "[570]\ttraining's auc: 0.80264\tvalid_1's auc: 0.793844\r\n",
        "[580]\ttraining's auc: 0.80275\tvalid_1's auc: 0.793865\r\n",
        "[590]\ttraining's auc: 0.802856\tvalid_1's auc: 0.793901\r\n",
        "[600]\ttraining's auc: 0.802957\tvalid_1's auc: 0.793925\r\n",
        "[610]\ttraining's auc: 0.803067\tvalid_1's auc: 0.793965\r\n",
        "[620]\ttraining's auc: 0.803182\tvalid_1's auc: 0.794009\r\n",
        "[630]\ttraining's auc: 0.803288\tvalid_1's auc: 0.794046\r\n",
        "[640]\ttraining's auc: 0.803392\tvalid_1's auc: 0.794071\r\n",
        "[650]\ttraining's auc: 0.803492\tvalid_1's auc: 0.794098\r\n",
        "[660]\ttraining's auc: 0.803582\tvalid_1's auc: 0.794113\r\n",
        "[670]\ttraining's auc: 0.803689\tvalid_1's auc: 0.794155\r\n",
        "[680]\ttraining's auc: 0.803782\tvalid_1's auc: 0.794163\r\n",
        "[690]\ttraining's auc: 0.803875\tvalid_1's auc: 0.794178\r\n",
        "[700]\ttraining's auc: 0.803977\tvalid_1's auc: 0.794207\r\n",
        "[710]\ttraining's auc: 0.804071\tvalid_1's auc: 0.794229\r\n",
        "[720]\ttraining's auc: 0.804159\tvalid_1's auc: 0.79425\r\n",
        "[730]\ttraining's auc: 0.804247\tvalid_1's auc: 0.794266\r\n",
        "[740]\ttraining's auc: 0.804344\tvalid_1's auc: 0.794292\r\n",
        "[750]\ttraining's auc: 0.804428\tvalid_1's auc: 0.794302\r\n",
        "[760]\ttraining's auc: 0.804517\tvalid_1's auc: 0.794317\r\n",
        "[770]\ttraining's auc: 0.804603\tvalid_1's auc: 0.794337\r\n",
        "[780]\ttraining's auc: 0.80469\tvalid_1's auc: 0.794349\r\n",
        "[790]\ttraining's auc: 0.804774\tvalid_1's auc: 0.794358\r\n",
        "[800]\ttraining's auc: 0.804854\tvalid_1's auc: 0.794363\r\n",
        "[810]\ttraining's auc: 0.804941\tvalid_1's auc: 0.794375\r\n",
        "[820]\ttraining's auc: 0.805033\tvalid_1's auc: 0.794391\r\n",
        "[830]\ttraining's auc: 0.805117\tvalid_1's auc: 0.794397\r\n",
        "[840]\ttraining's auc: 0.805202\tvalid_1's auc: 0.794419\r\n",
        "[850]\ttraining's auc: 0.805284\tvalid_1's auc: 0.794427\r\n",
        "[860]\ttraining's auc: 0.805372\tvalid_1's auc: 0.794442\r\n",
        "[870]\ttraining's auc: 0.805445\tvalid_1's auc: 0.794449\r\n",
        "[880]\ttraining's auc: 0.805524\tvalid_1's auc: 0.794461\r\n",
        "[890]\ttraining's auc: 0.805599\tvalid_1's auc: 0.794467\r\n",
        "[900]\ttraining's auc: 0.805678\tvalid_1's auc: 0.794474\r\n",
        "[910]\ttraining's auc: 0.805767\tvalid_1's auc: 0.794486\r\n",
        "[920]\ttraining's auc: 0.805854\tvalid_1's auc: 0.794504\r\n",
        "[930]\ttraining's auc: 0.80593\tvalid_1's auc: 0.79451\r\n",
        "[940]\ttraining's auc: 0.806008\tvalid_1's auc: 0.794517\r\n",
        "[950]\ttraining's auc: 0.806091\tvalid_1's auc: 0.794528\r\n",
        "[960]\ttraining's auc: 0.80617\tvalid_1's auc: 0.794535\r\n",
        "[970]\ttraining's auc: 0.806254\tvalid_1's auc: 0.794554\r\n",
        "[980]\ttraining's auc: 0.806342\tvalid_1's auc: 0.794568\r\n",
        "[990]\ttraining's auc: 0.806415\tvalid_1's auc: 0.794575\r\n",
        "[1000]\ttraining's auc: 0.806486\tvalid_1's auc: 0.794576\r\n",
        "[1010]\ttraining's auc: 0.80656\tvalid_1's auc: 0.794588\r\n",
        "[1020]\ttraining's auc: 0.806635\tvalid_1's auc: 0.794594\r\n",
        "[1030]\ttraining's auc: 0.806703\tvalid_1's auc: 0.794602\r\n",
        "[1040]\ttraining's auc: 0.806768\tvalid_1's auc: 0.794603\r\n",
        "[1050]\ttraining's auc: 0.806855\tvalid_1's auc: 0.794613\r\n",
        "[1060]\ttraining's auc: 0.80694\tvalid_1's auc: 0.794624\r\n",
        "[1070]\ttraining's auc: 0.807018\tvalid_1's auc: 0.794627\r\n",
        "[1080]\ttraining's auc: 0.807093\tvalid_1's auc: 0.794637\r\n",
        "[1090]\ttraining's auc: 0.807166\tvalid_1's auc: 0.794638\r\n",
        "[1100]\ttraining's auc: 0.807245\tvalid_1's auc: 0.794647\r\n",
        "[1110]\ttraining's auc: 0.807322\tvalid_1's auc: 0.794659\r\n",
        "[1120]\ttraining's auc: 0.807397\tvalid_1's auc: 0.794664\r\n",
        "[1130]\ttraining's auc: 0.807483\tvalid_1's auc: 0.794665\r\n",
        "[1140]\ttraining's auc: 0.807551\tvalid_1's auc: 0.794666\r\n",
        "[1150]\ttraining's auc: 0.807628\tvalid_1's auc: 0.794675\r\n",
        "[1160]\ttraining's auc: 0.807716\tvalid_1's auc: 0.794685\r\n",
        "[1170]\ttraining's auc: 0.807791\tvalid_1's auc: 0.794695\r\n",
        "[1180]\ttraining's auc: 0.807868\tvalid_1's auc: 0.794709\r\n",
        "[1190]\ttraining's auc: 0.807942\tvalid_1's auc: 0.794717\r\n",
        "[1200]\ttraining's auc: 0.808015\tvalid_1's auc: 0.794724\r\n",
        "[1210]\ttraining's auc: 0.808079\tvalid_1's auc: 0.794726\r\n",
        "[1220]\ttraining's auc: 0.808146\tvalid_1's auc: 0.794734\r\n",
        "[1230]\ttraining's auc: 0.808213\tvalid_1's auc: 0.794737\r\n",
        "[1240]\ttraining's auc: 0.808284\tvalid_1's auc: 0.79474\r\n",
        "[1250]\ttraining's auc: 0.808348\tvalid_1's auc: 0.794745\r\n",
        "[1260]\ttraining's auc: 0.808425\tvalid_1's auc: 0.794763\r\n",
        "[1270]\ttraining's auc: 0.808496\tvalid_1's auc: 0.794771\r\n",
        "[1280]\ttraining's auc: 0.808561\tvalid_1's auc: 0.794781\r\n",
        "Early stopping, best iteration is:\r\n",
        "[1279]\ttraining's auc: 0.808556\tvalid_1's auc: 0.794781\r\n",
        "'''\r\n",
        "\r\n",
        "start = datetime.datetime.now()\r\n",
        "\r\n",
        "params = {\r\n",
        "'num_leaves': 350,\r\n",
        "'max_bin':700,\r\n",
        "'min_child_weight': 0.03454472573214212,\r\n",
        "'feature_fraction': 0.58,\r\n",
        "'bagging_fraction': 0.58,\r\n",
        "'objective': 'binary',\r\n",
        "'max_depth': 16,\r\n",
        "'learning_rate': 0.05,\r\n",
        "\"boosting_type\": \"gbdt\",\r\n",
        "\"bagging_seed\": 11,\r\n",
        "\"metric\": 'auc',\r\n",
        "\"verbosity\": -1,\r\n",
        "'reg_alpha': 0.3899927210061127,\r\n",
        "'reg_lambda': 0.6485237330340494,\r\n",
        "'random_state': 47,\r\n",
        "}\r\n",
        "\r\n",
        "if debug:\r\n",
        "    params['learning_rate'] = 0.07\r\n",
        "\r\n",
        "file = 'lgb.pkl'\r\n",
        "if build:\r\n",
        "    model = lgb.train(params,\r\n",
        "                    lgb_train,\r\n",
        "                    valid_sets=[lgb_train, lgb_valid],\r\n",
        "                    verbose_eval=10,\r\n",
        "                    num_boost_round=2000,\r\n",
        "                    early_stopping_rounds=10\r\n",
        "                )\r\n",
        "    display(pd.DataFrame(model.feature_importance(), index=FEATS, columns=['importance']).sort_values('importance',ascending=False))\r\n",
        "    pickle.dump(model, open(file, 'wb'))\r\n",
        "    del model\r\n",
        "    _=gc.collect()\r\n",
        "else:\r\n",
        "    file = root + 'lgb.pkl'\r\n",
        "    model = pickle.load(open(file, 'rb')) \r\n",
        "\r\n",
        "print('train phase =',(datetime.datetime.now() - start))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}