{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M5 Forecasting - Accuracy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOUlWkBMOzfGreCjRvEtfFW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pea-sys/Kaggle_Public/blob/master/M5_Forecasting_Accuracy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmEkntw0aZv9",
        "colab_type": "text"
      },
      "source": [
        "# M5 Forecasting - Accuracy(結果:152/5380 上位3%以内のためSilver Medal)\n",
        "\n",
        "★今回のコンペでソロ参加銀メダル2枚目となりKaggle Expertになりました。  \n",
        "  機械学習を独学で0から学んで一年半かかりました。\n",
        "　\n",
        "\n",
        "##【概要】(※Official和訳)\n",
        "第5回目となる今回は、世界最大の売上高を誇るウォルマートの売上データを使って、今後28日間の日次売上高を予測します。  \n",
        "データは、3つの米国（カリフォルニア、テキサス、ウィスコンシン）の店舗をカバーし、アイテムレベル、部門、製品カテゴリ、店舗の詳細が含まれています。  \n",
        "さらに、価格、プロモーション、曜日、特別イベントなどの説明変数も含まれています。これらを合わせて、このロバストなデータセットを使用することで、予測精度を向上させることができます。\n",
        "\n",
        "成功すれば、あなたの研究は予測の理論と実践を前進させ続けることになります。  使用される手法は、適切な在庫やサービスレベルの設定など、様々なビジネス分野に応用することができます。財務省は、ビジネス支援とトレーニングを通じて、ツールと知識の普及を支援し、他の人たちがより正確で校正された予測を達成し、無駄を省き、不確実性とそのリスクの意味を理解できるようにしていきたいと考えています。\n",
        "\n",
        "## 評価指標\n",
        "このコンペティションでは、加重根平均二乗尺度誤差（RMSSE）を使用しています。  \n",
        "\n",
        "[メトリック、スケーリング、重み付けについての詳細](https://mofc.unic.ac.cy/m5-competition/)  \n",
        "※特殊な評価指標。モデルを学習させる際にはRMSEによる売り上げ数予測にしました\n",
        "\n",
        "## データセット\n",
        "[こちら](https://www.kaggle.com/c/m5-forecasting-accuracy/data?select=sales_train_validation.csv)からダウンロード可能\n",
        "※何も考慮せずに訓練用にデータ加工等するとメモリに載せるのが大変なレべル\n",
        "\n",
        "## スケジュール\n",
        "正確には覚えていない。\n",
        "私は3月26日から6月30日まで、ちょこちょこ休みなく取り組み続けていた。\n",
        "\n",
        "★活動記録  \n",
        "今回はあまり記録を残していない。    \n",
        "LBとCVの相関は確保できないことが分かっていたので  \n",
        "取り合えずTrustCVを言い聞かせ頑張った\n",
        "\n",
        "## ●やったことメモ  \n",
        "\n",
        "#### -- Base\n",
        "*   [こちら](https://www.kaggle.com/kyakovlev/m5-three-shades-of-dark-darker-magic)のカーネルを流用\n",
        "\n",
        "\n",
        "#### -- FE\n",
        "*   価格弾力性やsnapの統合  \n",
        " ※価格弾力性は在庫切れや店休日などで売上0になる日があるので、\n",
        "最小値の代わりに平均値を利用\n",
        "\n",
        "* Discussionを参考に価格の下一桁と下二桁を特徴化\n",
        " [ネタ元](https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/145011)\n",
        "\n",
        "* 敢えて価格が一意のアイテムの価格特徴量をNaNで埋める(平均や分散等) \n",
        "\n",
        "* 月や週の特徴量変換  \n",
        "[ネタ元](https://qiita.com/shimopino/items/4ef78aa589e43f315113)\n",
        "\n",
        "* snap前後一日を特徴化\n",
        "\n",
        "* 米国サマータイムの特徴量追加\n",
        "\n",
        "[未使用]\n",
        "\n",
        "* 0スパイク期間が共通するアイテムのグループ化(cumsum)\n",
        "　※これは結局使わなかった\n",
        "\n",
        "* イベントや祝日前後日の特徴量\n",
        "\n",
        "* 各店舗の各カテゴリー内での価格偏差値\n",
        "\n",
        "#### -- Model\n",
        "\n",
        "* 以下の２つのモデルをアンサンブル  \n",
        "  1.   2014年以前のデータのweight=0にしたLGBMモデル\n",
        "  2.   学習データ全てをweight=1にしたLGBMモデル\n",
        "\n",
        "  全てのアイテムを無条件にアンサンブルしたわけではなく、予測日から遡り数日間売上0になっているアイテムのみアンサンブルした。  \n",
        "  理由はモデル1は直近の値を重視しすぎて、0が連続した場合に予測値が低くなりすぎる傾向があったため。\n",
        "\n",
        "#### -- Validation\n",
        "* validation scoreが信頼しきれなかったので予測結果をプロット図でひたすら見る  \n",
        "　※すべては見ていないが二万個程度のプロット図は確認した。上記アンサンブルのヒントになった\n",
        "* 一応効くだろうと思ったFEが効いていたので、全くvalidationを信じていないわけではなかった\n",
        "\n",
        "\n",
        "#### -- PostProcess\n",
        "* 実務ではNGだと思うが、1.05乗数した。\n",
        "  これは月毎の5月から6月にかけての売上比が予測箇所だけ低かったため。LGBMのため、外挿出来ない代りのようなお気持ちで使用した。ちょっと実務だと使えるか怪しいが、係数をかけているノートブックが沢山あったため使用に踏み切った。\n",
        "\n",
        "\n",
        "\n",
        "# 感想\n",
        "ASHRAEの雪辱を晴らせたので良かった。概ねやったことの多くは精度に貢献した。\n",
        "今回は割とメダル取れる自信はあったので、締め切り三日前位にはやることが終わっていた。特徴量を追加してもほとんど良化しなかったが、2014年以下のweightを0にした途端に効き始めて、みるみるバリデーションスコアが下がってき楽しかった。  \n",
        "不思議なのが、2014年以下のデータをweight=0にした時と、ドロップした時でrmseが大きく違っていた理由が最後まで分からずじまいだった。  \n",
        "GoogleDriveのダウンロード制限に引っかかって12時間ダウンロードできない制限があることを知れてよかった。  \n",
        "今回のコンペは時系列+LB機能しない+final sub1つだけで、検証が困難なコンペだった様に思う。  \n",
        "LGBMのweightについては、明日以降に理解を深めようと思う。\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12n45REWZL8c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "a2807742-a2ad-4b27-d7e3-781e945e9d4a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul  1 11:15:17 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvGrLSb-pbZe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "97393fc1-0daf-4879-f786-5f4b8abfe712"
      },
      "source": [
        "\n",
        "!git clone --recursive https://github.com/Microsoft/LightGBM\n",
        "%cd /content/LightGBM/\n",
        "!mkdir build\n",
        "!cmake -DUSE_GPU=1 #avoid ..\n",
        "!make -j$(nproc)\n",
        "!sudo apt-get -y install python-pip\n",
        "!sudo -H pip install setuptools pandas numpy scipy scikit-learn -U\n",
        "%cd /content/LightGBM/python-package\n",
        "!sudo python setup.py install --precompile\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'LightGBM'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 18291 (delta 0), reused 0 (delta 0), pack-reused 18286\u001b[K\n",
            "Receiving objects: 100% (18291/18291), 12.28 MiB | 28.79 MiB/s, done.\n",
            "Resolving deltas: 100% (13362/13362), done.\n",
            "Submodule 'include/boost/compute' (https://github.com/boostorg/compute) registered for path 'compute'\n",
            "Cloning into '/content/LightGBM/compute'...\n",
            "remote: Enumerating objects: 21728, done.        \n",
            "remote: Total 21728 (delta 0), reused 0 (delta 0), pack-reused 21728        \n",
            "Receiving objects: 100% (21728/21728), 8.51 MiB | 27.48 MiB/s, done.\n",
            "Resolving deltas: 100% (17565/17565), done.\n",
            "Submodule path 'compute': checked out '36c89134d4013b2e5e45bc55656a18bd6141995a'\n",
            "/content/LightGBM\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
            "-- Looking for CL_VERSION_2_2\n",
            "-- Looking for CL_VERSION_2_2 - found\n",
            "-- Found OpenCL: /usr/lib/x86_64-linux-gnu/libOpenCL.so (found version \"2.2\") \n",
            "-- OpenCL include directory: /usr/include\n",
            "-- Boost version: 1.65.1\n",
            "-- Found the following Boost libraries:\n",
            "--   filesystem\n",
            "--   system\n",
            "-- Performing Test MM_PREFETCH\n",
            "-- Performing Test MM_PREFETCH - Success\n",
            "-- Using _mm_prefetch\n",
            "-- Performing Test MM_MALLOC\n",
            "-- Performing Test MM_MALLOC - Success\n",
            "-- Using _mm_malloc\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/LightGBM\n",
            "\u001b[35m\u001b[1mScanning dependencies of target _lightgbm\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target lightgbm\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/application/application.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 79%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
            "[ 93%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 96%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/c_api.cpp.o\u001b[0m\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable lightgbm\u001b[0m\n",
            "[ 98%] Built target lightgbm\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared library lib_lightgbm.so\u001b[0m\n",
            "[100%] Built target _lightgbm\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
            "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
            "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
            "  python-keyrings.alt python-pip-whl python-pkg-resources python-secretstorage\n",
            "  python-setuptools python-six python-wheel python-xdg\n",
            "Suggested packages:\n",
            "  python-crypto-doc python-cryptography-doc python-cryptography-vectors\n",
            "  python-dbus-dbg python-dbus-doc python-enum34-doc python-gi-cairo\n",
            "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0 python-fs\n",
            "  python-gdata python-keyczar python-secretstorage-doc python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
            "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
            "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
            "  python-keyrings.alt python-pip python-pip-whl python-pkg-resources\n",
            "  python-secretstorage python-setuptools python-six python-wheel python-xdg\n",
            "0 upgraded, 22 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 3,376 kB of archives.\n",
            "After this operation, 10.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpython-all-dev amd64 2.7.15~rc1-1 [1,092 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all amd64 2.7.15~rc1-1 [1,076 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all-dev amd64 2.7.15~rc1-1 [1,100 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-asn1crypto all 0.24.0-1 [72.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-cffi-backend amd64 1.11.5-1 [63.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-enum34 all 1.1.6-2 [34.8 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-idna all 2.6-1 [32.4 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-ipaddress all 1.0.17-1 [18.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-cryptography amd64 2.1.4-1ubuntu1.3 [221 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-dbus amd64 1.2.6-1 [90.2 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-gi amd64 3.26.1-2ubuntu1 [197 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-secretstorage all 2.3.1-2 [11.8 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyring all 10.6.0-1 [30.6 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyrings.alt all 3.0-1 [16.7 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.1 [1,653 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip all 9.0.1-2.3~ubuntu1.18.04.1 [151 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-setuptools all 39.0.1-2 [329 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-wheel all 0.30.0-0.2 [36.4 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-xdg all 0.25-4ubuntu1 [31.3 kB]\n",
            "Fetched 3,376 kB in 1s (3,326 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 22.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython-all-dev:amd64.\n",
            "(Reading database ... 144379 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libpython-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-all.\n",
            "Preparing to unpack .../01-python-all_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking python-all (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-all-dev.\n",
            "Preparing to unpack .../02-python-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking python-all-dev (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-asn1crypto.\n",
            "Preparing to unpack .../03-python-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python-cffi-backend.\n",
            "Preparing to unpack .../04-python-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python-crypto.\n",
            "Preparing to unpack .../05-python-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
            "Unpacking python-crypto (2.6.1-8ubuntu2) ...\n",
            "Selecting previously unselected package python-enum34.\n",
            "Preparing to unpack .../06-python-enum34_1.1.6-2_all.deb ...\n",
            "Unpacking python-enum34 (1.1.6-2) ...\n",
            "Selecting previously unselected package python-idna.\n",
            "Preparing to unpack .../07-python-idna_2.6-1_all.deb ...\n",
            "Unpacking python-idna (2.6-1) ...\n",
            "Selecting previously unselected package python-ipaddress.\n",
            "Preparing to unpack .../08-python-ipaddress_1.0.17-1_all.deb ...\n",
            "Unpacking python-ipaddress (1.0.17-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../09-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-cryptography.\n",
            "Preparing to unpack .../10-python-cryptography_2.1.4-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking python-cryptography (2.1.4-1ubuntu1.3) ...\n",
            "Selecting previously unselected package python-dbus.\n",
            "Preparing to unpack .../11-python-dbus_1.2.6-1_amd64.deb ...\n",
            "Unpacking python-dbus (1.2.6-1) ...\n",
            "Selecting previously unselected package python-gi.\n",
            "Preparing to unpack .../12-python-gi_3.26.1-2ubuntu1_amd64.deb ...\n",
            "Unpacking python-gi (3.26.1-2ubuntu1) ...\n",
            "Selecting previously unselected package python-secretstorage.\n",
            "Preparing to unpack .../13-python-secretstorage_2.3.1-2_all.deb ...\n",
            "Unpacking python-secretstorage (2.3.1-2) ...\n",
            "Selecting previously unselected package python-keyring.\n",
            "Preparing to unpack .../14-python-keyring_10.6.0-1_all.deb ...\n",
            "Unpacking python-keyring (10.6.0-1) ...\n",
            "Selecting previously unselected package python-keyrings.alt.\n",
            "Preparing to unpack .../15-python-keyrings.alt_3.0-1_all.deb ...\n",
            "Unpacking python-keyrings.alt (3.0-1) ...\n",
            "Selecting previously unselected package python-pip-whl.\n",
            "Preparing to unpack .../16-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.1_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
            "Selecting previously unselected package python-pip.\n",
            "Preparing to unpack .../17-python-pip_9.0.1-2.3~ubuntu1.18.04.1_all.deb ...\n",
            "Unpacking python-pip (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../18-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-setuptools.\n",
            "Preparing to unpack .../19-python-setuptools_39.0.1-2_all.deb ...\n",
            "Unpacking python-setuptools (39.0.1-2) ...\n",
            "Selecting previously unselected package python-wheel.\n",
            "Preparing to unpack .../20-python-wheel_0.30.0-0.2_all.deb ...\n",
            "Unpacking python-wheel (0.30.0-0.2) ...\n",
            "Selecting previously unselected package python-xdg.\n",
            "Preparing to unpack .../21-python-xdg_0.25-4ubuntu1_all.deb ...\n",
            "Unpacking python-xdg (0.25-4ubuntu1) ...\n",
            "Setting up python-idna (2.6-1) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
            "Setting up python-asn1crypto (0.24.0-1) ...\n",
            "Setting up python-crypto (2.6.1-8ubuntu2) ...\n",
            "Setting up python-wheel (0.30.0-0.2) ...\n",
            "Setting up libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-cffi-backend (1.11.5-1) ...\n",
            "Setting up python-gi (3.26.1-2ubuntu1) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-enum34 (1.1.6-2) ...\n",
            "Setting up python-dbus (1.2.6-1) ...\n",
            "Setting up python-ipaddress (1.0.17-1) ...\n",
            "Setting up python-pip (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
            "Setting up python-all (2.7.15~rc1-1) ...\n",
            "Setting up python-xdg (0.25-4ubuntu1) ...\n",
            "Setting up python-setuptools (39.0.1-2) ...\n",
            "Setting up python-keyrings.alt (3.0-1) ...\n",
            "Setting up python-all-dev (2.7.15~rc1-1) ...\n",
            "Setting up python-cryptography (2.1.4-1ubuntu1.3) ...\n",
            "Setting up python-secretstorage (2.3.1-2) ...\n",
            "Setting up python-keyring (10.6.0-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (47.3.1)\n",
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
            "Collecting numpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/0b/71ae818646c1a80fbe6776d41f480649523ed31243f1f34d9d7e41d70195/numpy-1.19.0-cp36-cp36m-manylinux2010_x86_64.whl (14.6MB)\n",
            "\u001b[K     |████████████████████████████████| 14.6MB 186kB/s \n",
            "\u001b[?25hCollecting scipy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/20/d4410683e4d416a11ebc60138f6d925f571ffcfcc3794baf78fff982c98d/scipy-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (25.9MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9MB 117kB/s \n",
            "\u001b[?25hCollecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/3a/eb8d7bbe28f4787d140bb9df685b7d5bf6115c0e2a969def4027144e98b6/scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 141kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.15.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.5.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, scipy, threadpoolctl, scikit-learn\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed numpy-1.19.0 scikit-learn-0.23.1 scipy-1.5.0 threadpoolctl-2.1.0\n",
            "/content/LightGBM/python-package\n",
            "running install\n",
            "running build\n",
            "running build_py\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/lightgbm\n",
            "copying lightgbm/engine.py -> build/lib/lightgbm\n",
            "copying lightgbm/compat.py -> build/lib/lightgbm\n",
            "copying lightgbm/plotting.py -> build/lib/lightgbm\n",
            "copying lightgbm/sklearn.py -> build/lib/lightgbm\n",
            "copying lightgbm/basic.py -> build/lib/lightgbm\n",
            "copying lightgbm/libpath.py -> build/lib/lightgbm\n",
            "copying lightgbm/callback.py -> build/lib/lightgbm\n",
            "copying lightgbm/__init__.py -> build/lib/lightgbm\n",
            "running egg_info\n",
            "creating lightgbm.egg-info\n",
            "writing lightgbm.egg-info/PKG-INFO\n",
            "writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
            "writing requirements to lightgbm.egg-info/requires.txt\n",
            "writing top-level names to lightgbm.egg-info/top_level.txt\n",
            "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "no previously-included directories found matching 'build'\n",
            "warning: no files found matching 'LICENSE'\n",
            "warning: no files found matching '*.txt'\n",
            "warning: no files found matching '*.so' under directory 'lightgbm'\n",
            "warning: no files found matching '*.txt' under directory 'compile'\n",
            "warning: no files found matching '*.so' under directory 'compile'\n",
            "warning: no files found matching '*.dll' under directory 'compile/Release'\n",
            "warning: no files found matching '*' under directory 'compile/compute'\n",
            "warning: no files found matching '*' under directory 'compile/include'\n",
            "warning: no files found matching '*' under directory 'compile/src'\n",
            "warning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\n",
            "warning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\n",
            "warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
            "warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
            "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "copying lightgbm/VERSION.txt -> build/lib/lightgbm\n",
            "running install_lib\n",
            "copying build/lib/lightgbm/VERSION.txt -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/engine.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/compat.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/plotting.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/sklearn.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/basic.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/libpath.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/callback.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/__init__.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "INFO:LightGBM:Installing lib_lightgbm from: ['../lib_lightgbm.so']\n",
            "copying ../lib_lightgbm.so -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/engine.py to engine.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/compat.py to compat.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/plotting.py to plotting.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/sklearn.py to sklearn.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/basic.py to basic.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/libpath.py to libpath.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/callback.py to callback.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/__init__.py to __init__.cpython-36.pyc\n",
            "running install_egg_info\n",
            "Copying lightgbm.egg-info to /usr/local/lib/python3.6/dist-packages/lightgbm-2.3.2-py3.6.egg-info\n",
            "running install_scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U26zFxJiZn2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f85c12f-67f1-4bce-ea4d-1cce9fd05a3c"
      },
      "source": [
        "'''\n",
        "!pip install -U lightgbm \n",
        "#バギングに不具合があり学習が遅いとのこと\n",
        "#https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/148273\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'\\n!pip install -U lightgbm \\n#バギングに不具合があり学習が遅いとのこと\\n#https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/148273\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG5gSn5iZqJ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "f9ef6282-def0-4377-8732-16bfa4ef24da"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfMAU7lyZsDW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "46594ae8-c934-49ba-c289-f29cd8708515"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/m5-stage"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/m5-stage\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BSLK_AEYoQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, sys, gc, time, warnings, pickle, psutil, random\n",
        "\n",
        "# custom imports\n",
        "from multiprocessing import Pool        # Multiprocess Runs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPs5ZF-5ZNjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################### ヘルパー\n",
        "#################################################################################\n",
        "## シード生成\n",
        "# ：すべてのプロセスを確定的にするためのシード     # type: int\n",
        "def seed_everything(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    \n",
        "## マルチプロセス実行\n",
        "def df_parallelize_run(func, t_split):\n",
        "    num_cores = np.min([N_CORES,len(t_split)])\n",
        "    pool = Pool(num_cores)\n",
        "    df = pd.concat(pool.map(func, t_split), axis=1)\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDZsWW4qtl2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import calendar\n",
        "from datetime import datetime as dt\n",
        "def get_nth_week2(year, month, day, firstweekday=0):\n",
        "    first_dow = calendar.monthrange(year, month)[0] + 1\n",
        "    if first_dow == 7:\n",
        "      first_dow = 0\n",
        "    offset = (first_dow - firstweekday) % 7\n",
        "    return (day + offset - 1) // 7 + 1\n",
        "def encode(df, col):\n",
        "    # この方法だと場合によって最大値が変化するデータでは正確な値は出ない\n",
        "    # 例：月の日数が30日や31日の場合がある\n",
        "    df[col + '_cos'] = np.cos(2 * np.pi * df[col] / df[col].max())\n",
        "    df[col + '_sin'] = np.sin(2 * np.pi * df[col] / df[col].max())\n",
        "    return df\n",
        "\n",
        "def original_fea(data):\n",
        "  sscaler = StandardScaler()\n",
        "  sscaler.fit(data['tm_d'].values.reshape(-1, 1))           # xの平均と分散を計算\n",
        "  y = sscaler.transform(data['tm_d'].values.reshape(-1, 1)) # xを変換\n",
        "\n",
        "  data['tm_d'] = y\n",
        "  data['tm_d'] = data['tm_d'].astype('float16')\n",
        "  del y\n",
        "  '''\n",
        "  #食品以外はSnap関係ないので落とす\n",
        "  for s in ['snap_CA','snap_TX','snap_WI']:\n",
        "    data.loc[(data['cat_id']!='FOODS') & (data[s]==1),s]=0\n",
        "  '''\n",
        "  #Snapカラムをまとめる\n",
        "  data['snap'] = 0\n",
        "  data.loc[(data['id'].astype(str).str.contains('CA')) & (data['snap_CA']==1),'snap'] = 1\n",
        "  data.loc[(data['id'].astype(str).str.contains('TX')) & (data['snap_TX']==1),'snap'] = 1\n",
        "  data.loc[(data['id'].astype(str).str.contains('WI')) & (data['snap_WI']==1),'snap'] = 1\n",
        "  data['snap'] = data['snap'].astype(\"int8\")\n",
        "  del data['snap_CA'],data['snap_TX'],data['snap_WI']\n",
        "  \n",
        "  #Snap周辺　CV は上がった\n",
        "  #CA snap 1-10\n",
        "  #TX 2,4,8,10,14を除いた1-15\n",
        "  #WI 1,4,7,10,13を除いた1-15\n",
        "  data.loc[(data['id'].astype(str).str.contains('CA')) & (data['tm_d'].isin([11])),'snap'] = 2\n",
        "  data.loc[(data['id'].astype(str).str.contains('TX')) & (data['tm_d'].isin([2,4,8,10,14,16])),'snap'] = 2\n",
        "  data.loc[(data['id'].astype(str).str.contains('WI')) & (data['tm_d'].isin([1,4,7,10,13,16])),'snap'] = 2\n",
        "  #data['snap'] = data['snap'].astype(\"category\")\n",
        "\n",
        "  '''\n",
        "  data['event_name_1'] = data['event_name_1'].astype(str)\n",
        "  data['event_type_1'] = data['event_type_1'].astype(str)\n",
        "  data.loc[(data['tm_m'] == 3) & (data['tm_d'] == 31) & (data['id'].astype(str).str.contains('CA')),'event_name_1'] = 'CA Holiday'\n",
        "  data.loc[(data['tm_m'] == 3) & (data['tm_d'] == 31) & (data['id'].astype(str).str.contains('CA')),'event_type_1'] = 'National'\n",
        "  data.loc[(data['tm_y'] == 0) & (data['tm_m'] == 11) & (data['tm_d'] == 27),'event_name_1'] = 'Black Friday'\n",
        "  data.loc[(data['tm_y'] == 0) & (data['tm_m'] == 11) & (data['tm_d'] == 27),'event_type_1'] = 'Cultural'\n",
        "  data.loc[(data['tm_y'] == 1) & (data['tm_m'] == 11) & (data['tm_d'] == 23),'event_name_1'] = 'Black Friday'\n",
        "  data.loc[(data['tm_y'] == 1) & (data['tm_m'] == 11) & (data['tm_d'] == 23),'event_type_1'] = 'Cultural'\n",
        "  data.loc[(data['tm_y'] == 2) & (data['tm_m'] == 11) & (data['tm_d'] == 27),'event_name_1'] = 'Black Friday'\n",
        "  data.loc[(data['tm_y'] == 2) & (data['tm_m'] == 11) & (data['tm_d'] == 27),'event_type_1'] = 'Cultural'\n",
        "  data.loc[(data['tm_y'] == 3) & (data['tm_m'] == 11) & (data['tm_d'] == 28),'event_name_1'] = 'Black Friday'\n",
        "  data.loc[(data['tm_y'] == 3) & (data['tm_m'] == 11) & (data['tm_d'] == 28),'event_type_1'] = 'Cultural'\n",
        "  data.loc[(data['tm_y'] == 4) & (data['tm_m'] == 11) & (data['tm_d'] == 27),'event_name_1'] = 'Black Friday'\n",
        "  data.loc[(data['tm_y'] == 4) & (data['tm_m'] == 11) & (data['tm_d'] == 27),'event_type_1'] = 'Cultural'\n",
        "  data['event_name_1'] = data['event_name_1'].astype(\"category\")\n",
        "  data['event_type_1'] = data['event_type_1'].astype(\"category\")\n",
        "  '''\n",
        "  '''\n",
        "  data['event_name_1'] = data['event_name_1'].astype(str)\n",
        "  bfr = data[~data['event_name_1'].isnull()]['d'].unique() - 1\n",
        "  aft = data[~data['event_name_1'].isnull()]['d'].unique() + 1\n",
        "  data.loc[(data['d'].isin(bfr)) & (data['event_name_1'].isnull()),'event_name_1'] = 'Before'\n",
        "  data.loc[(data['d'].isin(aft)) & (data['event_name_1'].isnull()),'event_name_1'] = 'After'\n",
        "  data['event_name_1'] = data['event_name_1'].astype(\"category\")\n",
        "\n",
        "  data.loc[(data['tm_m'] == 3) & (data['tm_d'] == 31) & (data['id'].astype(str).str.contains('CA')),\"wday\"] = 0\n",
        "  data.loc[(data['tm_y'] == 0) & (data['tm_m'] == 11) & (data['tm_d'] == 27),\"wday\"] = 0\n",
        "  data.loc[(data['tm_y'] == 1) & (data['tm_m'] == 11) & (data['tm_d'] == 23),\"wday\"] = 0\n",
        "  data.loc[(data['tm_y'] == 2) & (data['tm_m'] == 11) & (data['tm_d'] == 27),\"wday\"] = 0\n",
        "  data.loc[(data['tm_y'] == 3) & (data['tm_m'] == 11) & (data['tm_d'] == 28),\"wday\"] = 0\n",
        "  data.loc[(data['tm_y'] == 4) & (data['tm_m'] == 11) & (data['tm_d'] == 27),\"wday\"] = 0\n",
        "  data.loc[~data['event_name_1'].isnull(),\"wday\"] = 0\n",
        "  '''\n",
        "  \n",
        "  data['price_sign'] = -1\n",
        "  data['price_sign_last'] = -1\n",
        "  #data = data.loc[~data['sell_price'].isnull()]\n",
        "  data.loc[~data['sell_price'].isnull(),'price_sign'] = (data.loc[~data['sell_price'].isnull()]['sell_price'] * 100 % 100).astype(\"int8\")\n",
        "  data.loc[~data['sell_price'].isnull(),'price_sign_last'] =  data.loc[~data['sell_price'].isnull()]['price_sign'].astype(str).str[-1].astype(\"int8\")\n",
        "\n",
        "  data = encode(data, 'tm_dw')\n",
        "  data = encode(data, 'tm_d')\n",
        "  data = encode(data, 'tm_m')\n",
        "  \n",
        "  #weekの計算方法を年初ベースに変更\n",
        "  '''\n",
        "  data['date'] = (2011 + data['tm_y']).astype(str) +'年'+ data['tm_m'].astype(str)+'月' + data['tm_d'].astype(str)+'日0時0分'\n",
        "  data['date'] = pd.to_datetime(data['date'], format='%Y年%m月%d日%H時%M分')\n",
        "  data['tm_w'] = data['date'].apply(lambda x: get_nth_week2(x.year,x.month,x.da y))\n",
        "  data['tm_w'] = data['tm_w'].astype('int8')\n",
        "  del data['date']\n",
        "  '''\n",
        "\n",
        "  data['price_position'] = 0\n",
        "  data['price_position'] = data['price_position'].astype('int8')\n",
        "  data.loc[data['sell_price'] == data['price_mean'], 'price_position'] = 0\n",
        "  data.loc[data['sell_price'] < data['price_mean'], 'price_position'] = -1\n",
        "  data.loc[data['sell_price'] > data['price_mean'], 'price_position'] = 1\n",
        "  data['price_position'] =data['price_position'].astype(\"int8\")\n",
        "\n",
        "\n",
        "\n",
        "  data = item_group(data)\n",
        "  data = elasticity(data)\n",
        "  #data = add_itemcount(data)\n",
        "  data = add_summertime(data)\n",
        "  data = fill_static_price(data)\n",
        "  data =  add_deviation_value(data)\n",
        "  return data\n",
        "\n",
        "import csv\n",
        "def elasticity(data):\n",
        "  \n",
        "  #売値固定情報量削減 \n",
        "  tmp = data[['item_id','sales']].groupby(['item_id']).max().reset_index().sort_values('item_id')\n",
        "  tmp['demand_mean'] = data[['item_id','sales']].groupby(['item_id']).mean().reset_index().sort_values('item_id')['sales']\n",
        "  tmp['demand_gap'] =  tmp['sales'] / tmp['demand_mean']\n",
        "  del tmp['sales'],tmp['demand_mean']\n",
        "  data = data.merge(tmp,on='item_id',how='left')\n",
        "  data['Elasticity'] = (data['price_max'] - data['price_mean']) / data['demand_gap']\n",
        "  del data['demand_gap']\n",
        "  return data\n",
        "\n",
        "def item_group(data):\n",
        "  '''\n",
        "  with open('sample_writer_row.csv') as f:\n",
        "    reader = csv.reader(f)\n",
        "    l = [row for row in reader]\n",
        "\n",
        "  for i in range(0,len(l)):\n",
        "    data['gap_group'] = 0\n",
        "    data.loc[data['item_id'].isin(l[i]),'gap_group'] = i\n",
        "  data['gap_group'] = data['gap_group'].astype('int8')\n",
        "  '''\n",
        "  return data\n",
        "\n",
        "def add_itemcount(data):\n",
        "  tmp = data.groupby(['d','dept_id']).count().reset_index()\n",
        "  tmp = tmp.rename(columns={'id':'item_count'})\n",
        "  tmp = tmp[['d','dept_id','item_count']]\n",
        "  return data.merge(tmp,on=['d','dept_id'],how='left')\n",
        "\n",
        "def add_summertime(data):\n",
        "  data['IsSummerTime'] = False\n",
        "  data.loc[((data['tm_m'] >= 4) & (data['tm_m'] <= 10)),'IsSummerTime'] = True\n",
        "  data.loc[((data['tm_y']==0) & (data['tm_m']==3) & (data['tm_d']>=13)) | ((data['tm_y']==0) & (data['tm_m']==11) & (data['tm_d']<=6)),'IsSummerTime'] = True\n",
        "  data.loc[((data['tm_y']==1) & (data['tm_m']==3) & (data['tm_d']>=11)) | ((data['tm_y']==1) & (data['tm_m']==11) & (data['tm_d']<=4)),'IsSummerTime'] = True\n",
        "  data.loc[((data['tm_y']==2) & (data['tm_m']==3) & (data['tm_d']>=10)) | ((data['tm_y']==2) & (data['tm_m']==11) & (data['tm_d']<=3)),'IsSummerTime'] = True\n",
        "  data.loc[((data['tm_y']==3) & (data['tm_m']==3) & (data['tm_d']>=9)) | ((data['tm_y']==3) & (data['tm_m']==11) & (data['tm_d']<=2)),'IsSummerTime'] = True\n",
        "  data.loc[((data['tm_y']==4) & (data['tm_m']==3) & (data['tm_d']>=8)) | ((data['tm_y']==4) & (data['tm_m']==11) & (data['tm_d']<=1)),'IsSummerTime'] = True\n",
        "  data.loc[((data['tm_y']==5) & (data['tm_m']==3) & (data['tm_d']>=13)) | ((data['tm_y']==5) & (data['tm_m']==11) & (data['tm_d']<=6)),'IsSummerTime'] = True\n",
        "  return data\n",
        "\n",
        "def fill_static_price(data):\n",
        "  nancol = ['price_std','price_norm','price_mean','price_nunique','price_momentum','price_momentum_m','price_momentum_y']\n",
        "  for c in nancol:\n",
        "    data.loc[data['price_max'] == data['price_min'], c] = np.nan\n",
        "  data.loc[data['price_std'].isnull(),'price_max'] = np.nan\n",
        "  data.loc[data['price_std'].isnull(),'price_min'] = np.nan\n",
        "  return data\n",
        "\n",
        "def add_deviation_value(data):\n",
        "  '''\n",
        "  price_mean = data[['d','cat_id','sell_price']].groupby(['d','cat_id']).mean().reset_index()\n",
        "  price_mean.rename(columns={'sell_price':'sell_price_allmean'},inplace=True)\n",
        "  data = data.merge(price_mean,on=['d','cat_id'],how='left')\n",
        "  data['sell_price_allstd'] = (data['sell_price'] - data['sell_price_allmean']) ** 2\n",
        "  price_mean = data[['d','cat_id','sell_price_allstd']].groupby(['d','cat_id']).sum().reset_index()\n",
        "\n",
        "  price_mean['sell_price_allstd'] = np.sqrt(price_mean['sell_price_allstd'] / data[['d','cat_id','sell_price_allmean']].groupby(['d','cat_id']).count().reset_index()['sell_price_allmean'])\n",
        "  data = data.merge(price_mean,on=['d','cat_id'],how='left')\n",
        "  data['sell_price_allstd'] = ((data['sell_price'] - data['sell_price_allmean']) / data['sell_price_allstd_y']) #* 10 + 50\n",
        "  del data['sell_price_allstd_x'],data['sell_price_allstd_y'],data['sell_price_allmean']\n",
        "  '''\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkG35cnjncs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_weight(data):\n",
        "  data['weight'] = 1\n",
        "  data.loc[(data['tm_y']<=4),'weight'] = 0\n",
        "\n",
        "  #tmp = data.groupby('id').mean().reset_index()[['id','sales']]\n",
        "  #tmp = tmp.loc[(~tmp['sales'].isnull()) & (tmp['sales']>2)][['id']]\n",
        "  #data.loc[(data['weight']==0) & (data['id'].isin(tmp['id'])),'weight'] = 0.3\n",
        "\n",
        "  #data.loc[(data['weight']==0) & (data['tm_m']>=4) & (data['tm_m']<=6),'weight'] = 0.2\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrci2MehZRex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################### store IDによってデータをロードするヘルパー\n",
        "#################################################################################\n",
        "# データ読込\n",
        "def get_data_by_store(store):\n",
        "    \n",
        "    # 基本特徴量を読んで連絡する\n",
        "    # BASE,PRICE,CALENDARは「【日本語】M5 - Simple FE」を参照\n",
        "    df = pd.concat([pd.read_pickle(BASE),\n",
        "                    pd.read_pickle(PRICE).iloc[:,2:],\n",
        "                    pd.read_pickle(CALENDAR).iloc[:,2:]],\n",
        "                    axis=1)\n",
        "    \n",
        "    # 関連する店舗のみを残す\n",
        "    df = df[df['store_id']==store]\n",
        "    \n",
        "    # メモリの制限があるため、LAGとエンコード特徴量を個別に読み取り、\n",
        "    # 不要なアイテムを削除する必要があります。 \n",
        "    # 特徴量グリッドが整列されるため、必要な行のみを保持するために index を使用できます\n",
        "    # concatはmergeよりも少ないメモリを使用するため、整列は適切です。\n",
        "    df2 = pd.read_pickle(MEAN_ENC)[mean_features] # 「M5 - Custom features」を参照\n",
        "    df2 = df2[df2.index.isin(df.index)]\n",
        "    \n",
        "    df3 = pd.read_pickle(LAGS).iloc[:,3:] # 「M5 - Custom features」を参照\n",
        "    df3 = df3[df3.index.isin(df.index)]\n",
        "    \n",
        "    df = pd.concat([df, df2], axis=1)\n",
        "    del df2 # メモリ制限に達しないように削除\n",
        "    \n",
        "    df = pd.concat([df, df3], axis=1)\n",
        "    del df3 # メモリ制限に達しないように削除\n",
        "    df = original_fea(df)\n",
        "    \n",
        "    # 特徴量リストを作成する\n",
        "    features = [col for col in list(df) if col not in remove_features]\n",
        "    print(features)\n",
        "    df = df[['id','d',TARGET]+features]\n",
        "    df = set_weight(df)\n",
        "    # 最初のn行をスキップ\n",
        "    df = df[df['d']>=START_TRAIN].reset_index(drop=True)\n",
        "    \n",
        "    return df, features\n",
        "\n",
        "# トレーニング後にテストを再結合\n",
        "def get_base_test():\n",
        "    base_test = pd.DataFrame()\n",
        "\n",
        "    for store_id in STORES_IDS:\n",
        "        temp_df = pd.read_pickle('test_'+store_id+'.pkl')\n",
        "        temp_df['store_id'] = store_id\n",
        "        base_test = pd.concat([base_test, temp_df]).reset_index(drop=True)\n",
        "    \n",
        "    return base_test\n",
        "\n",
        "\n",
        "########################### 動的移動LAGを作成するヘルパー\n",
        "#################################################################################\n",
        "def make_lag(LAG_DAY):\n",
        "    lag_df = base_test[['id','d',TARGET]]\n",
        "    col_name = 'sales_lag_'+str(LAG_DAY)\n",
        "    lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(LAG_DAY)).astype(np.float16)\n",
        "    return lag_df[[col_name]]\n",
        "\n",
        "\n",
        "def make_lag_roll(LAG_DAY):\n",
        "    shift_day = LAG_DAY[0]\n",
        "    roll_wind = LAG_DAY[1]\n",
        "    lag_df = base_test[['id','d',TARGET]]\n",
        "    col_name = 'rolling_mean_tmp_'+str(shift_day)+'_'+str(roll_wind)\n",
        "    lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(shift_day).rolling(roll_wind).mean())\n",
        "    return lag_df[[col_name]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjtl_RZTZXoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################### モデルパラメータ\n",
        "#################################################################################\n",
        "import lightgbm as lgb\n",
        "lgb_params = {\n",
        "                    'boosting_type': 'gbdt',\n",
        "                    'objective': 'tweedie',\n",
        "                    'tweedie_variance_power': 1.1,\n",
        "                    'metric': 'rmse',\n",
        "                    'subsample': 0.5,\n",
        "                    'subsample_freq': 1,\n",
        "                    'learning_rate': 0.03,\n",
        "                    'num_leaves': 2**11-1,\n",
        "                    'min_data_in_leaf': 2**12-1,\n",
        "                    'feature_fraction': 0.5,\n",
        "                    'max_bin': 100,\n",
        "                    'n_estimators': 1400,\n",
        "                    'boost_from_average': False,\n",
        "                    'verbose': -1,\n",
        "                } "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxSXr782ZZqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################### 変数\n",
        "#################################################################################\n",
        "VER = 1                          # バージョン\n",
        "SEED = 42                        # \n",
        "seed_everything(SEED)            # 私たちはすべてのものが出来るだけ\n",
        "lgb_params['seed'] = SEED        # 確定的であることを望みます。\n",
        "N_CORES = psutil.cpu_count()     # 使用可能なCPUコア\n",
        "\n",
        "\n",
        "#限界と定数\n",
        "TARGET      = 'sales'            # ターゲット\n",
        "START_TRAIN = 0                  # We can skip some rows (Nans/faster training)\n",
        "END_TRAIN   = 1941               # trainの終了日\n",
        "P_HORIZON   = 28                 # 予測期間\n",
        "USE_AUX     = False               # 事前学習済みモデルを使用するかどうか\n",
        "\n",
        "#削除する特徴量\n",
        "## これらの機能はオーバーフィットにつながります \n",
        "## または test に存在しない値\n",
        "remove_features = ['id','state_id','store_id',\n",
        "                   'date','wm_yr_wk','d',TARGET]\n",
        "mean_features   = ['enc_cat_id_mean','enc_cat_id_std',\n",
        "                   'enc_dept_id_mean','enc_dept_id_std',\n",
        "                   'enc_item_id_mean','enc_item_id_std'] \n",
        "\n",
        "\n",
        "#特徴量のパス\n",
        "ORIGINAL = ''\n",
        "BASE     = 'grid_part_1.pkl'#../input/m5-simple-fe/\n",
        "PRICE    = 'grid_part_2.pkl'#../input/m5-simple-fe/\n",
        "CALENDAR = 'grid_part_3.pkl'#../input/m5-simple-fe/\n",
        "LAGS     = 'lags_df_28.pkl'#../input/m5-lags-features/\n",
        "MEAN_ENC = 'mean_encoding_df.pkl'#../input/m5-custom-features/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#STORES id\n",
        "STORES_IDS = pd.read_csv(ORIGINAL+'sales_train_evaluation.csv')['store_id']\n",
        "STORES_IDS = list(STORES_IDS.unique())\n",
        "STORES_IDS = ['CA_3','TX_3','WI_2']\n",
        "#STORES_IDS = ['CA_1','CA_2','CA_4']\n",
        "\n",
        "#LAG作成用の分割\n",
        "SHIFT_DAY  = 28\n",
        "N_LAGS     = 15\n",
        "LAGS_SPLIT = [col for col in range(SHIFT_DAY,SHIFT_DAY+N_LAGS)]\n",
        "ROLS_SPLIT = []\n",
        "for i in [1,7,14]:\n",
        "    for j in [7,14,21,30,60]:#実験21\n",
        "        ROLS_SPLIT.append([i,j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZQgi89vkyMP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "aa65bc16-8df0-4563-9f1f-3fc9da680e99"
      },
      "source": [
        "grid_df, features_columns = get_data_by_store('TX_1')\n",
        "grid_df.sample()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['item_id', 'dept_id', 'cat_id', 'release', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'snap', 'price_sign', 'price_sign_last', 'tm_dw_cos', 'tm_dw_sin', 'tm_d_cos', 'tm_d_sin', 'tm_m_cos', 'tm_m_sin', 'price_position', 'Elasticity', 'IsSummerTime']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>d</th>\n",
              "      <th>sales</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>release</th>\n",
              "      <th>sell_price</th>\n",
              "      <th>price_max</th>\n",
              "      <th>price_min</th>\n",
              "      <th>price_std</th>\n",
              "      <th>price_mean</th>\n",
              "      <th>price_norm</th>\n",
              "      <th>price_nunique</th>\n",
              "      <th>item_nunique</th>\n",
              "      <th>price_momentum</th>\n",
              "      <th>price_momentum_m</th>\n",
              "      <th>price_momentum_y</th>\n",
              "      <th>event_name_1</th>\n",
              "      <th>event_type_1</th>\n",
              "      <th>event_name_2</th>\n",
              "      <th>event_type_2</th>\n",
              "      <th>tm_d</th>\n",
              "      <th>tm_w</th>\n",
              "      <th>tm_m</th>\n",
              "      <th>tm_y</th>\n",
              "      <th>tm_wm</th>\n",
              "      <th>tm_dw</th>\n",
              "      <th>tm_w_end</th>\n",
              "      <th>enc_cat_id_mean</th>\n",
              "      <th>enc_cat_id_std</th>\n",
              "      <th>enc_dept_id_mean</th>\n",
              "      <th>enc_dept_id_std</th>\n",
              "      <th>enc_item_id_mean</th>\n",
              "      <th>enc_item_id_std</th>\n",
              "      <th>sales_lag_28</th>\n",
              "      <th>sales_lag_29</th>\n",
              "      <th>sales_lag_30</th>\n",
              "      <th>sales_lag_31</th>\n",
              "      <th>sales_lag_32</th>\n",
              "      <th>...</th>\n",
              "      <th>sales_lag_38</th>\n",
              "      <th>sales_lag_39</th>\n",
              "      <th>sales_lag_40</th>\n",
              "      <th>sales_lag_41</th>\n",
              "      <th>sales_lag_42</th>\n",
              "      <th>rolling_mean_7</th>\n",
              "      <th>rolling_std_7</th>\n",
              "      <th>rolling_mean_14</th>\n",
              "      <th>rolling_std_14</th>\n",
              "      <th>rolling_mean_30</th>\n",
              "      <th>rolling_std_30</th>\n",
              "      <th>rolling_mean_60</th>\n",
              "      <th>rolling_std_60</th>\n",
              "      <th>rolling_mean_180</th>\n",
              "      <th>rolling_std_180</th>\n",
              "      <th>rolling_mean_tmp_1_7</th>\n",
              "      <th>rolling_mean_tmp_1_14</th>\n",
              "      <th>rolling_mean_tmp_1_30</th>\n",
              "      <th>rolling_mean_tmp_1_60</th>\n",
              "      <th>rolling_mean_tmp_7_7</th>\n",
              "      <th>rolling_mean_tmp_7_14</th>\n",
              "      <th>rolling_mean_tmp_7_30</th>\n",
              "      <th>rolling_mean_tmp_7_60</th>\n",
              "      <th>rolling_mean_tmp_14_7</th>\n",
              "      <th>rolling_mean_tmp_14_14</th>\n",
              "      <th>rolling_mean_tmp_14_30</th>\n",
              "      <th>rolling_mean_tmp_14_60</th>\n",
              "      <th>snap</th>\n",
              "      <th>price_sign</th>\n",
              "      <th>price_sign_last</th>\n",
              "      <th>tm_dw_cos</th>\n",
              "      <th>tm_dw_sin</th>\n",
              "      <th>tm_d_cos</th>\n",
              "      <th>tm_d_sin</th>\n",
              "      <th>tm_m_cos</th>\n",
              "      <th>tm_m_sin</th>\n",
              "      <th>price_position</th>\n",
              "      <th>Elasticity</th>\n",
              "      <th>IsSummerTime</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>967271</th>\n",
              "      <td>FOODS_3_694_TX_1_evaluation</td>\n",
              "      <td>550</td>\n",
              "      <td>25.0</td>\n",
              "      <td>FOODS_3_694</td>\n",
              "      <td>FOODS_3</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>0</td>\n",
              "      <td>1.580078</td>\n",
              "      <td>1.679688</td>\n",
              "      <td>1.480469</td>\n",
              "      <td>0.076416</td>\n",
              "      <td>1.605469</td>\n",
              "      <td>0.94043</td>\n",
              "      <td>3.0</td>\n",
              "      <td>32</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.991211</td>\n",
              "      <td>1.007812</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.740234</td>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.109375</td>\n",
              "      <td>5.769531</td>\n",
              "      <td>2.626953</td>\n",
              "      <td>7.058594</td>\n",
              "      <td>20.375</td>\n",
              "      <td>13.3125</td>\n",
              "      <td>38.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>...</td>\n",
              "      <td>44.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>26.859375</td>\n",
              "      <td>5.898438</td>\n",
              "      <td>29.140625</td>\n",
              "      <td>8.859375</td>\n",
              "      <td>29.296875</td>\n",
              "      <td>8.085938</td>\n",
              "      <td>27.59375</td>\n",
              "      <td>8.164062</td>\n",
              "      <td>22.296875</td>\n",
              "      <td>8.460938</td>\n",
              "      <td>25.28125</td>\n",
              "      <td>24.640625</td>\n",
              "      <td>26.171875</td>\n",
              "      <td>27.984375</td>\n",
              "      <td>24.71875</td>\n",
              "      <td>23.921875</td>\n",
              "      <td>25.703125</td>\n",
              "      <td>27.828125</td>\n",
              "      <td>23.140625</td>\n",
              "      <td>25.71875</td>\n",
              "      <td>27.296875</td>\n",
              "      <td>27.78125</td>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.001935</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.021565</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 85 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 id    d  ...  IsSummerTime weight\n",
              "967271  FOODS_3_694_TX_1_evaluation  550  ...          True      0\n",
              "\n",
              "[1 rows x 85 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVAyIC9zQqWb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "9f036f07-2199-4e84-8c44-3cd6421e1b35"
      },
      "source": [
        "'''\n",
        "def drop_outliner(df,store_id):\n",
        "  print(df.shape)\n",
        "  if store_id == 'TX_1':\n",
        "    df = df[~((grid_df['item_id']=='HOUSEHOLD_2_466') & (df['sell_price'] >6.968750))]\n",
        "  elif store_id == 'WI_2':\n",
        "    df = df.loc[~((df['item_id']=='HOUSEHOLD_2_406') & (df['tm_y']==1))]\n",
        "  \n",
        "  df = df.loc[~((df['item_id']=='HOUSEHOLD_2_292') & (df['tm_y']<3))]\n",
        "  df = df.loc[~((df['item_id']=='HOUSEHOLD_1_259') & (df['tm_y']<4))]\n",
        "  print(df.shape)\n",
        "  return df\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef drop_outliner(df,store_id):\\n  print(df.shape)\\n  if store_id == 'TX_1':\\n    df = df[~((grid_df['item_id']=='HOUSEHOLD_2_466') & (df['sell_price'] >6.968750))]\\n  elif store_id == 'WI_2':\\n    df = df.loc[~((df['item_id']=='HOUSEHOLD_2_406') & (df['tm_y']==1))]\\n  \\n  df = df.loc[~((df['item_id']=='HOUSEHOLD_2_292') & (df['tm_y']<3))]\\n  df = df.loc[~((df['item_id']=='HOUSEHOLD_1_259') & (df['tm_y']<4))]\\n  print(df.shape)\\n  return df\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXg77RPKZbf1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "2efc3f02-1abf-46ff-831a-c9f7e9831bc2"
      },
      "source": [
        "########################### AUXモデル\n",
        "\n",
        "if USE_AUX:\n",
        "    lgb_params['n_estimators'] = 2\n",
        "    \n",
        "''' \n",
        "Train CA_3\n",
        "['item_id', 'dept_id', 'cat_id', 'release', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'snap', 'price_sign', 'price_sign_last', 'Elasticity', 'IsSummerTime']\n",
        "[100]\tvalid_0's rmse: 2.28421\n",
        "[200]\tvalid_0's rmse: 2.13191\n",
        "[300]\tvalid_0's rmse: 2.04963\n",
        "[400]\tvalid_0's rmse: 1.97499\n",
        "[500]\tvalid_0's rmse: 1.9129\n",
        "[600]\tvalid_0's rmse: 1.8525\n",
        "[700]\tvalid_0's rmse: 1.7945\n",
        "[800]\tvalid_0's rmse: 1.73828\n",
        "[900]\tvalid_0's rmse: 1.68724\n",
        "[1000]\tvalid_0's rmse: 1.6407\n",
        "[1100]\tvalid_0's rmse: 1.59522\n",
        "[1200]\tvalid_0's rmse: 1.5517\n",
        "[1300]\tvalid_0's rmse: 1.51027\n",
        "[1400]\tvalid_0's rmse: 1.47179\n",
        "rm: cannot remove 'train_data.bin': No such file or directory\n",
        "Train TX_3\n",
        "['item_id', 'dept_id', 'cat_id', 'release', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'snap', 'price_sign', 'price_sign_last', 'Elasticity', 'IsSummerTime']\n",
        "[100]\tvalid_0's rmse: 1.77015\n",
        "[200]\tvalid_0's rmse: 1.63885\n",
        "[300]\tvalid_0's rmse: 1.56974\n",
        "[400]\tvalid_0's rmse: 1.51605\n",
        "[500]\tvalid_0's rmse: 1.46463\n",
        "[600]\tvalid_0's rmse: 1.41385\n",
        "[700]\tvalid_0's rmse: 1.36775\n",
        "[800]\tvalid_0's rmse: 1.32441\n",
        "[900]\tvalid_0's rmse: 1.28204\n",
        "[1000]\tvalid_0's rmse: 1.2446\n",
        "[1100]\tvalid_0's rmse: 1.20861\n",
        "[1200]\tvalid_0's rmse: 1.17677\n",
        "[1300]\tvalid_0's rmse: 1.14591\n",
        "[1400]\tvalid_0's rmse: 1.11877\n",
        "rm: cannot remove 'train_data.bin': No such file or directory\n",
        "Train WI_2\n",
        "['item_id', 'dept_id', 'cat_id', 'release', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'snap', 'price_sign', 'price_sign_last', 'Elasticity', 'IsSummerTime']\n",
        "[100]\tvalid_0's rmse: 2.56866\n",
        "[200]\tvalid_0's rmse: 2.32451\n",
        "[300]\tvalid_0's rmse: 2.18298\n",
        "[400]\tvalid_0's rmse: 2.06812\n",
        "[500]\tvalid_0's rmse: 1.96433\n",
        "[600]\tvalid_0's rmse: 1.87574\n",
        "[700]\tvalid_0's rmse: 1.80038\n",
        "[800]\tvalid_0's rmse: 1.73619\n",
        "[900]\tvalid_0's rmse: 1.67442\n",
        "[1000]\tvalid_0's rmse: 1.621\n",
        "[1100]\tvalid_0's rmse: 1.57173\n",
        "[1200]\tvalid_0's rmse: 1.52515\n",
        "[1300]\tvalid_0's rmse: 1.48612\n",
        "[1400]\tvalid_0's rmse: 1.44579\n",
        "rm: cannot remove 'train_data.bin': No such file or directory\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" \\nTrain CA_3\\n['item_id', 'dept_id', 'cat_id', 'release', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'snap', 'price_sign', 'price_sign_last', 'Elasticity', 'IsSummerTime']\\n[100]\\tvalid_0's rmse: 2.28421\\n[200]\\tvalid_0's rmse: 2.13191\\n[300]\\tvalid_0's rmse: 2.04963\\n[400]\\tvalid_0's rmse: 1.97499\\n[500]\\tvalid_0's rmse: 1.9129\\n[600]\\tvalid_0's rmse: 1.8525\\n[700]\\tvalid_0's rmse: 1.7945\\n[800]\\tvalid_0's rmse: 1.73828\\n[900]\\tvalid_0's rmse: 1.68724\\n[1000]\\tvalid_0's rmse: 1.6407\\n[1100]\\tvalid_0's rmse: 1.59522\\n[1200]\\tvalid_0's rmse: 1.5517\\n[1300]\\tvalid_0's rmse: 1.51027\\n[1400]\\tvalid_0's rmse: 1.47179\\nrm: cannot remove 'train_data.bin': No such file or directory\\nTrain TX_3\\n['item_id', 'dept_id', 'cat_id', 'release', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'snap', 'price_sign', 'price_sign_last', 'Elasticity', 'IsSummerTime']\\n[100]\\tvalid_0's rmse: 1.77015\\n[200]\\tvalid_0's rmse: 1.63885\\n[300]\\tvalid_0's rmse: 1.56974\\n[400]\\tvalid_0's rmse: 1.51605\\n[500]\\tvalid_0's rmse: 1.46463\\n[600]\\tvalid_0's rmse: 1.41385\\n[700]\\tvalid_0's rmse: 1.36775\\n[800]\\tvalid_0's rmse: 1.32441\\n[900]\\tvalid_0's rmse: 1.28204\\n[1000]\\tvalid_0's rmse: 1.2446\\n[1100]\\tvalid_0's rmse: 1.20861\\n[1200]\\tvalid_0's rmse: 1.17677\\n[1300]\\tvalid_0's rmse: 1.14591\\n[1400]\\tvalid_0's rmse: 1.11877\\nrm: cannot remove 'train_data.bin': No such file or directory\\nTrain WI_2\\n['item_id', 'dept_id', 'cat_id', 'release', 'sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'tm_d', 'tm_w', 'tm_m', 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end', 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean', 'enc_dept_id_std', 'enc_item_id_mean', 'enc_item_id_std', 'sales_lag_28', 'sales_lag_29', 'sales_lag_30', 'sales_lag_31', 'sales_lag_32', 'sales_lag_33', 'sales_lag_34', 'sales_lag_35', 'sales_lag_36', 'sales_lag_37', 'sales_lag_38', 'sales_lag_39', 'sales_lag_40', 'sales_lag_41', 'sales_lag_42', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_30', 'rolling_std_30', 'rolling_mean_60', 'rolling_std_60', 'rolling_mean_180', 'rolling_std_180', 'rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_1_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_60', 'snap', 'price_sign', 'price_sign_last', 'Elasticity', 'IsSummerTime']\\n[100]\\tvalid_0's rmse: 2.56866\\n[200]\\tvalid_0's rmse: 2.32451\\n[300]\\tvalid_0's rmse: 2.18298\\n[400]\\tvalid_0's rmse: 2.06812\\n[500]\\tvalid_0's rmse: 1.96433\\n[600]\\tvalid_0's rmse: 1.87574\\n[700]\\tvalid_0's rmse: 1.80038\\n[800]\\tvalid_0's rmse: 1.73619\\n[900]\\tvalid_0's rmse: 1.67442\\n[1000]\\tvalid_0's rmse: 1.621\\n[1100]\\tvalid_0's rmse: 1.57173\\n[1200]\\tvalid_0's rmse: 1.52515\\n[1300]\\tvalid_0's rmse: 1.48612\\n[1400]\\tvalid_0's rmse: 1.44579\\nrm: cannot remove 'train_data.bin': No such file or directory\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUYsXThyZdS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################### モデルのトレーニング\n",
        "#################################################################################\n",
        "for store_id in STORES_IDS:\n",
        "    print('Train', store_id)\n",
        "    \n",
        "    # 現在の店舗のグリッドを取得\n",
        "    grid_df, features_columns = get_data_by_store(store_id)\n",
        "    #grid_df = drop_outliner(grid_df,store_id)\n",
        "    # マスク\n",
        "    # Train （1913未満のすべてのデータ）\n",
        "    # \"Validation\" （過去28日間-実際の検証セットではない\n",
        "    # Test （1913日を超えるすべてのデータ、再帰的機能のギャップあり）\n",
        "    train_mask = grid_df['d']<=END_TRAIN\n",
        "    valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n",
        "    preds_mask = grid_df['d']>(END_TRAIN-100)\n",
        "    # マスクを適用してlgbデータセットをbinとして保存し、\n",
        "    # dtype変換中のメモリスパイクを削減する\n",
        "    # https://github.com/Microsoft/LightGBM/issues/1032\n",
        "    # 変換を回避するには、常にnp.float32を使用するか、\n",
        "    # トレーニングを開始する前に bin に保存する必要があります\n",
        "    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
        "    train_data = lgb.Dataset(grid_df[train_mask][features_columns], \n",
        "                        weight=grid_df[train_mask]['weight'],\n",
        "                       label=grid_df[train_mask][TARGET])#                  \n",
        "    train_data.free_raw_data = None\n",
        "    #train_data.save_binary('train_data.bin')\n",
        "    #train_data = lgb.Dataset('train_data.bin')\n",
        "    valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], \n",
        "                              weight=grid_df[valid_mask]['weight'],\n",
        "                       label=grid_df[valid_mask][TARGET])#     ,                                     \n",
        "    valid_data.free_raw_data = None\n",
        "    # 後の予測のためにデータセットの一部を保存する\n",
        "    # 再帰的に計算する必要がある機能を削除する\n",
        "    grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
        "    keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
        "    grid_df = grid_df[keep_cols]\n",
        "    grid_df.to_pickle('test_'+store_id+'.pkl')\n",
        "    del grid_df\n",
        "    # シーダーを再度起動して、\n",
        "    # 各「コード行」np.randomが「進化」するlgbトレーニングを100％確定的にするため、\n",
        "    # 「リセット」する必要がある場合があります。\n",
        "    seed_everything(SEED)\n",
        "    estimator = lgb.train(lgb_params,\n",
        "                          train_data,\n",
        "                          valid_sets = [valid_data],\n",
        "                          verbose_eval = 100,\n",
        "                          )\n",
        "    \n",
        "    # モデルを保存-実際の「.bin」ではなく\n",
        "    # estimator = lgb.Booster(model_file='model.txt')\n",
        "    # pickleファイルとすると最良の反復（または保存反復）でのみ予測できます\n",
        "    # pickle.dumpは柔軟性を提供します。\n",
        "    # estimator.predict(TEST, num_iteration=100)\n",
        "    # num_iteration - 予測したい反復回数\n",
        "    # NULLまたは<= 0は最適な反復を使用することを意味します\n",
        "    model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
        "    pickle.dump(estimator, open(model_name, 'wb'))\n",
        "    # 一時ファイルとオブジェクトを削除して、\n",
        "    # HDDスペースとRAMメモリを解放します\n",
        "    !rm train_data.bin\n",
        "    del train_data, valid_data, estimator\n",
        "    gc.collect()\n",
        "    \n",
        "    # 予測のためのモデル特徴量の保持\n",
        "    MODEL_FEATURES = features_columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfbdvzP_Zfbm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "728b4b4a-8efa-4976-bec8-5d192dc0130c"
      },
      "source": [
        "########################### 予測\n",
        "#################################################################################\n",
        "\n",
        "# 予測を保存するためのダミーデータフレームを作成する\n",
        "all_preds = pd.DataFrame()\n",
        "\n",
        "# テストデータセットをトレーニングデータの一部に結合して、\n",
        "# 再帰的な特徴量を作成します\n",
        "base_test = get_base_test()\n",
        "\n",
        "# 予測時間を測定するタイマー\n",
        "main_time = time.time()\n",
        "\n",
        "# 各予測日にループする移動LAGは最も時間がかかるため、\n",
        "# 1日全体で計算します。\n",
        "for PREDICT_DAY in range(1,P_HORIZON+1):    \n",
        "    print('Predict | Day:', PREDICT_DAY)\n",
        "    start_time = time.time()\n",
        "\n",
        "    # 移動LAGを計算するための一時的なグリッドを作成する\n",
        "    grid_df = base_test.copy()\n",
        "    grid_df = pd.concat([grid_df, df_parallelize_run(make_lag_roll, ROLS_SPLIT)], axis=1)\n",
        "        \n",
        "    for store_id in STORES_IDS:\n",
        "        \n",
        "        # すべてのモデルを読んで、日/店舗のペアごとに予測を行う\n",
        "        model_path = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin' \n",
        " \n",
        "        \n",
        "        estimator = pickle.load(open(model_path, 'rb'))\n",
        "        \n",
        "        day_mask = base_test['d']==(END_TRAIN+PREDICT_DAY)\n",
        "        store_mask = base_test['store_id']==store_id\n",
        "        \n",
        "        mask = (day_mask)&(store_mask)\n",
        "        base_test[TARGET][mask] = estimator.predict(grid_df[mask][MODEL_FEATURES])\n",
        "    \n",
        "    # 適切な列の名前を付け、all_preds に追加します\n",
        "    temp_df = base_test[day_mask][['id',TARGET]]\n",
        "    temp_df.columns = ['id','F'+str(PREDICT_DAY)]\n",
        "    if 'id' in list(all_preds):\n",
        "        all_preds = all_preds.merge(temp_df, on=['id'], how='left')\n",
        "    else:\n",
        "        all_preds = temp_df.copy()\n",
        "        \n",
        "    print('#'*10, ' %0.2f min round |' % ((time.time() - start_time) / 60),\n",
        "                  ' %0.2f min total |' % ((time.time() - main_time) / 60),\n",
        "                  ' %0.2f day sales |' % (temp_df['F'+str(PREDICT_DAY)].sum()))\n",
        "    del temp_df\n",
        "    \n",
        "all_preds = all_preds.reset_index(drop=True)\n",
        "all_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predict | Day: 1\n",
            "##########  3.01 min round |  3.01 min total |  39759.87 day sales |\n",
            "Predict | Day: 2\n",
            "##########  2.90 min round |  5.91 min total |  37064.22 day sales |\n",
            "Predict | Day: 3\n",
            "##########  3.02 min round |  8.93 min total |  37035.72 day sales |\n",
            "Predict | Day: 4\n",
            "##########  3.03 min round |  11.96 min total |  36843.94 day sales |\n",
            "Predict | Day: 5\n",
            "##########  3.05 min round |  15.01 min total |  41757.13 day sales |\n",
            "Predict | Day: 6\n",
            "##########  3.05 min round |  18.06 min total |  49965.75 day sales |\n",
            "Predict | Day: 7\n",
            "##########  3.06 min round |  21.12 min total |  50753.83 day sales |\n",
            "Predict | Day: 8\n",
            "##########  3.06 min round |  24.18 min total |  45454.29 day sales |\n",
            "Predict | Day: 9\n",
            "##########  3.00 min round |  27.18 min total |  39027.52 day sales |\n",
            "Predict | Day: 10\n",
            "##########  2.93 min round |  30.11 min total |  44304.91 day sales |\n",
            "Predict | Day: 11\n",
            "##########  2.99 min round |  33.10 min total |  45306.22 day sales |\n",
            "Predict | Day: 12\n",
            "##########  3.05 min round |  36.15 min total |  53823.39 day sales |\n",
            "Predict | Day: 13\n",
            "##########  3.04 min round |  39.19 min total |  55939.59 day sales |\n",
            "Predict | Day: 14\n",
            "##########  3.05 min round |  42.24 min total |  58362.47 day sales |\n",
            "Predict | Day: 15\n",
            "##########  3.05 min round |  45.28 min total |  48290.99 day sales |\n",
            "Predict | Day: 16\n",
            "##########  3.04 min round |  48.32 min total |  43486.12 day sales |\n",
            "Predict | Day: 17\n",
            "##########  3.01 min round |  51.33 min total |  43024.62 day sales |\n",
            "Predict | Day: 18\n",
            "##########  2.91 min round |  54.24 min total |  45102.58 day sales |\n",
            "Predict | Day: 19\n",
            "##########  2.91 min round |  57.15 min total |  46999.82 day sales |\n",
            "Predict | Day: 20\n",
            "##########  3.00 min round |  60.15 min total |  57613.26 day sales |\n",
            "Predict | Day: 21\n",
            "##########  3.02 min round |  63.17 min total |  59394.81 day sales |\n",
            "Predict | Day: 22\n",
            "##########  3.03 min round |  66.20 min total |  46487.81 day sales |\n",
            "Predict | Day: 23\n",
            "##########  3.03 min round |  69.23 min total |  43440.51 day sales |\n",
            "Predict | Day: 24\n",
            "##########  3.04 min round |  72.27 min total |  45482.44 day sales |\n",
            "Predict | Day: 25\n",
            "##########  3.04 min round |  75.31 min total |  41939.45 day sales |\n",
            "Predict | Day: 26\n",
            "##########  2.95 min round |  78.26 min total |  46132.15 day sales |\n",
            "Predict | Day: 27\n",
            "##########  2.88 min round |  81.14 min total |  54541.00 day sales |\n",
            "Predict | Day: 28\n",
            "##########  2.94 min round |  84.07 min total |  51993.34 day sales |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "      <th>F11</th>\n",
              "      <th>F12</th>\n",
              "      <th>F13</th>\n",
              "      <th>F14</th>\n",
              "      <th>F15</th>\n",
              "      <th>F16</th>\n",
              "      <th>F17</th>\n",
              "      <th>F18</th>\n",
              "      <th>F19</th>\n",
              "      <th>F20</th>\n",
              "      <th>F21</th>\n",
              "      <th>F22</th>\n",
              "      <th>F23</th>\n",
              "      <th>F24</th>\n",
              "      <th>F25</th>\n",
              "      <th>F26</th>\n",
              "      <th>F27</th>\n",
              "      <th>F28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
              "      <td>0.896919</td>\n",
              "      <td>0.808327</td>\n",
              "      <td>0.787733</td>\n",
              "      <td>0.800273</td>\n",
              "      <td>1.044852</td>\n",
              "      <td>1.353330</td>\n",
              "      <td>1.283072</td>\n",
              "      <td>0.971777</td>\n",
              "      <td>0.788433</td>\n",
              "      <td>1.030200</td>\n",
              "      <td>0.827920</td>\n",
              "      <td>1.163072</td>\n",
              "      <td>1.399896</td>\n",
              "      <td>1.219377</td>\n",
              "      <td>0.939904</td>\n",
              "      <td>0.912041</td>\n",
              "      <td>0.868280</td>\n",
              "      <td>0.828838</td>\n",
              "      <td>0.973320</td>\n",
              "      <td>1.238219</td>\n",
              "      <td>1.288867</td>\n",
              "      <td>1.000805</td>\n",
              "      <td>0.921084</td>\n",
              "      <td>0.926695</td>\n",
              "      <td>0.971500</td>\n",
              "      <td>1.155859</td>\n",
              "      <td>1.203079</td>\n",
              "      <td>1.210900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
              "      <td>0.220466</td>\n",
              "      <td>0.204749</td>\n",
              "      <td>0.212473</td>\n",
              "      <td>0.199276</td>\n",
              "      <td>0.220701</td>\n",
              "      <td>0.305867</td>\n",
              "      <td>0.324968</td>\n",
              "      <td>0.213049</td>\n",
              "      <td>0.194676</td>\n",
              "      <td>0.211614</td>\n",
              "      <td>0.209575</td>\n",
              "      <td>0.319597</td>\n",
              "      <td>0.379714</td>\n",
              "      <td>0.297997</td>\n",
              "      <td>0.204043</td>\n",
              "      <td>0.233662</td>\n",
              "      <td>0.214412</td>\n",
              "      <td>0.237179</td>\n",
              "      <td>0.274404</td>\n",
              "      <td>0.329860</td>\n",
              "      <td>0.343886</td>\n",
              "      <td>0.211545</td>\n",
              "      <td>0.210241</td>\n",
              "      <td>0.205603</td>\n",
              "      <td>0.232045</td>\n",
              "      <td>0.266742</td>\n",
              "      <td>0.314893</td>\n",
              "      <td>0.399803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
              "      <td>0.529796</td>\n",
              "      <td>0.480658</td>\n",
              "      <td>0.485227</td>\n",
              "      <td>0.512719</td>\n",
              "      <td>0.711414</td>\n",
              "      <td>0.794804</td>\n",
              "      <td>0.726323</td>\n",
              "      <td>0.563683</td>\n",
              "      <td>0.519169</td>\n",
              "      <td>0.558241</td>\n",
              "      <td>0.450290</td>\n",
              "      <td>0.648836</td>\n",
              "      <td>0.777947</td>\n",
              "      <td>0.667974</td>\n",
              "      <td>0.498328</td>\n",
              "      <td>0.485776</td>\n",
              "      <td>0.490877</td>\n",
              "      <td>0.475087</td>\n",
              "      <td>0.553368</td>\n",
              "      <td>0.739833</td>\n",
              "      <td>0.701520</td>\n",
              "      <td>0.499819</td>\n",
              "      <td>0.445005</td>\n",
              "      <td>0.473900</td>\n",
              "      <td>0.483154</td>\n",
              "      <td>0.658015</td>\n",
              "      <td>0.758736</td>\n",
              "      <td>0.704474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
              "      <td>1.679303</td>\n",
              "      <td>1.350790</td>\n",
              "      <td>1.390648</td>\n",
              "      <td>1.472831</td>\n",
              "      <td>1.742545</td>\n",
              "      <td>2.423991</td>\n",
              "      <td>2.897262</td>\n",
              "      <td>2.091391</td>\n",
              "      <td>1.362763</td>\n",
              "      <td>1.384726</td>\n",
              "      <td>1.576862</td>\n",
              "      <td>2.081480</td>\n",
              "      <td>2.863150</td>\n",
              "      <td>2.804167</td>\n",
              "      <td>1.817179</td>\n",
              "      <td>1.660786</td>\n",
              "      <td>1.362049</td>\n",
              "      <td>1.440221</td>\n",
              "      <td>1.874175</td>\n",
              "      <td>2.524346</td>\n",
              "      <td>3.068022</td>\n",
              "      <td>1.936250</td>\n",
              "      <td>1.373735</td>\n",
              "      <td>1.419908</td>\n",
              "      <td>1.443614</td>\n",
              "      <td>1.886773</td>\n",
              "      <td>2.622977</td>\n",
              "      <td>3.134182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
              "      <td>1.015119</td>\n",
              "      <td>0.977014</td>\n",
              "      <td>0.927098</td>\n",
              "      <td>0.993035</td>\n",
              "      <td>1.080928</td>\n",
              "      <td>1.303042</td>\n",
              "      <td>1.378404</td>\n",
              "      <td>1.250934</td>\n",
              "      <td>1.054353</td>\n",
              "      <td>1.132265</td>\n",
              "      <td>1.105215</td>\n",
              "      <td>1.377746</td>\n",
              "      <td>1.400710</td>\n",
              "      <td>1.540751</td>\n",
              "      <td>1.097919</td>\n",
              "      <td>1.049561</td>\n",
              "      <td>0.998681</td>\n",
              "      <td>1.012499</td>\n",
              "      <td>1.142446</td>\n",
              "      <td>1.346198</td>\n",
              "      <td>1.401818</td>\n",
              "      <td>1.146235</td>\n",
              "      <td>0.986988</td>\n",
              "      <td>1.073486</td>\n",
              "      <td>1.128597</td>\n",
              "      <td>1.389739</td>\n",
              "      <td>1.579713</td>\n",
              "      <td>1.455819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30485</th>\n",
              "      <td>FOODS_3_823_WI_3_evaluation</td>\n",
              "      <td>0.476450</td>\n",
              "      <td>0.443781</td>\n",
              "      <td>0.437969</td>\n",
              "      <td>0.483285</td>\n",
              "      <td>0.471879</td>\n",
              "      <td>0.511311</td>\n",
              "      <td>0.668452</td>\n",
              "      <td>0.499746</td>\n",
              "      <td>0.490234</td>\n",
              "      <td>0.436963</td>\n",
              "      <td>0.646053</td>\n",
              "      <td>0.730032</td>\n",
              "      <td>0.706655</td>\n",
              "      <td>0.783020</td>\n",
              "      <td>0.620229</td>\n",
              "      <td>0.549439</td>\n",
              "      <td>0.520738</td>\n",
              "      <td>0.592746</td>\n",
              "      <td>0.562463</td>\n",
              "      <td>0.711263</td>\n",
              "      <td>0.877204</td>\n",
              "      <td>0.616886</td>\n",
              "      <td>0.582591</td>\n",
              "      <td>0.584170</td>\n",
              "      <td>0.486450</td>\n",
              "      <td>0.551508</td>\n",
              "      <td>0.578857</td>\n",
              "      <td>0.728974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>FOODS_3_824_WI_3_evaluation</td>\n",
              "      <td>0.250087</td>\n",
              "      <td>0.239587</td>\n",
              "      <td>0.220720</td>\n",
              "      <td>0.192613</td>\n",
              "      <td>0.209839</td>\n",
              "      <td>0.281332</td>\n",
              "      <td>0.285680</td>\n",
              "      <td>0.277420</td>\n",
              "      <td>0.243141</td>\n",
              "      <td>0.226478</td>\n",
              "      <td>0.326821</td>\n",
              "      <td>0.315657</td>\n",
              "      <td>0.284630</td>\n",
              "      <td>0.318896</td>\n",
              "      <td>0.280560</td>\n",
              "      <td>0.296365</td>\n",
              "      <td>0.275089</td>\n",
              "      <td>0.292407</td>\n",
              "      <td>0.244004</td>\n",
              "      <td>0.300197</td>\n",
              "      <td>0.386606</td>\n",
              "      <td>0.287312</td>\n",
              "      <td>0.311400</td>\n",
              "      <td>0.287994</td>\n",
              "      <td>0.239931</td>\n",
              "      <td>0.208813</td>\n",
              "      <td>0.264203</td>\n",
              "      <td>0.345811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30487</th>\n",
              "      <td>FOODS_3_825_WI_3_evaluation</td>\n",
              "      <td>0.663887</td>\n",
              "      <td>0.480266</td>\n",
              "      <td>0.514194</td>\n",
              "      <td>0.494664</td>\n",
              "      <td>0.553251</td>\n",
              "      <td>0.645590</td>\n",
              "      <td>0.727649</td>\n",
              "      <td>0.728169</td>\n",
              "      <td>0.494397</td>\n",
              "      <td>0.652815</td>\n",
              "      <td>0.993464</td>\n",
              "      <td>1.103823</td>\n",
              "      <td>0.854273</td>\n",
              "      <td>1.083670</td>\n",
              "      <td>1.077858</td>\n",
              "      <td>0.775913</td>\n",
              "      <td>0.887848</td>\n",
              "      <td>0.875240</td>\n",
              "      <td>0.843881</td>\n",
              "      <td>1.073937</td>\n",
              "      <td>1.255404</td>\n",
              "      <td>0.937257</td>\n",
              "      <td>0.987630</td>\n",
              "      <td>0.981570</td>\n",
              "      <td>0.670349</td>\n",
              "      <td>0.709838</td>\n",
              "      <td>0.738259</td>\n",
              "      <td>0.931900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30488</th>\n",
              "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
              "      <td>1.018613</td>\n",
              "      <td>1.053016</td>\n",
              "      <td>0.957609</td>\n",
              "      <td>0.994166</td>\n",
              "      <td>1.000394</td>\n",
              "      <td>1.178593</td>\n",
              "      <td>1.157526</td>\n",
              "      <td>1.221021</td>\n",
              "      <td>1.052750</td>\n",
              "      <td>1.008126</td>\n",
              "      <td>1.313052</td>\n",
              "      <td>1.604317</td>\n",
              "      <td>1.451344</td>\n",
              "      <td>1.762432</td>\n",
              "      <td>1.243546</td>\n",
              "      <td>1.156422</td>\n",
              "      <td>1.183751</td>\n",
              "      <td>1.257486</td>\n",
              "      <td>1.169555</td>\n",
              "      <td>1.537536</td>\n",
              "      <td>1.723522</td>\n",
              "      <td>1.168916</td>\n",
              "      <td>1.462073</td>\n",
              "      <td>1.250036</td>\n",
              "      <td>1.044753</td>\n",
              "      <td>1.122169</td>\n",
              "      <td>1.159464</td>\n",
              "      <td>1.296833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30489</th>\n",
              "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
              "      <td>1.684870</td>\n",
              "      <td>1.578499</td>\n",
              "      <td>1.463709</td>\n",
              "      <td>1.607283</td>\n",
              "      <td>1.980092</td>\n",
              "      <td>1.998912</td>\n",
              "      <td>1.928996</td>\n",
              "      <td>1.676306</td>\n",
              "      <td>1.592155</td>\n",
              "      <td>1.394305</td>\n",
              "      <td>1.667078</td>\n",
              "      <td>2.113235</td>\n",
              "      <td>2.087524</td>\n",
              "      <td>2.081891</td>\n",
              "      <td>1.601206</td>\n",
              "      <td>1.411176</td>\n",
              "      <td>1.387175</td>\n",
              "      <td>1.530088</td>\n",
              "      <td>1.449447</td>\n",
              "      <td>2.022072</td>\n",
              "      <td>2.006983</td>\n",
              "      <td>1.474236</td>\n",
              "      <td>1.978958</td>\n",
              "      <td>1.659772</td>\n",
              "      <td>1.362620</td>\n",
              "      <td>1.619337</td>\n",
              "      <td>1.857102</td>\n",
              "      <td>1.927825</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30490 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  id        F1  ...       F27       F28\n",
              "0      HOBBIES_1_001_CA_1_evaluation  0.896919  ...  1.203079  1.210900\n",
              "1      HOBBIES_1_002_CA_1_evaluation  0.220466  ...  0.314893  0.399803\n",
              "2      HOBBIES_1_003_CA_1_evaluation  0.529796  ...  0.758736  0.704474\n",
              "3      HOBBIES_1_004_CA_1_evaluation  1.679303  ...  2.622977  3.134182\n",
              "4      HOBBIES_1_005_CA_1_evaluation  1.015119  ...  1.579713  1.455819\n",
              "...                              ...       ...  ...       ...       ...\n",
              "30485    FOODS_3_823_WI_3_evaluation  0.476450  ...  0.578857  0.728974\n",
              "30486    FOODS_3_824_WI_3_evaluation  0.250087  ...  0.264203  0.345811\n",
              "30487    FOODS_3_825_WI_3_evaluation  0.663887  ...  0.738259  0.931900\n",
              "30488    FOODS_3_826_WI_3_evaluation  1.018613  ...  1.159464  1.296833\n",
              "30489    FOODS_3_827_WI_3_evaluation  1.684870  ...  1.857102  1.927825\n",
              "\n",
              "[30490 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDcgI0zvJftt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "707b520d-3dce-4b4c-fcc7-5b75cb67e16e"
      },
      "source": [
        "VER"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRRsK1u9ZhR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################### 書き出す\n",
        "#################################################################################\n",
        "# コンぺのサンプル提出を読んで、予測を結合する\n",
        "# 「_validation」データのみの予測があるため\n",
        "# 「_evaluation」アイテムに対してfillna（）を実行する必要がある\n",
        "submission = pd.read_csv(ORIGINAL+'sample_submission.csv')[['id']]\n",
        "submission = submission.merge(all_preds, on=['id'], how='left').fillna(0)\n",
        "submission.to_csv('submission_v'+str(VER)+'.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR_eGLU9UKrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}